import _defineProperty from '@babel/runtime/helpers/defineProperty';
import { TkeyError, secp256k1, generatePrivateExcludingIndexes, Polynomial, Point, PublicPolynomial, decrypt, toPrivKeyECC, ShareStore, getPubKeyPoint, PublicShare, Share, stripHexPrefix, toPrivKeyEC, KEY_NOT_FOUND, prettyPrintError, SHARE_DELETED, encrypt, getPubKeyECC, ONE_KEY_DELETE_NONCE } from '@tkey/common-types';
import { keccak256, getEd25519ExtendedPublicKey } from '@toruslabs/torus.js';
import stringify from 'json-stable-stringify';
import _objectSpread from '@babel/runtime/helpers/objectSpread2';
import BN from 'bn.js';
import { getRandomBytes } from 'ethereum-cryptography/random';

/**
 * CoreError, extension for Error using CustomError
 * details: github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work
 *
 * Usage:
 * 1. throw CoreError.metadataUndefined() // regularly used errors
 * 2. throw CoreError.fromCode(1304); // throw via code
 * 3. throw new CoreError(1000, "share indexes should be unique"); // for scarce errors
 *
 * Guide:
 * 1000 - core
 * 2000 - security questions
 * 3000 - webstorage
 * 4000 - common types (code reserved for future implementation)
 * 5000 - private key
 * 6000 - seed phrase
 * 7000 - share serialization
 * 8000 - share transfer
 */
class CoreError extends TkeyError {
  constructor(code, message) {
    // takes care of stack and proto
    super(code, message);

    // Set name explicitly as minification can mangle class names
    Object.defineProperty(this, "name", {
      value: "CoreError"
    });
  }
  static fromCode(code, extraMessage = "") {
    return new CoreError(code, `${CoreError.messages[code]} ${extraMessage}`);
  }
  static default(extraMessage = "") {
    return new CoreError(1000, `${CoreError.messages[1000]} ${extraMessage}`);
  }

  // Custom methods
  // Metadata
  static metadataUndefined(extraMessage = "") {
    return CoreError.fromCode(1101, extraMessage);
  }
  static delete1OutOf1OnlyManualSync(extraMessage = "") {
    return CoreError.fromCode(1601, extraMessage);
  }
  static metadataGetFailed(extraMessage = "") {
    return CoreError.fromCode(1102, extraMessage);
  }
  static metadataPostFailed(extraMessage = "") {
    return CoreError.fromCode(1103, extraMessage);
  }

  // TkeyData
  static tkeyStoreInvalid(extraMessage = "") {
    return CoreError.fromCode(1201, extraMessage);
  }
  static tkeyEncryptionFailed(extraMessage = "") {
    return CoreError.fromCode(1202, extraMessage);
  }
  static tkeyDecryptionFailed(extraMessage = "") {
    return CoreError.fromCode(1203, extraMessage);
  }

  // Shares
  static privateKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1301, extraMessage);
  }
  static unableToReconstruct(extraMessage = "") {
    return CoreError.fromCode(1302, extraMessage);
  }
  static incorrectReconstruction(extraMessage = "") {
    return CoreError.fromCode(1303, extraMessage);
  }
  static encryptedShareStoreUnavailable(extraMessage = "") {
    return CoreError.fromCode(1306, extraMessage);
  }

  // Metadata locks
  static acquireLockFailed(extraMessage = "") {
    return CoreError.fromCode(1401, extraMessage);
  }
  static releaseLockFailed(extraMessage = "") {
    return CoreError.fromCode(1402, extraMessage);
  }

  // Authmetadata
  static privKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1501, extraMessage);
  }
  static metadataPubKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1502, extraMessage);
  }
  static authMetadataGetUnavailable(extraMessage = "") {
    return CoreError.fromCode(1503, extraMessage);
  }
  static authMetadataSetUnavailable(extraMessage = "") {
    return CoreError.fromCode(1504, extraMessage);
  }
}
_defineProperty(CoreError, "messages", {
  1000: "Custom",
  // Misc
  1001: "Unable to delete service provider share",
  1002: "Wrong share index",
  1003: "Unable to updateSDK",
  // metadata
  1101: "metadata not found, SDK likely not initialized",
  1102: "getMetadata errored",
  1103: "setMetadata errored",
  1104: "previouslyFetchedCloudMetadata provided in initialization is outdated",
  1105: "previouslyFetchedCloudMetadata.nonce should never be higher than the latestShareDetails, please contact support",
  // tkeystore
  1201: "Invalid tkeyStore",
  1202: "Encryption failed",
  1203: "Decryption failed",
  // shares
  1301: "Private key not available. Please reconstruct key first",
  1302: "Unable to reconstruct",
  1303: "reconstructed key is not pub key",
  1304: "Share found in unexpected polynomial",
  1305: "Input is not supported",
  1306: "no encrypted share store for share exists",
  1307: "Share doesn't exist",
  1308: "Share was deleted",
  // lock
  1401: "Unable to acquire lock",
  1402: "Unable to release lock",
  // auth metadata
  1501: "privkey unavailable",
  1502: "metadata pubkey unavailable",
  1503: "getAuthMetadata errored",
  1504: "setAuthMetadata errored",
  1601: "delete1OutOf1 requires manualSync=true"
});
var CoreError$1 = CoreError;

function generatePrivateBN() {
  return secp256k1.genKeyPair().getPrivate();
}
const generateEmptyBNArray = length => Array.from({
  length
}, () => new BN(0));
const denominator = (i, innerPoints) => {
  let result = new BN(1);
  const xi = innerPoints[i].x;
  for (let j = innerPoints.length - 1; j >= 0; j -= 1) {
    if (i !== j) {
      let tmp = new BN(xi);
      tmp = tmp.sub(innerPoints[j].x);
      tmp = tmp.umod(secp256k1.curve.n);
      result = result.mul(tmp);
      result = result.umod(secp256k1.curve.n);
    }
  }
  return result;
};
const interpolationPoly = (i, innerPoints) => {
  let coefficients = generateEmptyBNArray(innerPoints.length);
  const d = denominator(i, innerPoints);
  if (d.cmp(new BN(0)) === 0) {
    throw CoreError$1.default("Denominator for interpolationPoly is 0");
  }
  coefficients[0] = d.invm(secp256k1.curve.n);
  for (let k = 0; k < innerPoints.length; k += 1) {
    const newCoefficients = generateEmptyBNArray(innerPoints.length);
    if (k !== i) {
      let j;
      if (k < i) {
        j = k + 1;
      } else {
        j = k;
      }
      j -= 1;
      for (; j >= 0; j -= 1) {
        newCoefficients[j + 1] = newCoefficients[j + 1].add(coefficients[j]);
        newCoefficients[j + 1] = newCoefficients[j + 1].umod(secp256k1.curve.n);
        let tmp = new BN(innerPoints[k].x);
        tmp = tmp.mul(coefficients[j]);
        tmp = tmp.umod(secp256k1.curve.n);
        newCoefficients[j] = newCoefficients[j].sub(tmp);
        newCoefficients[j] = newCoefficients[j].umod(secp256k1.curve.n);
      }
      coefficients = newCoefficients;
    }
  }
  return coefficients;
};
const pointSort = innerPoints => {
  const pointArrClone = [...innerPoints];
  pointArrClone.sort((a, b) => a.x.cmp(b.x));
  return pointArrClone;
};
const lagrange = unsortedPoints => {
  const sortedPoints = pointSort(unsortedPoints);
  const polynomial = generateEmptyBNArray(sortedPoints.length);
  for (let i = 0; i < sortedPoints.length; i += 1) {
    const coefficients = interpolationPoly(i, sortedPoints);
    for (let k = 0; k < sortedPoints.length; k += 1) {
      let tmp = new BN(sortedPoints[i].y);
      tmp = tmp.mul(coefficients[k]);
      polynomial[k] = polynomial[k].add(tmp);
      polynomial[k] = polynomial[k].umod(secp256k1.curve.n);
    }
  }
  return new Polynomial(polynomial);
};
function lagrangeInterpolatePolynomial(points) {
  return lagrange(points);
}
function lagrangeInterpolation(shares, nodeIndex) {
  if (shares.length !== nodeIndex.length) {
    throw CoreError$1.default("shares not equal to nodeIndex length in lagrangeInterpolation");
  }
  let secret = new BN(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new BN(1);
    let lower = new BN(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(secp256k1.curve.n);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(secp256k1.curve.n);
        lower = lower.mul(temp).umod(secp256k1.curve.n);
      }
    }
    let delta = upper.mul(lower.invm(secp256k1.curve.n)).umod(secp256k1.curve.n);
    delta = delta.mul(shares[i]).umod(secp256k1.curve.n);
    secret = secret.add(delta);
  }
  return secret.umod(secp256k1.curve.n);
}

// generateRandomPolynomial - determinisiticShares are assumed random
function generateRandomPolynomial(degree, secret, deterministicShares) {
  let actualS = secret;
  if (!secret) {
    actualS = generatePrivateExcludingIndexes([new BN(0)]);
  }
  if (!deterministicShares) {
    const poly = [actualS];
    for (let i = 0; i < degree; i += 1) {
      const share = generatePrivateExcludingIndexes(poly);
      poly.push(share);
    }
    return new Polynomial(poly);
  }
  if (!Array.isArray(deterministicShares)) {
    throw CoreError$1.default("deterministic shares in generateRandomPolynomial should be an array");
  }
  if (deterministicShares.length > degree) {
    throw CoreError$1.default("deterministicShares in generateRandomPolynomial should be less or equal than degree to ensure an element of randomness");
  }
  const points = {};
  deterministicShares.forEach(share => {
    points[share.shareIndex.toString("hex")] = new Point(share.shareIndex, share.share);
  });
  for (let i = 0; i < degree - deterministicShares.length; i += 1) {
    let shareIndex = generatePrivateExcludingIndexes([new BN(0)]);
    while (points[shareIndex.toString("hex")] !== undefined) {
      shareIndex = generatePrivateExcludingIndexes([new BN(0)]);
    }
    points[shareIndex.toString("hex")] = new Point(shareIndex, generatePrivateBN());
  }
  points["0"] = new Point(new BN(0), actualS);
  return lagrangeInterpolatePolynomial(Object.values(points));
}

//  2 + 3x = y | secret for index 1 is 5 >>> g^5 is the commitment | now we have g^2, g^3 and 1, |
function polyCommitmentEval(polyCommitments, index) {
  // convert to base points, this is badly written, its the only way to access the point rn zzz TODO: refactor
  const basePtPolyCommitments = [];
  for (let i = 0; i < polyCommitments.length; i += 1) {
    const key = secp256k1.keyFromPublic({
      x: polyCommitments[i].x.toString("hex"),
      y: polyCommitments[i].y.toString("hex")
    }, "");
    basePtPolyCommitments.push(key.getPublic());
  }
  let shareCommitment = basePtPolyCommitments[0];
  for (let i = 1; i < basePtPolyCommitments.length; i += 1) {
    const factor = index.pow(new BN(i)).umod(secp256k1.n);
    const e = basePtPolyCommitments[i].mul(factor);
    shareCommitment = shareCommitment.add(e);
  }
  return new Point(shareCommitment.getX(), shareCommitment.getY());
}

class Metadata {
  constructor(input) {
    _defineProperty(this, "pubKey", void 0);
    _defineProperty(this, "publicPolynomials", void 0);
    _defineProperty(this, "publicShares", void 0);
    // Tuple of PolyID and array of ShareIndexes
    _defineProperty(this, "polyIDList", void 0);
    _defineProperty(this, "generalStore", void 0);
    _defineProperty(this, "tkeyStore", void 0);
    _defineProperty(this, "scopedStore", void 0);
    _defineProperty(this, "nonce", void 0);
    _defineProperty(this, "tssKeyTypes", void 0);
    _defineProperty(this, "tssNonces", void 0);
    _defineProperty(this, "tssPolyCommits", void 0);
    _defineProperty(this, "factorPubs", void 0);
    _defineProperty(this, "factorEncs", void 0);
    this.publicPolynomials = {};
    this.publicShares = {};
    this.generalStore = {};
    this.tkeyStore = {};
    this.scopedStore = {};
    this.pubKey = input;
    this.polyIDList = [];
    this.nonce = 0;
    this.tssKeyTypes = {};
    this.tssPolyCommits = {};
    this.tssNonces = {};
    this.factorPubs = {};
    this.factorEncs = {};
  }
  static fromJSON(value) {
    const {
      pubKey,
      polyIDList,
      generalStore,
      tkeyStore,
      scopedStore,
      nonce,
      tssKeyTypes,
      tssPolyCommits,
      tssNonces,
      factorPubs,
      factorEncs
    } = value;
    const point = Point.fromSEC1(secp256k1, pubKey);
    const metadata = new Metadata(point);
    const unserializedPolyIDList = [];
    if (generalStore) metadata.generalStore = generalStore;
    if (tkeyStore) metadata.tkeyStore = tkeyStore;
    if (scopedStore) metadata.scopedStore = scopedStore;
    if (nonce) metadata.nonce = nonce;
    if (tssKeyTypes) {
      metadata.tssKeyTypes = {};
      for (const key in tssKeyTypes) {
        metadata.tssKeyTypes[key] = tssKeyTypes[key];
      }
    }
    if (tssPolyCommits) {
      metadata.tssPolyCommits = {};
      for (const key in tssPolyCommits) {
        metadata.tssPolyCommits[key] = tssPolyCommits[key].map(obj => new Point(obj.x, obj.y));
      }
    }
    if (tssNonces) {
      metadata.tssNonces = {};
      for (const key in tssNonces) {
        metadata.tssNonces[key] = tssNonces[key];
      }
    }
    if (factorPubs) {
      metadata.factorPubs = {};
      for (const key in factorPubs) {
        metadata.factorPubs[key] = factorPubs[key].map(obj => new Point(obj.x, obj.y));
      }
    }
    if (factorEncs) metadata.factorEncs = factorEncs;
    for (let i = 0; i < polyIDList.length; i += 1) {
      const serializedPolyID = polyIDList[i];
      const arrPolyID = serializedPolyID.split("|");
      const zeroIndex = arrPolyID.findIndex(v => v === "0x0");
      const firstHalf = arrPolyID.slice(0, zeroIndex);
      const secondHalf = arrPolyID.slice(zeroIndex + 1, arrPolyID.length);
      // for publicPolynomials
      const pubPolyID = firstHalf.join("|");
      const pointCommitments = [];
      firstHalf.forEach(compressedCommitment => {
        pointCommitments.push(Point.fromCompressedPub(compressedCommitment));
      });
      const publicPolynomial = new PublicPolynomial(pointCommitments);
      metadata.publicPolynomials[pubPolyID] = publicPolynomial;

      // for polyIDList
      unserializedPolyIDList.push([pubPolyID, secondHalf]);
    }
    metadata.polyIDList = unserializedPolyIDList;
    return metadata;
  }
  getShareIndexesForPolynomial(polyID) {
    const matchingPolyIDs = this.polyIDList.filter(tuple => tuple[0] === polyID);
    if (matchingPolyIDs.length < 1) {
      throw CoreError$1.default("there is no matching polyID");
    } else if (matchingPolyIDs.length > 1) {
      throw CoreError$1.default("there is more than one matching polyID");
    }
    return matchingPolyIDs[0][1];
  }
  getLatestPublicPolynomial() {
    return this.publicPolynomials[this.polyIDList[this.polyIDList.length - 1][0]];
  }
  addPublicShare(polynomialID, publicShare) {
    if (!(polynomialID in this.publicShares)) {
      this.publicShares[polynomialID] = {};
    }
    this.publicShares[polynomialID][publicShare.shareIndex.toString("hex")] = publicShare;
  }
  setGeneralStoreDomain(key, obj) {
    this.generalStore[key] = obj;
  }
  getGeneralStoreDomain(key) {
    return this.generalStore[key];
  }
  deleteGeneralStoreDomain(key) {
    delete this.generalStore[key];
  }
  setTkeyStoreDomain(key, arr) {
    this.tkeyStore[key] = arr;
  }
  getTkeyStoreDomain(key) {
    return this.tkeyStore[key];
  }

  // appends shares and public polynomial to metadata.
  // should represent a generation of share or edit of threshold
  addFromPolynomialAndShares(polynomial, shares) {
    const publicPolynomial = polynomial.getPublicPolynomial();
    const polyID = publicPolynomial.getPolynomialID();
    this.publicPolynomials[polyID] = publicPolynomial;
    const shareIndexArr = [];
    if (Array.isArray(shares)) {
      for (let i = 0; i < shares.length; i += 1) {
        this.addPublicShare(publicPolynomial.getPolynomialID(), shares[i].getPublicShare());
        shareIndexArr.push(shares[i].shareIndex.toString("hex"));
      }
    } else {
      for (const k in shares) {
        if (Object.prototype.hasOwnProperty.call(shares, k)) {
          this.addPublicShare(publicPolynomial.getPolynomialID(), shares[k].getPublicShare());
          shareIndexArr.push(shares[k].shareIndex.toString("hex"));
        }
      }
    }
    this.polyIDList.push([polyID, shareIndexArr]);
  }
  setScopedStore(domain, data) {
    this.scopedStore[domain] = data;
  }
  async getEncryptedShare(shareStore) {
    const pubShare = shareStore.share.getPublicShare();
    const encryptedShareStore = this.scopedStore.encryptedShares;
    if (!encryptedShareStore) {
      throw CoreError$1.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const encryptedShare = encryptedShareStore[pubShare.shareCommitment.x.toString("hex")];
    if (!encryptedShare) {
      throw CoreError$1.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const rawDecrypted = await decrypt(toPrivKeyECC(shareStore.share.share), encryptedShare);
    return ShareStore.fromJSON(JSON.parse(rawDecrypted.toString()));
  }
  getShareDescription() {
    return this.getGeneralStoreDomain("shareDescriptions");
  }
  addShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions") || {};
    if (currentSD[shareIndex]) {
      currentSD[shareIndex].push(description);
    } else {
      currentSD[shareIndex] = [description];
    }
    this.setGeneralStoreDomain("shareDescriptions", currentSD);
  }
  deleteShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(description);
    if (index > -1) {
      currentSD[shareIndex].splice(index, 1);
    } else {
      throw CoreError$1.default(`No share description found for the given shareIndex: ${shareIndex} 
        and description: ${description}`);
    }
  }
  updateShareDescription(shareIndex, oldDescription, newDescription) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(oldDescription);
    if (index > -1) {
      currentSD[shareIndex][index] = newDescription;
    } else {
      throw CoreError$1.default(`No share description found for the given shareIndex:
        ${shareIndex} and description: ${oldDescription}`);
    }
  }
  shareToShareStore(share) {
    const pubkey = getPubKeyPoint(share);
    for (let i = this.polyIDList.length - 1; i >= 0; i -= 1) {
      const el = this.polyIDList[i][0];
      for (let t = 0; t < this.polyIDList[i][1].length; t += 1) {
        const shareIndex = this.polyIDList[i][1][t];
        // find pubshare in cache if its there
        let pubShare;
        if (this.publicShares[el]) {
          if (this.publicShares[el][shareIndex]) {
            pubShare = this.publicShares[el][shareIndex];
          }
        }

        // if not reconstruct
        if (!pubShare) {
          pubShare = new PublicShare(shareIndex, polyCommitmentEval(this.publicPolynomials[el].polynomialCommitments, new BN(shareIndex, "hex")));
        }
        if (pubShare.shareCommitment.x.eq(pubkey.x) && pubShare.shareCommitment.y.eq(pubkey.y)) {
          const tempShare = new Share(pubShare.shareIndex, share);
          return new ShareStore(tempShare, el);
        }
      }
    }
    {
      throw CoreError$1.fromCode(1307);
    }
  }
  clone() {
    return Metadata.fromJSON(JSON.parse(stringify(this)));
  }
  toJSON() {
    // squash data to serialized polyID according to spec
    const serializedPolyIDList = [];
    for (let i = 0; i < this.polyIDList.length; i += 1) {
      const polyID = this.polyIDList[i][0];
      const shareIndexes = this.polyIDList[i][1];
      const sortedShareIndexes = shareIndexes.sort((a, b) => new BN(a, "hex").cmp(new BN(b, "hex")));
      const serializedPolyID = polyID.split(`|`).concat("0x0").concat(...sortedShareIndexes).join("|");
      serializedPolyIDList.push(serializedPolyID);
    }
    return _objectSpread(_objectSpread(_objectSpread(_objectSpread(_objectSpread({
      pubKey: this.pubKey.toSEC1(secp256k1, true).toString("hex"),
      polyIDList: serializedPolyIDList,
      scopedStore: this.scopedStore,
      generalStore: this.generalStore,
      tkeyStore: this.tkeyStore,
      nonce: this.nonce
    }, this.tssKeyTypes && {
      tssKeyTypes: this.tssKeyTypes
    }), this.tssNonces && {
      tssNonces: this.tssNonces
    }), this.tssPolyCommits && {
      tssPolyCommits: this.tssPolyCommits
    }), this.factorPubs && {
      factorPubs: this.factorPubs
    }), this.factorEncs && {
      factorEncs: this.factorEncs
    });
  }

  /**
   * Updates the TSS metadata for the given tag.
   */
  updateTSSData(tssData) {
    const {
      tssKeyType,
      tssTag,
      tssNonce,
      tssPolyCommits,
      factorPubs,
      factorEncs
    } = tssData;
    if (tssKeyType) this.tssKeyTypes[tssTag] = tssKeyType;
    if (tssNonce !== undefined) this.tssNonces[tssTag] = tssNonce;
    if (tssPolyCommits) this.tssPolyCommits[tssTag] = tssPolyCommits;
    if (factorPubs) this.factorPubs[tssTag] = factorPubs;
    if (factorEncs) this.factorEncs[tssTag] = factorEncs;
  }
}
var Metadata$1 = Metadata;

class AuthMetadata {
  constructor(metadata, privKey) {
    _defineProperty(this, "metadata", void 0);
    _defineProperty(this, "privKey", void 0);
    this.metadata = metadata;
    this.privKey = privKey;
  }
  static fromJSON(value) {
    const {
      data,
      sig
    } = value;
    if (!data) throw CoreError$1.metadataUndefined();
    const m = Metadata$1.fromJSON(data);
    if (!m.pubKey) throw CoreError$1.metadataPubKeyUnavailable();
    const keyPair = secp256k1.keyFromPublic(m.pubKey.toSEC1(secp256k1));
    if (!keyPair.verify(stripHexPrefix(keccak256(Buffer.from(stringify(data), "utf8"))), sig)) {
      throw CoreError$1.default("Signature not valid for returning metadata");
    }
    return new AuthMetadata(m);
  }
  toJSON() {
    const data = this.metadata;
    if (!this.privKey) throw CoreError$1.privKeyUnavailable();
    const k = toPrivKeyEC(this.privKey);
    const sig = k.sign(stripHexPrefix(keccak256(Buffer.from(stringify(data), "utf8"))));
    return {
      data,
      sig: sig.toDER("hex")
    };
  }
}
var AuthMetadata$1 = AuthMetadata;

const ed25519SeedConst = "ed25519Seed";

// TODO: handle errors for get and set with retries

class ThresholdKey {
  constructor(args) {
    _defineProperty(this, "modules", void 0);
    _defineProperty(this, "enableLogging", void 0);
    _defineProperty(this, "serviceProvider", void 0);
    _defineProperty(this, "storageLayer", void 0);
    _defineProperty(this, "shares", void 0);
    _defineProperty(this, "lastFetchedCloudMetadata", void 0);
    _defineProperty(this, "metadata", void 0);
    _defineProperty(this, "manualSync", void 0);
    _defineProperty(this, "_localMetadataTransitions", void 0);
    _defineProperty(this, "_refreshMiddleware", void 0);
    _defineProperty(this, "_reconstructKeyMiddleware", void 0);
    _defineProperty(this, "_shareSerializationMiddleware", void 0);
    _defineProperty(this, "storeDeviceShare", void 0);
    _defineProperty(this, "haveWriteMetadataLock", void 0);
    _defineProperty(this, "serverTimeOffset", 0);
    // secp256k1 key
    _defineProperty(this, "privKey", void 0);
    _defineProperty(this, "_ed25519Seed", void 0);
    const {
      enableLogging = false,
      modules = {},
      serviceProvider,
      storageLayer,
      manualSync = false,
      serverTimeOffset
    } = args || {};
    this.enableLogging = enableLogging;
    this.serviceProvider = serviceProvider;
    this.storageLayer = storageLayer;
    this.modules = modules;
    this.shares = {};
    this.privKey = undefined;
    this.manualSync = manualSync;
    this._refreshMiddleware = {};
    this._reconstructKeyMiddleware = {};
    this._shareSerializationMiddleware = undefined;
    this.storeDeviceShare = undefined;
    this._localMetadataTransitions = [[], []];
    this.setModuleReferences(); // Providing ITKeyApi access to modules
    this.haveWriteMetadataLock = "";
    this.serverTimeOffset = serverTimeOffset;
  }
  get secp256k1Key() {
    if (typeof this.privKey !== "undefined") {
      return this.privKey;
    }
    return null;
  }
  get ed25519Key() {
    if (typeof this._ed25519Seed !== "undefined") {
      return this._ed25519Seed;
    }
    return null;
  }
  set secp256k1Key(privKey) {
    this.privKey = privKey;
  }
  set ed25519Key(seed) {
    this._ed25519Seed = seed;
  }
  static async fromJSON(value, args) {
    const {
      enableLogging,
      privKey,
      metadata,
      shares,
      _localMetadataTransitions,
      manualSync,
      lastFetchedCloudMetadata,
      serverTimeOffset
    } = value;
    const {
      storageLayer,
      serviceProvider,
      modules
    } = args;
    const tb = new ThresholdKey({
      enableLogging,
      storageLayer,
      serviceProvider,
      modules,
      manualSync,
      serverTimeOffset
    });
    if (privKey) tb.privKey = new BN(privKey, "hex");
    for (const key in shares) {
      if (Object.prototype.hasOwnProperty.call(shares, key)) {
        const shareStoreMapElement = shares[key];
        for (const shareElementKey in shareStoreMapElement) {
          if (Object.prototype.hasOwnProperty.call(shareStoreMapElement, shareElementKey)) {
            const shareStore = shareStoreMapElement[shareElementKey];
            shareStoreMapElement[shareElementKey] = ShareStore.fromJSON(shareStore);
          }
        }
      }
    }
    tb.shares = shares;

    // switch to deserialize local metadata transition based on Object.keys() of authMetadata, ShareStore's and, IMessageMetadata
    const AuthMetadataKeys = Object.keys(JSON.parse(stringify(new AuthMetadata$1(new Metadata$1(new Point("0", "0")), new BN("0", "hex")))));
    const ShareStoreKeys = Object.keys(JSON.parse(stringify(new ShareStore(new Share("0", "0"), ""))));
    const sampleMessageMetadata = {
      message: "Sample message",
      dateAdded: Date.now()
    };
    const MessageMetadataKeys = Object.keys(sampleMessageMetadata);
    const localTransitionShares = [];
    const localTransitionData = [];
    _localMetadataTransitions[0].forEach((x, index) => {
      if (x) {
        localTransitionShares.push(new BN(x, "hex"));
      } else {
        localTransitionShares.push(undefined);
      }
      const keys = Object.keys(_localMetadataTransitions[1][index]);
      if (keys.length === AuthMetadataKeys.length && keys.every(val => AuthMetadataKeys.includes(val))) {
        const tempAuth = AuthMetadata$1.fromJSON(_localMetadataTransitions[1][index]);
        tempAuth.privKey = privKey;
        localTransitionData.push(tempAuth);
      } else if (keys.length === ShareStoreKeys.length && keys.every(val => ShareStoreKeys.includes(val))) {
        localTransitionData.push(ShareStore.fromJSON(_localMetadataTransitions[1][index]));
      } else if (keys.length === MessageMetadataKeys.length && keys.every(val => MessageMetadataKeys.includes(val))) {
        localTransitionData.push(_localMetadataTransitions[1][index]);
      } else {
        throw CoreError$1.default("fromJSON failed. Could not deserialise _localMetadataTransitions");
      }
    });
    if (metadata || lastFetchedCloudMetadata) {
      let tempMetadata;
      let tempCloud;
      let shareToUseForSerialization;

      // if service provider key is missing, we should initialize with one of the existing shares
      // TODO: fix for deleted share
      if (tb.serviceProvider.postboxKey.toString("hex") === "0") {
        const latestPolyIDOnCloud = Metadata$1.fromJSON(lastFetchedCloudMetadata).getLatestPublicPolynomial().getPolynomialID();
        const shareIndexesExistInSDK = Object.keys(shares[latestPolyIDOnCloud]);
        const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
        if (shareIndexesExistInSDK.length >= 1) {
          shareToUseForSerialization = shares[latestPolyIDOnCloud][randomIndex];
        }
      }
      if (metadata) tempMetadata = Metadata$1.fromJSON(metadata);
      if (lastFetchedCloudMetadata) tempCloud = Metadata$1.fromJSON(lastFetchedCloudMetadata);
      await tb.initialize({
        neverInitializeNewKey: true,
        transitionMetadata: tempMetadata,
        previouslyFetchedCloudMetadata: tempCloud,
        previousLocalMetadataTransitions: [localTransitionShares, localTransitionData],
        withShare: shareToUseForSerialization
      });
    } else {
      await tb.initialize({
        neverInitializeNewKey: true
      });
    }
    return tb;
  }
  getStorageLayer() {
    return this.storageLayer;
  }
  getMetadata() {
    if (typeof this.metadata !== "undefined") {
      return this.metadata;
    }
    throw CoreError$1.metadataUndefined();
  }
  async initialize(params) {
    // setup initial params/states
    const p = params || {};
    if (p.delete1OutOf1 && !this.manualSync) throw CoreError$1.delete1OutOf1OnlyManualSync();
    const {
      withShare,
      importKey,
      importEd25519Seed,
      neverInitializeNewKey,
      transitionMetadata,
      previouslyFetchedCloudMetadata,
      previousLocalMetadataTransitions
    } = p;
    const previousLocalMetadataTransitionsExists = previousLocalMetadataTransitions && previousLocalMetadataTransitions[0].length > 0 && previousLocalMetadataTransitions[1].length > 0;
    const reinitializing = transitionMetadata && previousLocalMetadataTransitionsExists; // are we reinitializing the SDK?
    // in the case we're reinitializing whilst newKeyAssign has not been synced
    const reinitializingWithNewKeyAssign = reinitializing && previouslyFetchedCloudMetadata === undefined;
    let shareStore;
    if (withShare instanceof ShareStore) {
      shareStore = withShare;
    } else if (typeof withShare === "object") {
      shareStore = ShareStore.fromJSON(withShare);
    } else if (!withShare) {
      // default to use service provider
      // first we see if a share has been kept for us
      const spIncludeLocalMetadataTransitions = reinitializingWithNewKeyAssign;
      const spLocalMetadataTransitions = reinitializingWithNewKeyAssign ? previousLocalMetadataTransitions : undefined;
      const rawServiceProviderShare = await this.getGenericMetadataWithTransitionStates({
        serviceProvider: this.serviceProvider,
        includeLocalMetadataTransitions: spIncludeLocalMetadataTransitions,
        _localMetadataTransitions: spLocalMetadataTransitions,
        fromJSONConstructor: {
          fromJSON(val) {
            return val;
          }
        }
      });
      const noKeyFound = rawServiceProviderShare;
      if (noKeyFound.message === KEY_NOT_FOUND) {
        if (neverInitializeNewKey) {
          throw CoreError$1.default("key has not been generated yet");
        }

        // no metadata set, assumes new user
        // check for serviceprovider migratableKey for import key from service provider for new user
        // provided no importKey is provided ( importKey take precedent )
        if (this.serviceProvider.migratableKey && !(importKey || importEd25519Seed)) {
          // importkey from server provider need to be atomic, hence manual sync is required.
          const tempStateManualSync = this.manualSync; // temp store manual sync flag
          this.manualSync = true; // Setting this as true since _initializeNewKey has a check where for importkey from server provider need to be atomic, hence manual sync is required.
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: this.serviceProvider.migratableKey,
            delete1OutOf1: true
          });
          if (!tempStateManualSync) await this.syncLocalMetadataTransitions(); // Only sync if we were not in manual sync mode, if manual sync is set by developer, they should handle it themselves
          // restore manual sync flag
          this.manualSync = tempStateManualSync;
        } else {
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: importKey,
            delete1OutOf1: p.delete1OutOf1,
            importEd25519Seed
          });
        }

        // return after created new tkey account ( skip other steps)
        return this.getKeyDetails();
      }
      // else we continue with catching up share and metadata
      shareStore = ShareStore.fromJSON(rawServiceProviderShare);
    } else {
      throw CoreError$1.default("Input is not supported");
    }

    // We determine the latest metadata on the SDK and if there has been
    // needed transitions to include
    let currentMetadata;
    let latestCloudMetadata;
    // we fetch the latest metadata for the account from the share
    let latestShareDetails;
    try {
      latestShareDetails = await this.catchupToLatestShare({
        shareStore
      });
    } catch (error) {
      // check if error is not the undefined error
      // if so we don't throw immediately incase there is valid transition metadata
      const err = error;
      const noMetadataExistsForShare = err.code === 1503;
      if (!noMetadataExistsForShare || !reinitializing) {
        throw err;
      }
    }

    // lets check if the cloud metadata has been updated or not from previously if we are reinitializing
    if (reinitializing && !reinitializingWithNewKeyAssign) {
      if (previouslyFetchedCloudMetadata.nonce < latestShareDetails.shareMetadata.nonce) {
        throw CoreError$1.fromCode(1104);
      } else if (previouslyFetchedCloudMetadata.nonce > latestShareDetails.shareMetadata.nonce) {
        throw CoreError$1.fromCode(1105);
      }
      latestCloudMetadata = previouslyFetchedCloudMetadata;
    } else {
      latestCloudMetadata = latestShareDetails ? latestShareDetails.shareMetadata.clone() : undefined;
    }

    // If we've been provided with transition metadata we use that as the current metadata instead
    // as we want to maintain state before and after serialization.
    // (Given that the checks for cloud metadata pass)
    if (reinitializing) {
      currentMetadata = transitionMetadata;
      this._localMetadataTransitions = previousLocalMetadataTransitions;
    } else {
      currentMetadata = latestShareDetails.shareMetadata;
    }
    this.lastFetchedCloudMetadata = latestCloudMetadata;
    this.metadata = currentMetadata;
    const latestShare = latestShareDetails ? latestShareDetails.latestShare : shareStore;
    this.inputShareStore(latestShare);
    if (importEd25519Seed && this.getEd25519PublicKey()) {
      throw CoreError$1.default("Ed25119 key already exists");
    }

    // initialize modules
    await this.initializeModules();
    return this.getKeyDetails();
  }

  /**
   * catchupToLatestShare recursively loops fetches metadata of the provided share and checks if there is an encrypted share for it.
   * @param shareStore - share to start of with
   * @param polyID - if specified, polyID to refresh to if it exists
   */
  async catchupToLatestShare(params) {
    const {
      shareStore,
      polyID,
      includeLocalMetadataTransitions
    } = params;
    let shareMetadata;
    try {
      shareMetadata = await this.getAuthMetadata({
        privKey: shareStore.share.share,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      // delete share error
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      const prettyError = await prettyPrintError(err);
      throw CoreError$1.authMetadataGetUnavailable(`, ${prettyError.message}`);
    }
    try {
      // if matches specified polyID return it
      if (polyID) {
        if (shareStore.polynomialID === polyID) {
          return {
            latestShare: shareStore,
            shareMetadata
          };
        }
      }
      const nextShare = await shareMetadata.getEncryptedShare(shareStore);
      return await this.catchupToLatestShare({
        shareStore: nextShare,
        polyID,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      // delete share error
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      return {
        latestShare: shareStore,
        shareMetadata
      };
    }
  }
  async reconstructKey(_reconstructKeyMiddleware = true) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const requiredThreshold = pubPoly.getThreshold();
    const pubPolyID = pubPoly.getPolynomialID();

    // check if we have enough shares to meet threshold
    let sharesLeft = requiredThreshold;
    // we don't just check the latest poly but
    // we check if the shares on previous polynomials in our stores have the share indexes we require
    const fullShareList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const shareIndexesRequired = {};
    for (let i = 0; i < fullShareList.length; i += 1) {
      shareIndexesRequired[fullShareList[i]] = true;
    }
    const sharesToInput = [];
    for (let z = this.metadata.polyIDList.length - 1; z >= 0 && sharesLeft > 0; z -= 1) {
      const sharesForPoly = this.shares[this.metadata.polyIDList[z][0]];
      if (sharesForPoly) {
        const shareIndexesForPoly = Object.keys(sharesForPoly);
        for (let k = 0; k < shareIndexesForPoly.length && sharesLeft > 0; k += 1) {
          if (shareIndexesForPoly[k] in shareIndexesRequired) {
            const currentShareForPoly = sharesForPoly[shareIndexesForPoly[k]];
            if (currentShareForPoly.polynomialID === pubPolyID) {
              sharesToInput.push(currentShareForPoly);
            } else {
              const latestShareRes = await this.catchupToLatestShare({
                shareStore: currentShareForPoly,
                polyID: pubPolyID,
                includeLocalMetadataTransitions: true
              });
              if (latestShareRes.latestShare.polynomialID === pubPolyID) {
                sharesToInput.push(latestShareRes.latestShare);
              } else {
                throw new CoreError$1(1304, "Share found in unexpected polynomial"); // Share found in unexpected polynomial
              }
            }
            delete shareIndexesRequired[shareIndexesForPoly[k]];
            sharesLeft -= 1;
          }
        }
      }
    }

    // Input shares to ensure atomicity
    sharesToInput.forEach(share => {
      this.inputShareStore(share);
    });
    if (sharesLeft > 0) {
      throw CoreError$1.unableToReconstruct(` require ${requiredThreshold} but have ${requiredThreshold - sharesLeft}`);
    }
    const polyShares = Object.keys(this.shares[pubPolyID]);
    const shareArr = [];
    const shareIndexArr = [];
    for (let i = 0; i < requiredThreshold; i += 1) {
      shareArr.push(this.shares[pubPolyID][polyShares[i]].share.share);
      shareIndexArr.push(this.shares[pubPolyID][polyShares[i]].share.shareIndex);
    }
    const privKey = lagrangeInterpolation(shareArr, shareIndexArr);
    // check that priv key regenerated is correct
    const reconstructedPubKey = getPubKeyPoint(privKey);
    if (this.metadata.pubKey.x.cmp(reconstructedPubKey.x) !== 0) {
      throw CoreError$1.incorrectReconstruction();
    }
    this.secp256k1Key = privKey;
    const returnObject = {
      allKeys: [privKey]
    };
    if (_reconstructKeyMiddleware && Object.keys(this._reconstructKeyMiddleware).length > 0) {
      // retireve/reconstruct extra keys that live on metadata
      await Promise.all(Object.keys(this._reconstructKeyMiddleware).map(async x => {
        if (Object.prototype.hasOwnProperty.call(this._reconstructKeyMiddleware, x)) {
          const extraKeys = await this._reconstructKeyMiddleware[x]();
          returnObject[x] = extraKeys;
          returnObject.allKeys.push(...extraKeys);
        }
      }));
    }

    // ed25519key
    if (this.getEd25519PublicKey()) {
      const seed = await this.retrieveEd25519Seed();
      if (!seed) {
        throw CoreError$1.default("Ed25519 seed not found");
      }
      this._ed25519Seed = seed;
    }
    return _objectSpread({
      secp256k1Key: privKey,
      ed25519Seed: this._ed25519Seed
    }, returnObject);
  }
  reconstructLatestPoly() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares to reconstruct poly");
    }
    if (new Set(sharesForExistingPoly).size !== sharesForExistingPoly.length) {
      throw CoreError$1.default("share indexes should be unique");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point(new BN(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    return lagrangeInterpolatePolynomial(pointsArr);
  }
  async deleteShare(shareIndex) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const shareIndexToDelete = new BN(shareIndex, "hex");
    const shareToDelete = this.outputShareStore(shareIndexToDelete);
    if (shareIndexToDelete.cmp(new BN("1", "hex")) === 0) {
      throw new CoreError$1(1001, "Unable to delete service provider share");
    }

    // Get existing shares
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const newShareIndexes = [];
    existingShareIndexes.forEach(el => {
      const bn = new BN(el, "hex");
      if (bn.cmp(shareIndexToDelete) !== 0) {
        newShareIndexes.push(bn.toString("hex"));
      }
    });

    // Update shares
    if (existingShareIndexes.length === newShareIndexes.length) {
      throw CoreError$1.default("Share index does not exist in latest polynomial");
    } else if (newShareIndexes.length < pubPoly.getThreshold()) {
      throw CoreError$1.default(`Minimum ${pubPoly.getThreshold()} shares are required for tkey. Unable to delete share`);
    }
    const results = await this._refreshShares(pubPoly.getThreshold(), [...newShareIndexes], previousPolyID);
    const newShareStores = results.shareStores;
    await this.addLocalMetadataTransitions({
      input: [{
        message: SHARE_DELETED,
        dateAdded: Date.now()
      }],
      privKey: [shareToDelete.share.share]
    });
    return {
      newShareStores
    };
  }
  async generateNewShare() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.secp256k1Key) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const existingShareIndexesBN = existingShareIndexes.map(el => new BN(el, "hex"));
    const newShareIndex = new BN(generatePrivateExcludingIndexes(existingShareIndexesBN));
    const results = await this._refreshShares(pubPoly.getThreshold(), [...existingShareIndexes, newShareIndex.toString("hex")], previousPolyID);
    const newShareStores = results.shareStores;
    return {
      newShareStores,
      newShareIndex
    };
  }
  getEd25519PublicKey() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    return result === null || result === void 0 ? void 0 : result.publicKey;
  }
  async retrieveEd25519Seed() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    const seed = await this.decrypt(result.message);
    this._ed25519Seed = seed;
    return seed;
  }
  async addLocalMetadataTransitions(params) {
    const {
      privKey,
      input
    } = params;
    this._localMetadataTransitions[0] = [...this._localMetadataTransitions[0], ...privKey];
    this._localMetadataTransitions[1] = [...this._localMetadataTransitions[1], ...input];
    if (!this.manualSync) await this.syncLocalMetadataTransitions();
  }
  async syncLocalMetadataTransitions() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!(Array.isArray(this._localMetadataTransitions[0]) && this._localMetadataTransitions[0].length > 0)) return;

    // get lock
    let acquiredLock = false;
    if (this.lastFetchedCloudMetadata) {
      await this.acquireWriteMetadataLock();
      acquiredLock = true;
    }
    try {
      await this.storageLayer.setMetadataStream({
        input: this._localMetadataTransitions[1],
        privKey: this._localMetadataTransitions[0],
        serviceProvider: this.serviceProvider
      });
      this._localMetadataTransitions = [[], []];
      this.lastFetchedCloudMetadata = this.metadata.clone();
    } catch (error) {
      const prettyError = await prettyPrintError(error);
      throw CoreError$1.metadataPostFailed(prettyError.message);
    } finally {
      // release lock
      if (acquiredLock) await this.releaseWriteMetadataLock();
    }
  }
  async readMetadata(privKey) {
    return this.storageLayer.getMetadata({
      privKey
    });
  }

  // Returns a new instance of metadata with a clean state. All the previous state will be reset.
  async updateSDK(params) {
    const tb = new ThresholdKey({
      enableLogging: this.enableLogging,
      modules: this.modules,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer,
      manualSync: this.manualSync
    });
    try {
      await tb.initialize({
        neverInitializeNewKey: true,
        withShare: params && params.withShare
      });
    } catch (err) {
      throw CoreError$1.fromCode(1103, `${err.message}`);
    }

    // Delete unnecessary polyIDs and shareStores
    const allPolyIDList = tb.metadata.polyIDList;
    let lastValidPolyID;
    Object.keys(this.shares).forEach(x => {
      if (allPolyIDList.find(id => id[0] === x)) {
        lastValidPolyID = x;
      } else {
        delete this.shares[x];
      }
    });

    // catchup to latest shareStore for all latest available shares.
    // TODO: fix edge cases where shares are deleted in the newer polynomials
    // TODO: maybe assign this.shares directly rather than output and inputsharestore.
    const shareStoresForLastValidPolyID = Object.keys(this.shares[lastValidPolyID]).map(x => tb.inputShareStoreSafe(this.outputShareStore(x, lastValidPolyID)));
    await Promise.all(shareStoresForLastValidPolyID);
    return tb;
  }

  // NOTE: This API will be DEPRECATED in the future in favour of inputShareStoreSafe()
  inputShareStore(shareStore) {
    let ss;
    if (shareStore instanceof ShareStore) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = ShareStore.fromJSON(shareStore);
    } else {
      throw CoreError$1.default("can only add type ShareStore into shares");
    }
    if (!(ss.polynomialID in this.shares)) {
      this.shares[ss.polynomialID] = {};
    }
    this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
  }

  // inputs a share ensuring that the share is the latest share AND metadata is updated to its latest state
  async inputShareStoreSafe(shareStore, autoUpdateMetadata = false) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let ss;
    if (shareStore instanceof ShareStore) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = ShareStore.fromJSON(shareStore);
    } else {
      throw CoreError$1.default("can only add type ShareStore into shares");
    }
    const polynomialId = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    if (ss.polynomialID !== polynomialId) {
      const latestShareRes = await this.catchupToLatestShare({
        shareStore: ss,
        includeLocalMetadataTransitions: true
      });
      // check if the latest share is part of the current tkey instances
      // to avoid random share getting input into metadata
      if (!latestShareRes.shareMetadata.polyIDList.find(tuple => tuple[0] === polynomialId)) {
        throw CoreError$1.fromCode(1307);
      }
      // if latest share's polynomial is not equal with tkey latest polynomial, tkey's metadata is outdated
      if (polynomialId !== latestShareRes.latestShare.polynomialID) {
        if (!autoUpdateMetadata) throw CoreError$1.default(`TKey SDK metadata seems to be outdated because shareIndex: ` + `${latestShareRes.latestShare.share.shareIndex.toString("hex")} has a more recent metadata. Please call updateSDK first`);else this.metadata = latestShareRes.shareMetadata;
      }
      if (!(latestShareRes.latestShare.polynomialID in this.shares)) {
        this.shares[latestShareRes.latestShare.polynomialID] = {};
      }
      this.shares[latestShareRes.latestShare.polynomialID][latestShareRes.latestShare.share.shareIndex.toString("hex")] = latestShareRes.latestShare;
    } else {
      if (!(ss.polynomialID in this.shares)) {
        this.shares[ss.polynomialID] = {};
      }
      this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
    }
  }
  outputShareStore(shareIndex, polyID) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let shareIndexParsed;
    if (typeof shareIndex === "number") {
      shareIndexParsed = new BN(shareIndex);
    } else if (BN.isBN(shareIndex)) {
      shareIndexParsed = shareIndex;
    } else if (typeof shareIndex === "string") {
      shareIndexParsed = new BN(shareIndex, "hex");
    }
    let polyIDToSearch;
    if (polyID) {
      polyIDToSearch = polyID;
    } else {
      polyIDToSearch = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    }
    if (!this.metadata.getShareIndexesForPolynomial(polyIDToSearch).includes(shareIndexParsed.toString("hex"))) {
      throw new CoreError$1(1002, "no such share index created");
    }
    const shareFromStore = this.shares[polyIDToSearch][shareIndexParsed.toString("hex")];
    if (shareFromStore) return shareFromStore;
    const poly = this.reconstructLatestPoly();
    const shareMap = poly.generateShares([shareIndexParsed]);
    return new ShareStore(shareMap[shareIndexParsed.toString("hex")], polyIDToSearch);
  }
  getCurrentShareIndexes() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const latestPolynomial = this.metadata.getLatestPublicPolynomial();
    const latestPolynomialId = latestPolynomial.getPolynomialID();
    const currentShareIndexes = Object.keys(this.shares[latestPolynomialId]);
    return currentShareIndexes;
  }
  getKeyDetails() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const poly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = poly.getPolynomialID();
    const requiredShares = poly.getThreshold() - Object.keys(this.shares[previousPolyID]).length;
    let shareDescriptions = this.metadata.getShareDescription();
    if (shareDescriptions) {
      const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
      shareDescriptions = Object.keys(shareDescriptions).reduce((acc, index) => {
        if (existingShareIndexes.indexOf(index) >= 0) acc[index] = shareDescriptions[index];
        return acc;
      }, {});
    }
    return {
      pubKey: this.metadata.pubKey,
      ed25519PublicKey: this.getEd25519PublicKey(),
      requiredShares,
      threshold: poly.getThreshold(),
      totalShares: this.metadata.getShareIndexesForPolynomial(previousPolyID).length,
      shareDescriptions
    };
  }

  // Auth functions

  generateAuthMetadata(params) {
    const {
      input
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new AuthMetadata$1(input[i], this.privKey));
    }
    return authMetadatas;
  }
  setAuthMetadata(params) {
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadata = new AuthMetadata$1(input, this.privKey);
    return this.storageLayer.setMetadata({
      input: authMetadata,
      serviceProvider,
      privKey
    });
  }
  async setAuthMetadataBulk(params) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new AuthMetadata$1(input[i], this.privKey));
    }
    await this.addLocalMetadataTransitions({
      input: authMetadatas,
      serviceProvider,
      privKey
    });
  }
  async getAuthMetadata(params) {
    const raw = await this.getGenericMetadataWithTransitionStates(_objectSpread(_objectSpread({}, params), {}, {
      fromJSONConstructor: AuthMetadata$1
    }));
    const authMetadata = raw;
    return authMetadata.metadata;
  }

  // fetches the latest metadata potentially searching in local transition states first
  async getGenericMetadataWithTransitionStates(params) {
    if (!(params.serviceProvider && params.serviceProvider.postboxKey.toString("hex") !== "0" || params.privKey)) {
      throw CoreError$1.default("require either serviceProvider or priv key in getGenericMetadataWithTransitionStates");
    }
    if (params.includeLocalMetadataTransitions) {
      const transitions = params._localMetadataTransitions ? params._localMetadataTransitions : this._localMetadataTransitions;
      let index = null;
      for (let i = transitions[0].length - 1; i >= 0; i -= 1) {
        const x = transitions[0][i];
        if (params.privKey && x && x.cmp(params.privKey) === 0) index = i;else if (params.serviceProvider && !x) index = i;
        if (index !== null) break;
      }
      if (index !== null) {
        return transitions[1][index];
      }
    }
    let raw;
    try {
      raw = await this.storageLayer.getMetadata(params);
    } catch (err) {
      const prettyError = await prettyPrintError(err);
      throw CoreError$1.metadataGetFailed(prettyError.message);
    }
    if (raw.message === SHARE_DELETED) {
      throw CoreError$1.fromCode(1308);
    }
    return params.fromJSONConstructor.fromJSON(raw);
  }

  // Lock functions
  async acquireWriteMetadataLock() {
    if (this.haveWriteMetadataLock) return this.metadata.nonce;
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }

    // we check the metadata of a random share we have on the latest polynomial we know that reflects the cloud
    // below we cater for if we have an existing share or need to create the share in the SDK
    let randomShareStore;
    const latestPolyIDOnCloud = this.lastFetchedCloudMetadata.getLatestPublicPolynomial().getPolynomialID();
    const shareIndexesExistInSDK = Object.keys(this.shares[latestPolyIDOnCloud]);
    const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
    if (shareIndexesExistInSDK.length >= 1) {
      randomShareStore = this.shares[latestPolyIDOnCloud][randomIndex];
    } else {
      randomShareStore = this.outputShareStore(randomIndex, latestPolyIDOnCloud);
    }
    const latestRes = await this.catchupToLatestShare({
      shareStore: randomShareStore
    });
    const latestMetadata = latestRes.shareMetadata;

    // read errors for what each means
    if (latestMetadata.nonce > this.lastFetchedCloudMetadata.nonce) {
      throw CoreError$1.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
           being lower than last written metadata nonce (${latestMetadata.nonce}). perhaps update metadata SDK (create new tKey and init)`);
    } else if (latestMetadata.nonce < this.lastFetchedCloudMetadata.nonce) {
      throw CoreError$1.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
      being higher than last written metadata nonce (${latestMetadata.nonce}). this should never happen as it 
      should only ever be updated by getting metadata)`);
    }
    const res = await this.storageLayer.acquireWriteLock({
      privKey: this.privKey
    });
    if (res.status !== 1) throw CoreError$1.acquireLockFailed(`lock cannot be acquired from storage layer status code: ${res.status}`);

    // increment metadata nonce for write session
    // this.metadata.nonce += 1;
    this.haveWriteMetadataLock = res.id;
    return this.metadata.nonce;
  }
  async releaseWriteMetadataLock() {
    if (!this.haveWriteMetadataLock) throw CoreError$1.releaseLockFailed("releaseWriteMetadataLock - don't have metadata lock to release");
    const res = await this.storageLayer.releaseWriteLock({
      privKey: this.privKey,
      id: this.haveWriteMetadataLock
    });
    if (res.status !== 1) throw CoreError$1.releaseLockFailed(`lock cannot be released from storage layer status code: ${res.status}`);
    this.haveWriteMetadataLock = "";
  }

  // Module functions

  async _syncShareMetadata(adjustScopedStore) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const shareArray = this.getAllShareStoresForLatestPolynomial().map(x => x.share.share);
    await this.syncMultipleShareMetadata(shareArray, adjustScopedStore);
  }
  async syncMultipleShareMetadata(shares, adjustScopedStore) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.nonce += 1;
    const newMetadataPromise = shares.map(async share => {
      const newMetadata = this.metadata.clone();
      let specificShareMetadata;
      try {
        specificShareMetadata = await this.getAuthMetadata({
          privKey: share,
          includeLocalMetadataTransitions: true
        });
      } catch (err) {
        const prettyError = await prettyPrintError(err);
        throw CoreError$1.authMetadataGetUnavailable(prettyError.message);
      }
      let scopedStoreToBeSet;
      if (adjustScopedStore) {
        scopedStoreToBeSet = adjustScopedStore(specificShareMetadata.scopedStore);
      } else {
        scopedStoreToBeSet = specificShareMetadata.scopedStore;
      }
      newMetadata.scopedStore = scopedStoreToBeSet;
      return newMetadata;
    });
    const newMetadata = await Promise.all(newMetadataPromise);
    return this.setAuthMetadataBulk({
      input: newMetadata,
      privKey: shares
    });
  }
  _addRefreshMiddleware(moduleName, middleware) {
    this._refreshMiddleware[moduleName] = middleware;
  }
  _addReconstructKeyMiddleware(moduleName, middleware) {
    this._reconstructKeyMiddleware[moduleName] = middleware;
  }
  _addShareSerializationMiddleware(serialize, deserialize) {
    this._shareSerializationMiddleware = {
      serialize,
      deserialize
    };
  }
  _setDeviceStorage(storeDeviceStorage) {
    if (this.storeDeviceShare) {
      throw CoreError$1.default("storeDeviceShare already set");
    }
    this.storeDeviceShare = storeDeviceStorage;
  }
  async addShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.addShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async deleteShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.deleteShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async updateShareDescription(shareIndex, oldDescription, newDescription, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.updateShareDescription(shareIndex, oldDescription, newDescription);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async encrypt(data) {
    if (!this.privKey) throw CoreError$1.privateKeyUnavailable();
    return encrypt(getPubKeyECC(this.privKey), data);
  }
  async decrypt(encryptedMessage) {
    if (!this.privKey) throw CoreError$1.privateKeyUnavailable();
    return decrypt(toPrivKeyECC(this.privKey), encryptedMessage);
  }
  async _setTKeyStoreItem(moduleName, data) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const encryptedData = await this.encrypt(Buffer.from(stringify(data)));
    const duplicateItemIndex = decryptedItems.findIndex(x => x.id === data.id);
    if (duplicateItemIndex > -1) {
      rawTkeyStoreItems[duplicateItemIndex] = encryptedData;
    } else {
      rawTkeyStoreItems.push(encryptedData);
    }

    // update metadataStore
    this.metadata.setTkeyStoreDomain(moduleName, rawTkeyStoreItems);
    await this._syncShareMetadata();
  }
  async _deleteTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const finalItems = decryptedItems.filter(x => x.id !== id);
    this.metadata.setTkeyStoreDomain(moduleName, finalItems);
    await this._syncShareMetadata();
  }
  async getTKeyStore(moduleName) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    return decryptedItems;
  }
  async getTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const item = decryptedItems.find(x => x.id === id);
    return item;
  }

  // Import export shares
  async outputShare(shareIndex, type) {
    const {
      share
    } = this.outputShareStore(shareIndex).share;
    if (!type) return share;
    return this._shareSerializationMiddleware.serialize(share, type);
  }
  async inputShare(share, type) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let shareStore;
    if (!type) shareStore = this.metadata.shareToShareStore(share);else {
      const deserialized = await this._shareSerializationMiddleware.deserialize(share, type);
      shareStore = this.metadata.shareToShareStore(deserialized);
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const fullShareIndexesList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    if (!fullShareIndexesList.includes(shareStore.share.shareIndex.toString("hex"))) {
      throw CoreError$1.default("Latest poly doesn't include this share");
    }
    await this.inputShareStoreSafe(shareStore);
  }
  toJSON() {
    return {
      shares: this.shares,
      enableLogging: this.enableLogging,
      privKey: this.privKey ? this.privKey.toString("hex") : undefined,
      metadata: this.metadata,
      lastFetchedCloudMetadata: this.lastFetchedCloudMetadata,
      _localMetadataTransitions: this._localMetadataTransitions,
      manualSync: this.manualSync,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer
    };
  }
  getAllShareStoresForLatestPolynomial() {
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point(new BN(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    const currentPoly = lagrangeInterpolatePolynomial(pointsArr);
    const allExistingShares = currentPoly.generateShares(existingShareIndexes);
    const shareArray = existingShareIndexes.map(shareIndex => {
      return this.metadata.shareToShareStore(allExistingShares[shareIndex].share);
    });
    return shareArray;
  }

  /// Destructive method. All data will be wiped!
  async CRITICAL_deleteTkey() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (this._localMetadataTransitions[0].length > 0 || this._localMetadataTransitions[1].length > 0) {
      throw CoreError$1.default("Please sync all local state before calling this function");
    }

    // Construct all shares
    const shareArray = this.getAllShareStoresForLatestPolynomial();
    await this.addLocalMetadataTransitions({
      input: [...Array(shareArray.length).fill({
        message: SHARE_DELETED,
        dateAdded: Date.now()
      }), {
        message: KEY_NOT_FOUND
      }],
      privKey: [...shareArray.map(x => x.share.share), undefined]
    });
    await this.syncLocalMetadataTransitions(); // forcesync

    this.privKey = undefined;
    this.metadata = undefined;
    this.shares = {};
    this.lastFetchedCloudMetadata = undefined;
  }
  getApi() {
    return {
      getMetadata: this.getMetadata.bind(this),
      getStorageLayer: this.getStorageLayer.bind(this),
      initialize: this.initialize.bind(this),
      catchupToLatestShare: this.catchupToLatestShare.bind(this),
      _syncShareMetadata: this._syncShareMetadata.bind(this),
      _addRefreshMiddleware: this._addRefreshMiddleware.bind(this),
      _addReconstructKeyMiddleware: this._addReconstructKeyMiddleware.bind(this),
      _addShareSerializationMiddleware: this._addShareSerializationMiddleware.bind(this),
      addShareDescription: this.addShareDescription.bind(this),
      generateNewShare: this.generateNewShare.bind(this),
      inputShareStore: this.inputShareStore.bind(this),
      inputShareStoreSafe: this.inputShareStoreSafe.bind(this),
      outputShareStore: this.outputShareStore.bind(this),
      inputShare: this.inputShare.bind(this),
      outputShare: this.outputShare.bind(this),
      _setDeviceStorage: this._setDeviceStorage.bind(this),
      encrypt: this.encrypt.bind(this),
      decrypt: this.decrypt.bind(this),
      getTKeyStore: this.getTKeyStore.bind(this),
      getTKeyStoreItem: this.getTKeyStoreItem.bind(this),
      _setTKeyStoreItem: this._setTKeyStoreItem.bind(this),
      _deleteTKeyStoreItem: this._deleteTKeyStoreItem.bind(this),
      deleteShare: this.deleteShare.bind(this)
    };
  }
  setModuleReferences() {
    Object.keys(this.modules).map(x => this.modules[x].setModuleReferences(this.getApi()));
  }
  async initializeModules() {
    return Promise.all(Object.keys(this.modules).map(x => this.modules[x].initialize()));
  }
  async _refreshShares(threshold, newShareIndexes, previousPolyID) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (threshold > newShareIndexes.length) {
      throw CoreError$1.default(`threshold should not be greater than share indexes. ${threshold} > ${newShareIndexes.length}`);
    }

    // update metadata nonce
    this.metadata.nonce += 1;
    const poly = generateRandomPolynomial(threshold - 1, this.privKey);
    const shares = poly.generateShares(newShareIndexes);
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[previousPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point(new BN(sharesForExistingPoly[i], "hex"), this.shares[previousPolyID][sharesForExistingPoly[i]].share.share));
    }
    const oldPoly = lagrangeInterpolatePolynomial(pointsArr);
    const shareIndexesNeedingEncryption = [];
    for (let index = 0; index < existingShareIndexes.length; index += 1) {
      const shareIndexHex = existingShareIndexes[index];
      // define shares that need encryption/relaying
      if (newShareIndexes.includes(shareIndexHex)) {
        shareIndexesNeedingEncryption.push(shareIndexHex);
      }
    }

    // add metadata new poly to metadata
    this.metadata.addFromPolynomialAndShares(poly, shares);

    // change to share stores for public storing
    const oldShareStores = {};
    const newShareStores = {};
    const polyID = poly.getPolynomialID();
    newShareIndexes.forEach(shareIndexHex => {
      newShareStores[shareIndexHex] = new ShareStore(shares[shareIndexHex], polyID);
    });

    // evaluate oldPoly for old shares and set new metadata with encrypted share for new polynomial

    const m = this.metadata.clone();
    const newScopedStore = {};
    const sharesToPush = await Promise.all(shareIndexesNeedingEncryption.map(async shareIndex => {
      const oldShare = oldPoly.polyEval(new BN(shareIndex, "hex"));
      const encryptedShare = await encrypt(getPubKeyECC(oldShare), Buffer.from(JSON.stringify(newShareStores[shareIndex])));
      newScopedStore[getPubKeyPoint(oldShare).x.toString("hex")] = encryptedShare;
      oldShareStores[shareIndex] = new ShareStore(new Share(shareIndex, oldShare), previousPolyID);
      return oldShare;
    }));
    m.setScopedStore("encryptedShares", newScopedStore);
    const metadataToPush = Array(sharesToPush.length).fill(m);

    // run refreshShare middleware
    // If a shareIndex is left out during refresh shares, we assume that it being explicitly deleted.
    for (const moduleName in this._refreshMiddleware) {
      if (Object.prototype.hasOwnProperty.call(this._refreshMiddleware, moduleName)) {
        const adjustedGeneralStore = this._refreshMiddleware[moduleName](this.metadata.getGeneralStoreDomain(moduleName), oldShareStores, newShareStores);
        if (!adjustedGeneralStore) this.metadata.deleteGeneralStoreDomain(moduleName);else this.metadata.setGeneralStoreDomain(moduleName, adjustedGeneralStore);
      }
    }
    const newShareMetadataToPush = [];
    const newShareStoreSharesToPush = newShareIndexes.map(shareIndex => {
      const me = this.metadata.clone();
      newShareMetadataToPush.push(me);
      return newShareStores[shareIndex].share.share;
    });
    const AuthMetadatas = this.generateAuthMetadata({
      input: [...metadataToPush, ...newShareMetadataToPush]
    });

    // Combine Authmetadata and service provider ShareStore
    await this.addLocalMetadataTransitions({
      input: [...AuthMetadatas, newShareStores["1"]],
      privKey: [...sharesToPush, ...newShareStoreSharesToPush, undefined]
    });

    // update this.shares with these new shares
    for (let index = 0; index < newShareIndexes.length; index += 1) {
      const shareIndex = newShareIndexes[index];
      this.inputShareStore(newShareStores[shareIndex]);
    }
    // await this.releaseWriteMetadataLock();
    return {
      shareStores: newShareStores
    };
  }
  async _initializeNewKey({
    determinedShare,
    initializeModules,
    importedKey,
    importEd25519Seed,
    delete1OutOf1
  } = {}) {
    if (!importedKey) {
      const tmpPriv = generatePrivateBN();
      this.secp256k1Key = tmpPriv;
    } else {
      this.secp256k1Key = importedKey;
    }

    // create a random poly and respective shares
    // 1 is defined as the serviceProvider share
    // 0 is for tKey
    const shareIndexForDeviceStorage = generatePrivateExcludingIndexes([new BN(1), new BN(0)]);
    const shareIndexes = [new BN(1), shareIndexForDeviceStorage];
    let poly;
    if (determinedShare) {
      const shareIndexForDeterminedShare = generatePrivateExcludingIndexes([new BN(1), new BN(0)]);
      poly = generateRandomPolynomial(1, this.privKey, [new Share(shareIndexForDeterminedShare, determinedShare)]);
      shareIndexes.push(shareIndexForDeterminedShare);
    } else {
      poly = generateRandomPolynomial(1, this.privKey);
    }
    const shares = poly.generateShares(shareIndexes);

    // create metadata to be stored
    const metadata = new Metadata$1(getPubKeyPoint(this.privKey));
    metadata.addFromPolynomialAndShares(poly, shares);
    const serviceProviderShare = shares[shareIndexes[0].toString("hex")];
    const shareStore = new ShareStore(serviceProviderShare, poly.getPolynomialID());
    this.metadata = metadata;

    // setup ed25519 seed after metadata is set
    // import/gen ed25519 seed
    await this.setupEd25519Seed(importEd25519Seed);

    // initialize modules
    if (initializeModules) {
      await this.initializeModules();
    }
    const metadataToPush = [];
    const sharesToPush = shareIndexes.map(shareIndex => {
      metadataToPush.push(this.metadata);
      return shares[shareIndex.toString("hex")].share;
    });
    const authMetadatas = this.generateAuthMetadata({
      input: metadataToPush
    });

    // because this is the first time we're setting metadata there is no need to acquire a lock
    // acquireLock: false. Force push
    await this.addLocalMetadataTransitions({
      input: [...authMetadatas, shareStore],
      privKey: [...sharesToPush, undefined]
    });
    if (delete1OutOf1) {
      await this.addLocalMetadataTransitions({
        input: [{
          message: ONE_KEY_DELETE_NONCE
        }],
        privKey: [this.serviceProvider.postboxKey]
      });
    }

    // store metadata on metadata respective to shares
    for (let index = 0; index < shareIndexes.length; index += 1) {
      const shareIndex = shareIndexes[index];
      // also add into our share store
      this.inputShareStore(new ShareStore(shares[shareIndex.toString("hex")], poly.getPolynomialID()));
    }
    if (this.storeDeviceShare) {
      await this.storeDeviceShare(new ShareStore(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()));
    }
    const result = {
      secp256k1Key: this.privKey,
      deviceShare: new ShareStore(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()),
      userShare: undefined
    };
    if (determinedShare) {
      result.userShare = new ShareStore(shares[shareIndexes[2].toString("hex")], poly.getPolynomialID());
    }
    return result;
  }
  async importEd25519Seed(seed) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (this.getEd25519PublicKey()) {
      throw CoreError$1.default("Ed25519 key already exists");
    }

    // derive key pair (scalar, public key point) from seed
    const keyPair = getEd25519ExtendedPublicKey(seed);
    this.metadata.setGeneralStoreDomain(ed25519SeedConst, {
      message: await this.encrypt(seed),
      publicKey: keyPair.point.encode("hex", false)
    });
    this._ed25519Seed = seed;
  }
  async setupEd25519Seed(seed) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    let seedToUse = seed;
    if (!seed) {
      const newEd25519Seed = await getRandomBytes(32);
      seedToUse = Buffer.from(newEd25519Seed);
    }
    await this.importEd25519Seed(seedToUse);
  }
}
var ThresholdKey$1 = ThresholdKey;

export { AuthMetadata$1 as AuthMetadata, CoreError$1 as CoreError, Metadata$1 as Metadata, ThresholdKey$1 as TKey, generatePrivateBN, generateRandomPolynomial, lagrangeInterpolatePolynomial, lagrangeInterpolation, polyCommitmentEval };
