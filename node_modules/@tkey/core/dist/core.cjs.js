/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	// The require scope
/******/ 	var __webpack_require__ = {};
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// ESM COMPAT FLAG
__webpack_require__.r(__webpack_exports__);

// EXPORTS
__webpack_require__.d(__webpack_exports__, {
  AuthMetadata: () => (/* reexport */ src_authMetadata),
  CoreError: () => (/* reexport */ errors),
  Metadata: () => (/* reexport */ src_metadata),
  TKey: () => (/* reexport */ core),
  generatePrivateBN: () => (/* reexport */ generatePrivateBN),
  generateRandomPolynomial: () => (/* reexport */ generateRandomPolynomial),
  lagrangeInterpolatePolynomial: () => (/* reexport */ lagrangeInterpolatePolynomial),
  lagrangeInterpolation: () => (/* reexport */ lagrangeInterpolation),
  polyCommitmentEval: () => (/* reexport */ polyCommitmentEval)
});

;// CONCATENATED MODULE: external "@babel/runtime/helpers/defineProperty"
const defineProperty_namespaceObject = require("@babel/runtime/helpers/defineProperty");
var defineProperty_default = /*#__PURE__*/__webpack_require__.n(defineProperty_namespaceObject);
;// CONCATENATED MODULE: external "@tkey/common-types"
const common_types_namespaceObject = require("@tkey/common-types");
;// CONCATENATED MODULE: external "@toruslabs/torus.js"
const torus_js_namespaceObject = require("@toruslabs/torus.js");
;// CONCATENATED MODULE: external "json-stable-stringify"
const external_json_stable_stringify_namespaceObject = require("json-stable-stringify");
var external_json_stable_stringify_default = /*#__PURE__*/__webpack_require__.n(external_json_stable_stringify_namespaceObject);
;// CONCATENATED MODULE: ./src/errors.ts



/**
 * CoreError, extension for Error using CustomError
 * details: github.com/Microsoft/TypeScript-wiki/blob/master/Breaking-Changes.md#extending-built-ins-like-error-array-and-map-may-no-longer-work
 *
 * Usage:
 * 1. throw CoreError.metadataUndefined() // regularly used errors
 * 2. throw CoreError.fromCode(1304); // throw via code
 * 3. throw new CoreError(1000, "share indexes should be unique"); // for scarce errors
 *
 * Guide:
 * 1000 - core
 * 2000 - security questions
 * 3000 - webstorage
 * 4000 - common types (code reserved for future implementation)
 * 5000 - private key
 * 6000 - seed phrase
 * 7000 - share serialization
 * 8000 - share transfer
 */
class CoreError extends common_types_namespaceObject.TkeyError {
  constructor(code, message) {
    // takes care of stack and proto
    super(code, message);

    // Set name explicitly as minification can mangle class names
    Object.defineProperty(this, "name", {
      value: "CoreError"
    });
  }
  static fromCode(code, extraMessage = "") {
    return new CoreError(code, `${CoreError.messages[code]} ${extraMessage}`);
  }
  static default(extraMessage = "") {
    return new CoreError(1000, `${CoreError.messages[1000]} ${extraMessage}`);
  }

  // Custom methods
  // Metadata
  static metadataUndefined(extraMessage = "") {
    return CoreError.fromCode(1101, extraMessage);
  }
  static delete1OutOf1OnlyManualSync(extraMessage = "") {
    return CoreError.fromCode(1601, extraMessage);
  }
  static metadataGetFailed(extraMessage = "") {
    return CoreError.fromCode(1102, extraMessage);
  }
  static metadataPostFailed(extraMessage = "") {
    return CoreError.fromCode(1103, extraMessage);
  }

  // TkeyData
  static tkeyStoreInvalid(extraMessage = "") {
    return CoreError.fromCode(1201, extraMessage);
  }
  static tkeyEncryptionFailed(extraMessage = "") {
    return CoreError.fromCode(1202, extraMessage);
  }
  static tkeyDecryptionFailed(extraMessage = "") {
    return CoreError.fromCode(1203, extraMessage);
  }

  // Shares
  static privateKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1301, extraMessage);
  }
  static unableToReconstruct(extraMessage = "") {
    return CoreError.fromCode(1302, extraMessage);
  }
  static incorrectReconstruction(extraMessage = "") {
    return CoreError.fromCode(1303, extraMessage);
  }
  static encryptedShareStoreUnavailable(extraMessage = "") {
    return CoreError.fromCode(1306, extraMessage);
  }

  // Metadata locks
  static acquireLockFailed(extraMessage = "") {
    return CoreError.fromCode(1401, extraMessage);
  }
  static releaseLockFailed(extraMessage = "") {
    return CoreError.fromCode(1402, extraMessage);
  }

  // Authmetadata
  static privKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1501, extraMessage);
  }
  static metadataPubKeyUnavailable(extraMessage = "") {
    return CoreError.fromCode(1502, extraMessage);
  }
  static authMetadataGetUnavailable(extraMessage = "") {
    return CoreError.fromCode(1503, extraMessage);
  }
  static authMetadataSetUnavailable(extraMessage = "") {
    return CoreError.fromCode(1504, extraMessage);
  }
}
defineProperty_default()(CoreError, "messages", {
  1000: "Custom",
  // Misc
  1001: "Unable to delete service provider share",
  1002: "Wrong share index",
  1003: "Unable to updateSDK",
  // metadata
  1101: "metadata not found, SDK likely not initialized",
  1102: "getMetadata errored",
  1103: "setMetadata errored",
  1104: "previouslyFetchedCloudMetadata provided in initialization is outdated",
  1105: "previouslyFetchedCloudMetadata.nonce should never be higher than the latestShareDetails, please contact support",
  // tkeystore
  1201: "Invalid tkeyStore",
  1202: "Encryption failed",
  1203: "Decryption failed",
  // shares
  1301: "Private key not available. Please reconstruct key first",
  1302: "Unable to reconstruct",
  1303: "reconstructed key is not pub key",
  1304: "Share found in unexpected polynomial",
  1305: "Input is not supported",
  1306: "no encrypted share store for share exists",
  1307: "Share doesn't exist",
  1308: "Share was deleted",
  // lock
  1401: "Unable to acquire lock",
  1402: "Unable to release lock",
  // auth metadata
  1501: "privkey unavailable",
  1502: "metadata pubkey unavailable",
  1503: "getAuthMetadata errored",
  1504: "setAuthMetadata errored",
  1601: "delete1OutOf1 requires manualSync=true"
});
/* harmony default export */ const errors = (CoreError);
;// CONCATENATED MODULE: external "@babel/runtime/helpers/objectSpread2"
const objectSpread2_namespaceObject = require("@babel/runtime/helpers/objectSpread2");
var objectSpread2_default = /*#__PURE__*/__webpack_require__.n(objectSpread2_namespaceObject);
;// CONCATENATED MODULE: external "bn.js"
const external_bn_js_namespaceObject = require("bn.js");
var external_bn_js_default = /*#__PURE__*/__webpack_require__.n(external_bn_js_namespaceObject);
;// CONCATENATED MODULE: ./src/lagrangeInterpolatePolynomial.ts



function generatePrivateBN() {
  return common_types_namespaceObject.secp256k1.genKeyPair().getPrivate();
}
const generateEmptyBNArray = length => Array.from({
  length
}, () => new (external_bn_js_default())(0));
const denominator = (i, innerPoints) => {
  let result = new (external_bn_js_default())(1);
  const xi = innerPoints[i].x;
  for (let j = innerPoints.length - 1; j >= 0; j -= 1) {
    if (i !== j) {
      let tmp = new (external_bn_js_default())(xi);
      tmp = tmp.sub(innerPoints[j].x);
      tmp = tmp.umod(common_types_namespaceObject.secp256k1.curve.n);
      result = result.mul(tmp);
      result = result.umod(common_types_namespaceObject.secp256k1.curve.n);
    }
  }
  return result;
};
const interpolationPoly = (i, innerPoints) => {
  let coefficients = generateEmptyBNArray(innerPoints.length);
  const d = denominator(i, innerPoints);
  if (d.cmp(new (external_bn_js_default())(0)) === 0) {
    throw errors["default"]("Denominator for interpolationPoly is 0");
  }
  coefficients[0] = d.invm(common_types_namespaceObject.secp256k1.curve.n);
  for (let k = 0; k < innerPoints.length; k += 1) {
    const newCoefficients = generateEmptyBNArray(innerPoints.length);
    if (k !== i) {
      let j;
      if (k < i) {
        j = k + 1;
      } else {
        j = k;
      }
      j -= 1;
      for (; j >= 0; j -= 1) {
        newCoefficients[j + 1] = newCoefficients[j + 1].add(coefficients[j]);
        newCoefficients[j + 1] = newCoefficients[j + 1].umod(common_types_namespaceObject.secp256k1.curve.n);
        let tmp = new (external_bn_js_default())(innerPoints[k].x);
        tmp = tmp.mul(coefficients[j]);
        tmp = tmp.umod(common_types_namespaceObject.secp256k1.curve.n);
        newCoefficients[j] = newCoefficients[j].sub(tmp);
        newCoefficients[j] = newCoefficients[j].umod(common_types_namespaceObject.secp256k1.curve.n);
      }
      coefficients = newCoefficients;
    }
  }
  return coefficients;
};
const pointSort = innerPoints => {
  const pointArrClone = [...innerPoints];
  pointArrClone.sort((a, b) => a.x.cmp(b.x));
  return pointArrClone;
};
const lagrange = unsortedPoints => {
  const sortedPoints = pointSort(unsortedPoints);
  const polynomial = generateEmptyBNArray(sortedPoints.length);
  for (let i = 0; i < sortedPoints.length; i += 1) {
    const coefficients = interpolationPoly(i, sortedPoints);
    for (let k = 0; k < sortedPoints.length; k += 1) {
      let tmp = new (external_bn_js_default())(sortedPoints[i].y);
      tmp = tmp.mul(coefficients[k]);
      polynomial[k] = polynomial[k].add(tmp);
      polynomial[k] = polynomial[k].umod(common_types_namespaceObject.secp256k1.curve.n);
    }
  }
  return new common_types_namespaceObject.Polynomial(polynomial);
};
function lagrangeInterpolatePolynomial(points) {
  return lagrange(points);
}
function lagrangeInterpolation(shares, nodeIndex) {
  if (shares.length !== nodeIndex.length) {
    throw errors["default"]("shares not equal to nodeIndex length in lagrangeInterpolation");
  }
  let secret = new (external_bn_js_default())(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new (external_bn_js_default())(1);
    let lower = new (external_bn_js_default())(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(common_types_namespaceObject.secp256k1.curve.n);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(common_types_namespaceObject.secp256k1.curve.n);
        lower = lower.mul(temp).umod(common_types_namespaceObject.secp256k1.curve.n);
      }
    }
    let delta = upper.mul(lower.invm(common_types_namespaceObject.secp256k1.curve.n)).umod(common_types_namespaceObject.secp256k1.curve.n);
    delta = delta.mul(shares[i]).umod(common_types_namespaceObject.secp256k1.curve.n);
    secret = secret.add(delta);
  }
  return secret.umod(common_types_namespaceObject.secp256k1.curve.n);
}

// generateRandomPolynomial - determinisiticShares are assumed random
function generateRandomPolynomial(degree, secret, deterministicShares) {
  let actualS = secret;
  if (!secret) {
    actualS = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)([new (external_bn_js_default())(0)]);
  }
  if (!deterministicShares) {
    const poly = [actualS];
    for (let i = 0; i < degree; i += 1) {
      const share = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)(poly);
      poly.push(share);
    }
    return new common_types_namespaceObject.Polynomial(poly);
  }
  if (!Array.isArray(deterministicShares)) {
    throw errors["default"]("deterministic shares in generateRandomPolynomial should be an array");
  }
  if (deterministicShares.length > degree) {
    throw errors["default"]("deterministicShares in generateRandomPolynomial should be less or equal than degree to ensure an element of randomness");
  }
  const points = {};
  deterministicShares.forEach(share => {
    points[share.shareIndex.toString("hex")] = new common_types_namespaceObject.Point(share.shareIndex, share.share);
  });
  for (let i = 0; i < degree - deterministicShares.length; i += 1) {
    let shareIndex = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)([new (external_bn_js_default())(0)]);
    while (points[shareIndex.toString("hex")] !== undefined) {
      shareIndex = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)([new (external_bn_js_default())(0)]);
    }
    points[shareIndex.toString("hex")] = new common_types_namespaceObject.Point(shareIndex, generatePrivateBN());
  }
  points["0"] = new common_types_namespaceObject.Point(new (external_bn_js_default())(0), actualS);
  return lagrangeInterpolatePolynomial(Object.values(points));
}

//  2 + 3x = y | secret for index 1 is 5 >>> g^5 is the commitment | now we have g^2, g^3 and 1, |
function polyCommitmentEval(polyCommitments, index) {
  // convert to base points, this is badly written, its the only way to access the point rn zzz TODO: refactor
  const basePtPolyCommitments = [];
  for (let i = 0; i < polyCommitments.length; i += 1) {
    const key = common_types_namespaceObject.secp256k1.keyFromPublic({
      x: polyCommitments[i].x.toString("hex"),
      y: polyCommitments[i].y.toString("hex")
    }, "");
    basePtPolyCommitments.push(key.getPublic());
  }
  let shareCommitment = basePtPolyCommitments[0];
  for (let i = 1; i < basePtPolyCommitments.length; i += 1) {
    const factor = index.pow(new (external_bn_js_default())(i)).umod(common_types_namespaceObject.secp256k1.n);
    const e = basePtPolyCommitments[i].mul(factor);
    shareCommitment = shareCommitment.add(e);
  }
  return new common_types_namespaceObject.Point(shareCommitment.getX(), shareCommitment.getY());
}
;// CONCATENATED MODULE: ./src/metadata.ts







class Metadata {
  constructor(input) {
    defineProperty_default()(this, "pubKey", void 0);
    defineProperty_default()(this, "publicPolynomials", void 0);
    defineProperty_default()(this, "publicShares", void 0);
    // Tuple of PolyID and array of ShareIndexes
    defineProperty_default()(this, "polyIDList", void 0);
    defineProperty_default()(this, "generalStore", void 0);
    defineProperty_default()(this, "tkeyStore", void 0);
    defineProperty_default()(this, "scopedStore", void 0);
    defineProperty_default()(this, "nonce", void 0);
    defineProperty_default()(this, "tssKeyTypes", void 0);
    defineProperty_default()(this, "tssNonces", void 0);
    defineProperty_default()(this, "tssPolyCommits", void 0);
    defineProperty_default()(this, "factorPubs", void 0);
    defineProperty_default()(this, "factorEncs", void 0);
    this.publicPolynomials = {};
    this.publicShares = {};
    this.generalStore = {};
    this.tkeyStore = {};
    this.scopedStore = {};
    this.pubKey = input;
    this.polyIDList = [];
    this.nonce = 0;
    this.tssKeyTypes = {};
    this.tssPolyCommits = {};
    this.tssNonces = {};
    this.factorPubs = {};
    this.factorEncs = {};
  }
  static fromJSON(value) {
    const {
      pubKey,
      polyIDList,
      generalStore,
      tkeyStore,
      scopedStore,
      nonce,
      tssKeyTypes,
      tssPolyCommits,
      tssNonces,
      factorPubs,
      factorEncs
    } = value;
    const point = common_types_namespaceObject.Point.fromSEC1(common_types_namespaceObject.secp256k1, pubKey);
    const metadata = new Metadata(point);
    const unserializedPolyIDList = [];
    if (generalStore) metadata.generalStore = generalStore;
    if (tkeyStore) metadata.tkeyStore = tkeyStore;
    if (scopedStore) metadata.scopedStore = scopedStore;
    if (nonce) metadata.nonce = nonce;
    if (tssKeyTypes) {
      metadata.tssKeyTypes = {};
      for (const key in tssKeyTypes) {
        metadata.tssKeyTypes[key] = tssKeyTypes[key];
      }
    }
    if (tssPolyCommits) {
      metadata.tssPolyCommits = {};
      for (const key in tssPolyCommits) {
        metadata.tssPolyCommits[key] = tssPolyCommits[key].map(obj => new common_types_namespaceObject.Point(obj.x, obj.y));
      }
    }
    if (tssNonces) {
      metadata.tssNonces = {};
      for (const key in tssNonces) {
        metadata.tssNonces[key] = tssNonces[key];
      }
    }
    if (factorPubs) {
      metadata.factorPubs = {};
      for (const key in factorPubs) {
        metadata.factorPubs[key] = factorPubs[key].map(obj => new common_types_namespaceObject.Point(obj.x, obj.y));
      }
    }
    if (factorEncs) metadata.factorEncs = factorEncs;
    for (let i = 0; i < polyIDList.length; i += 1) {
      const serializedPolyID = polyIDList[i];
      const arrPolyID = serializedPolyID.split("|");
      const zeroIndex = arrPolyID.findIndex(v => v === "0x0");
      const firstHalf = arrPolyID.slice(0, zeroIndex);
      const secondHalf = arrPolyID.slice(zeroIndex + 1, arrPolyID.length);
      // for publicPolynomials
      const pubPolyID = firstHalf.join("|");
      const pointCommitments = [];
      firstHalf.forEach(compressedCommitment => {
        pointCommitments.push(common_types_namespaceObject.Point.fromCompressedPub(compressedCommitment));
      });
      const publicPolynomial = new common_types_namespaceObject.PublicPolynomial(pointCommitments);
      metadata.publicPolynomials[pubPolyID] = publicPolynomial;

      // for polyIDList
      unserializedPolyIDList.push([pubPolyID, secondHalf]);
    }
    metadata.polyIDList = unserializedPolyIDList;
    return metadata;
  }
  getShareIndexesForPolynomial(polyID) {
    const matchingPolyIDs = this.polyIDList.filter(tuple => tuple[0] === polyID);
    if (matchingPolyIDs.length < 1) {
      throw errors["default"]("there is no matching polyID");
    } else if (matchingPolyIDs.length > 1) {
      throw errors["default"]("there is more than one matching polyID");
    }
    return matchingPolyIDs[0][1];
  }
  getLatestPublicPolynomial() {
    return this.publicPolynomials[this.polyIDList[this.polyIDList.length - 1][0]];
  }
  addPublicShare(polynomialID, publicShare) {
    if (!(polynomialID in this.publicShares)) {
      this.publicShares[polynomialID] = {};
    }
    this.publicShares[polynomialID][publicShare.shareIndex.toString("hex")] = publicShare;
  }
  setGeneralStoreDomain(key, obj) {
    this.generalStore[key] = obj;
  }
  getGeneralStoreDomain(key) {
    return this.generalStore[key];
  }
  deleteGeneralStoreDomain(key) {
    delete this.generalStore[key];
  }
  setTkeyStoreDomain(key, arr) {
    this.tkeyStore[key] = arr;
  }
  getTkeyStoreDomain(key) {
    return this.tkeyStore[key];
  }

  // appends shares and public polynomial to metadata.
  // should represent a generation of share or edit of threshold
  addFromPolynomialAndShares(polynomial, shares) {
    const publicPolynomial = polynomial.getPublicPolynomial();
    const polyID = publicPolynomial.getPolynomialID();
    this.publicPolynomials[polyID] = publicPolynomial;
    const shareIndexArr = [];
    if (Array.isArray(shares)) {
      for (let i = 0; i < shares.length; i += 1) {
        this.addPublicShare(publicPolynomial.getPolynomialID(), shares[i].getPublicShare());
        shareIndexArr.push(shares[i].shareIndex.toString("hex"));
      }
    } else {
      for (const k in shares) {
        if (Object.prototype.hasOwnProperty.call(shares, k)) {
          this.addPublicShare(publicPolynomial.getPolynomialID(), shares[k].getPublicShare());
          shareIndexArr.push(shares[k].shareIndex.toString("hex"));
        }
      }
    }
    this.polyIDList.push([polyID, shareIndexArr]);
  }
  setScopedStore(domain, data) {
    this.scopedStore[domain] = data;
  }
  async getEncryptedShare(shareStore) {
    const pubShare = shareStore.share.getPublicShare();
    const encryptedShareStore = this.scopedStore.encryptedShares;
    if (!encryptedShareStore) {
      throw errors.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const encryptedShare = encryptedShareStore[pubShare.shareCommitment.x.toString("hex")];
    if (!encryptedShare) {
      throw errors.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const rawDecrypted = await (0,common_types_namespaceObject.decrypt)((0,common_types_namespaceObject.toPrivKeyECC)(shareStore.share.share), encryptedShare);
    return common_types_namespaceObject.ShareStore.fromJSON(JSON.parse(rawDecrypted.toString()));
  }
  getShareDescription() {
    return this.getGeneralStoreDomain("shareDescriptions");
  }
  addShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions") || {};
    if (currentSD[shareIndex]) {
      currentSD[shareIndex].push(description);
    } else {
      currentSD[shareIndex] = [description];
    }
    this.setGeneralStoreDomain("shareDescriptions", currentSD);
  }
  deleteShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(description);
    if (index > -1) {
      currentSD[shareIndex].splice(index, 1);
    } else {
      throw errors["default"](`No share description found for the given shareIndex: ${shareIndex} 
        and description: ${description}`);
    }
  }
  updateShareDescription(shareIndex, oldDescription, newDescription) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(oldDescription);
    if (index > -1) {
      currentSD[shareIndex][index] = newDescription;
    } else {
      throw errors["default"](`No share description found for the given shareIndex:
        ${shareIndex} and description: ${oldDescription}`);
    }
  }
  shareToShareStore(share) {
    const pubkey = (0,common_types_namespaceObject.getPubKeyPoint)(share);
    let returnShare;
    for (let i = this.polyIDList.length - 1; i >= 0; i -= 1) {
      const el = this.polyIDList[i][0];
      for (let t = 0; t < this.polyIDList[i][1].length; t += 1) {
        const shareIndex = this.polyIDList[i][1][t];
        // find pubshare in cache if its there
        let pubShare;
        if (this.publicShares[el]) {
          if (this.publicShares[el][shareIndex]) {
            pubShare = this.publicShares[el][shareIndex];
          }
        }

        // if not reconstruct
        if (!pubShare) {
          pubShare = new common_types_namespaceObject.PublicShare(shareIndex, polyCommitmentEval(this.publicPolynomials[el].polynomialCommitments, new (external_bn_js_default())(shareIndex, "hex")));
        }
        if (pubShare.shareCommitment.x.eq(pubkey.x) && pubShare.shareCommitment.y.eq(pubkey.y)) {
          const tempShare = new common_types_namespaceObject.Share(pubShare.shareIndex, share);
          return new common_types_namespaceObject.ShareStore(tempShare, el);
        }
      }
    }
    if (!returnShare) {
      throw errors.fromCode(1307);
    }
    return returnShare;
  }
  clone() {
    return Metadata.fromJSON(JSON.parse(external_json_stable_stringify_default()(this)));
  }
  toJSON() {
    // squash data to serialized polyID according to spec
    const serializedPolyIDList = [];
    for (let i = 0; i < this.polyIDList.length; i += 1) {
      const polyID = this.polyIDList[i][0];
      const shareIndexes = this.polyIDList[i][1];
      const sortedShareIndexes = shareIndexes.sort((a, b) => new (external_bn_js_default())(a, "hex").cmp(new (external_bn_js_default())(b, "hex")));
      const serializedPolyID = polyID.split(`|`).concat("0x0").concat(...sortedShareIndexes).join("|");
      serializedPolyIDList.push(serializedPolyID);
    }
    return objectSpread2_default()(objectSpread2_default()(objectSpread2_default()(objectSpread2_default()(objectSpread2_default()({
      pubKey: this.pubKey.toSEC1(common_types_namespaceObject.secp256k1, true).toString("hex"),
      polyIDList: serializedPolyIDList,
      scopedStore: this.scopedStore,
      generalStore: this.generalStore,
      tkeyStore: this.tkeyStore,
      nonce: this.nonce
    }, this.tssKeyTypes && {
      tssKeyTypes: this.tssKeyTypes
    }), this.tssNonces && {
      tssNonces: this.tssNonces
    }), this.tssPolyCommits && {
      tssPolyCommits: this.tssPolyCommits
    }), this.factorPubs && {
      factorPubs: this.factorPubs
    }), this.factorEncs && {
      factorEncs: this.factorEncs
    });
  }

  /**
   * Updates the TSS metadata for the given tag.
   */
  updateTSSData(tssData) {
    const {
      tssKeyType,
      tssTag,
      tssNonce,
      tssPolyCommits,
      factorPubs,
      factorEncs
    } = tssData;
    if (tssKeyType) this.tssKeyTypes[tssTag] = tssKeyType;
    if (tssNonce !== undefined) this.tssNonces[tssTag] = tssNonce;
    if (tssPolyCommits) this.tssPolyCommits[tssTag] = tssPolyCommits;
    if (factorPubs) this.factorPubs[tssTag] = factorPubs;
    if (factorEncs) this.factorEncs[tssTag] = factorEncs;
  }
}
/* harmony default export */ const src_metadata = (Metadata);
;// CONCATENATED MODULE: ./src/authMetadata.ts






class AuthMetadata {
  constructor(metadata, privKey) {
    defineProperty_default()(this, "metadata", void 0);
    defineProperty_default()(this, "privKey", void 0);
    this.metadata = metadata;
    this.privKey = privKey;
  }
  static fromJSON(value) {
    const {
      data,
      sig
    } = value;
    if (!data) throw errors.metadataUndefined();
    const m = src_metadata.fromJSON(data);
    if (!m.pubKey) throw errors.metadataPubKeyUnavailable();
    const keyPair = common_types_namespaceObject.secp256k1.keyFromPublic(m.pubKey.toSEC1(common_types_namespaceObject.secp256k1));
    if (!keyPair.verify((0,common_types_namespaceObject.stripHexPrefix)((0,torus_js_namespaceObject.keccak256)(Buffer.from(external_json_stable_stringify_default()(data), "utf8"))), sig)) {
      throw errors["default"]("Signature not valid for returning metadata");
    }
    return new AuthMetadata(m);
  }
  toJSON() {
    const data = this.metadata;
    if (!this.privKey) throw errors.privKeyUnavailable();
    const k = (0,common_types_namespaceObject.toPrivKeyEC)(this.privKey);
    const sig = k.sign((0,common_types_namespaceObject.stripHexPrefix)((0,torus_js_namespaceObject.keccak256)(Buffer.from(external_json_stable_stringify_default()(data), "utf8"))));
    return {
      data,
      sig: sig.toDER("hex")
    };
  }
}
/* harmony default export */ const src_authMetadata = (AuthMetadata);
;// CONCATENATED MODULE: ../../node_modules/@noble/hashes/esm/crypto.js
const crypto_crypto = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;
//# sourceMappingURL=crypto.js.map
;// CONCATENATED MODULE: ../../node_modules/@noble/hashes/esm/utils.js
/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated (2025-04-30), we can just drop the import.


// export { isBytes } from './_assert.js';
// We can't reuse isBytes from _assert, because somehow this causes huge perf issues
function isBytes(a) {
    return (a instanceof Uint8Array ||
        (a != null && typeof a === 'object' && a.constructor.name === 'Uint8Array'));
}
// Cast array to different type
const u8 = (arr) => new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);
const u32 = (arr) => new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));
// Cast array to view
const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);
// The rotate left (circular left shift) operation for uint32
const rotl = (word, shift) => (word << shift) | ((word >>> (32 - shift)) >>> 0);
const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
// The byte swap operation for uint32
const byteSwap = (word) => ((word << 24) & 0xff000000) |
    ((word << 8) & 0xff0000) |
    ((word >>> 8) & 0xff00) |
    ((word >>> 24) & 0xff);
// Conditionally byte swap if on a big-endian platform
const byteSwapIfBE = (/* unused pure expression or super */ null && (isLE ? (n) => n : (n) => byteSwap(n)));
// In place byte swap for Uint32Array
function byteSwap32(arr) {
    for (let i = 0; i < arr.length; i++) {
        arr[i] = byteSwap(arr[i]);
    }
}
// Array where index 0xf0 (240) is mapped to string 'f0'
const hexes = /* @__PURE__ */ Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, '0'));
/**
 * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'
 */
function bytesToHex(bytes) {
    abytes(bytes);
    // pre-caching improves the speed 6x
    let hex = '';
    for (let i = 0; i < bytes.length; i++) {
        hex += hexes[bytes[i]];
    }
    return hex;
}
// We use optimized technique to convert hex string to byte array
const asciis = { _0: 48, _9: 57, _A: 65, _F: 70, _a: 97, _f: 102 };
function asciiToBase16(char) {
    if (char >= asciis._0 && char <= asciis._9)
        return char - asciis._0;
    if (char >= asciis._A && char <= asciis._F)
        return char - (asciis._A - 10);
    if (char >= asciis._a && char <= asciis._f)
        return char - (asciis._a - 10);
    return;
}
/**
 * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])
 */
function hexToBytes(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    const hl = hex.length;
    const al = hl / 2;
    if (hl % 2)
        throw new Error('padded hex string expected, got unpadded hex of length ' + hl);
    const array = new Uint8Array(al);
    for (let ai = 0, hi = 0; ai < al; ai++, hi += 2) {
        const n1 = asciiToBase16(hex.charCodeAt(hi));
        const n2 = asciiToBase16(hex.charCodeAt(hi + 1));
        if (n1 === undefined || n2 === undefined) {
            const char = hex[hi] + hex[hi + 1];
            throw new Error('hex string expected, got non-hex character "' + char + '" at index ' + hi);
        }
        array[ai] = n1 * 16 + n2;
    }
    return array;
}
// There is no setImmediate in browser and setTimeout is slow.
// call of async fn will return Promise, which will be fullfiled only on
// next scheduler queue processing step and this is exactly what we need.
const nextTick = async () => { };
// Returns control to thread each 'tick' ms to avoid blocking
async function asyncLoop(iters, tick, cb) {
    let ts = Date.now();
    for (let i = 0; i < iters; i++) {
        cb(i);
        // Date.now() is not monotonic, so in case if clock goes backwards we return return control too
        const diff = Date.now() - ts;
        if (diff >= 0 && diff < tick)
            continue;
        await nextTick();
        ts += diff;
    }
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes(data) {
    if (typeof data === 'string')
        data = utf8ToBytes(data);
    abytes(data);
    return data;
}
/**
 * Copies several Uint8Arrays into one.
 */
function concatBytes(...arrays) {
    let sum = 0;
    for (let i = 0; i < arrays.length; i++) {
        const a = arrays[i];
        abytes(a);
        sum += a.length;
    }
    const res = new Uint8Array(sum);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const a = arrays[i];
        res.set(a, pad);
        pad += a.length;
    }
    return res;
}
// For runtime check if class implements interface
class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
}
const toStr = {}.toString;
function checkOpts(defaults, opts) {
    if (opts !== undefined && toStr.call(opts) !== '[object Object]')
        throw new Error('Options should be object or undefined');
    const merged = Object.assign(defaults, opts);
    return merged;
}
function wrapConstructor(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}
function wrapConstructorWithOpts(hashCons) {
    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();
    const tmp = hashCons({});
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = (opts) => hashCons(opts);
    return hashC;
}
function wrapXOFConstructorWithOpts(hashCons) {
    const hashC = (msg, opts) => hashCons(opts).update(toBytes(msg)).digest();
    const tmp = hashCons({});
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = (opts) => hashCons(opts);
    return hashC;
}
/**
 * Secure PRNG. Uses `crypto.getRandomValues`, which defers to OS.
 */
function utils_randomBytes(bytesLength = 32) {
    if (crypto_crypto && typeof crypto_crypto.getRandomValues === 'function') {
        return crypto_crypto.getRandomValues(new Uint8Array(bytesLength));
    }
    throw new Error('crypto.getRandomValues must be defined');
}
//# sourceMappingURL=utils.js.map
;// CONCATENATED MODULE: ../../node_modules/ethereum-cryptography/esm/random.js

function getRandomBytesSync(bytes) {
    return randomBytes(bytes);
}
async function getRandomBytes(bytes) {
    return utils_randomBytes(bytes);
}

;// CONCATENATED MODULE: ./src/core.ts











const ed25519SeedConst = "ed25519Seed";

// TODO: handle errors for get and set with retries

class ThresholdKey {
  constructor(args) {
    defineProperty_default()(this, "modules", void 0);
    defineProperty_default()(this, "enableLogging", void 0);
    defineProperty_default()(this, "serviceProvider", void 0);
    defineProperty_default()(this, "storageLayer", void 0);
    defineProperty_default()(this, "shares", void 0);
    defineProperty_default()(this, "lastFetchedCloudMetadata", void 0);
    defineProperty_default()(this, "metadata", void 0);
    defineProperty_default()(this, "manualSync", void 0);
    defineProperty_default()(this, "_localMetadataTransitions", void 0);
    defineProperty_default()(this, "_refreshMiddleware", void 0);
    defineProperty_default()(this, "_reconstructKeyMiddleware", void 0);
    defineProperty_default()(this, "_shareSerializationMiddleware", void 0);
    defineProperty_default()(this, "storeDeviceShare", void 0);
    defineProperty_default()(this, "haveWriteMetadataLock", void 0);
    defineProperty_default()(this, "serverTimeOffset", 0);
    // secp256k1 key
    defineProperty_default()(this, "privKey", void 0);
    defineProperty_default()(this, "_ed25519Seed", void 0);
    const {
      enableLogging = false,
      modules = {},
      serviceProvider,
      storageLayer,
      manualSync = false,
      serverTimeOffset
    } = args || {};
    this.enableLogging = enableLogging;
    this.serviceProvider = serviceProvider;
    this.storageLayer = storageLayer;
    this.modules = modules;
    this.shares = {};
    this.privKey = undefined;
    this.manualSync = manualSync;
    this._refreshMiddleware = {};
    this._reconstructKeyMiddleware = {};
    this._shareSerializationMiddleware = undefined;
    this.storeDeviceShare = undefined;
    this._localMetadataTransitions = [[], []];
    this.setModuleReferences(); // Providing ITKeyApi access to modules
    this.haveWriteMetadataLock = "";
    this.serverTimeOffset = serverTimeOffset;
  }
  get secp256k1Key() {
    if (typeof this.privKey !== "undefined") {
      return this.privKey;
    }
    return null;
  }
  get ed25519Key() {
    if (typeof this._ed25519Seed !== "undefined") {
      return this._ed25519Seed;
    }
    return null;
  }
  set secp256k1Key(privKey) {
    this.privKey = privKey;
  }
  set ed25519Key(seed) {
    this._ed25519Seed = seed;
  }
  static async fromJSON(value, args) {
    const {
      enableLogging,
      privKey,
      metadata,
      shares,
      _localMetadataTransitions,
      manualSync,
      lastFetchedCloudMetadata,
      serverTimeOffset
    } = value;
    const {
      storageLayer,
      serviceProvider,
      modules
    } = args;
    const tb = new ThresholdKey({
      enableLogging,
      storageLayer,
      serviceProvider,
      modules,
      manualSync,
      serverTimeOffset
    });
    if (privKey) tb.privKey = new (external_bn_js_default())(privKey, "hex");
    for (const key in shares) {
      if (Object.prototype.hasOwnProperty.call(shares, key)) {
        const shareStoreMapElement = shares[key];
        for (const shareElementKey in shareStoreMapElement) {
          if (Object.prototype.hasOwnProperty.call(shareStoreMapElement, shareElementKey)) {
            const shareStore = shareStoreMapElement[shareElementKey];
            shareStoreMapElement[shareElementKey] = common_types_namespaceObject.ShareStore.fromJSON(shareStore);
          }
        }
      }
    }
    tb.shares = shares;

    // switch to deserialize local metadata transition based on Object.keys() of authMetadata, ShareStore's and, IMessageMetadata
    const AuthMetadataKeys = Object.keys(JSON.parse(external_json_stable_stringify_default()(new src_authMetadata(new src_metadata(new common_types_namespaceObject.Point("0", "0")), new (external_bn_js_default())("0", "hex")))));
    const ShareStoreKeys = Object.keys(JSON.parse(external_json_stable_stringify_default()(new common_types_namespaceObject.ShareStore(new common_types_namespaceObject.Share("0", "0"), ""))));
    const sampleMessageMetadata = {
      message: "Sample message",
      dateAdded: Date.now()
    };
    const MessageMetadataKeys = Object.keys(sampleMessageMetadata);
    const localTransitionShares = [];
    const localTransitionData = [];
    _localMetadataTransitions[0].forEach((x, index) => {
      if (x) {
        localTransitionShares.push(new (external_bn_js_default())(x, "hex"));
      } else {
        localTransitionShares.push(undefined);
      }
      const keys = Object.keys(_localMetadataTransitions[1][index]);
      if (keys.length === AuthMetadataKeys.length && keys.every(val => AuthMetadataKeys.includes(val))) {
        const tempAuth = src_authMetadata.fromJSON(_localMetadataTransitions[1][index]);
        tempAuth.privKey = privKey;
        localTransitionData.push(tempAuth);
      } else if (keys.length === ShareStoreKeys.length && keys.every(val => ShareStoreKeys.includes(val))) {
        localTransitionData.push(common_types_namespaceObject.ShareStore.fromJSON(_localMetadataTransitions[1][index]));
      } else if (keys.length === MessageMetadataKeys.length && keys.every(val => MessageMetadataKeys.includes(val))) {
        localTransitionData.push(_localMetadataTransitions[1][index]);
      } else {
        throw errors["default"]("fromJSON failed. Could not deserialise _localMetadataTransitions");
      }
    });
    if (metadata || lastFetchedCloudMetadata) {
      let tempMetadata;
      let tempCloud;
      let shareToUseForSerialization;

      // if service provider key is missing, we should initialize with one of the existing shares
      // TODO: fix for deleted share
      if (tb.serviceProvider.postboxKey.toString("hex") === "0") {
        const latestPolyIDOnCloud = src_metadata.fromJSON(lastFetchedCloudMetadata).getLatestPublicPolynomial().getPolynomialID();
        const shareIndexesExistInSDK = Object.keys(shares[latestPolyIDOnCloud]);
        const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
        if (shareIndexesExistInSDK.length >= 1) {
          shareToUseForSerialization = shares[latestPolyIDOnCloud][randomIndex];
        }
      }
      if (metadata) tempMetadata = src_metadata.fromJSON(metadata);
      if (lastFetchedCloudMetadata) tempCloud = src_metadata.fromJSON(lastFetchedCloudMetadata);
      await tb.initialize({
        neverInitializeNewKey: true,
        transitionMetadata: tempMetadata,
        previouslyFetchedCloudMetadata: tempCloud,
        previousLocalMetadataTransitions: [localTransitionShares, localTransitionData],
        withShare: shareToUseForSerialization
      });
    } else {
      await tb.initialize({
        neverInitializeNewKey: true
      });
    }
    return tb;
  }
  getStorageLayer() {
    return this.storageLayer;
  }
  getMetadata() {
    if (typeof this.metadata !== "undefined") {
      return this.metadata;
    }
    throw errors.metadataUndefined();
  }
  async initialize(params) {
    // setup initial params/states
    const p = params || {};
    if (p.delete1OutOf1 && !this.manualSync) throw errors.delete1OutOf1OnlyManualSync();
    const {
      withShare,
      importKey,
      importEd25519Seed,
      neverInitializeNewKey,
      transitionMetadata,
      previouslyFetchedCloudMetadata,
      previousLocalMetadataTransitions
    } = p;
    const previousLocalMetadataTransitionsExists = previousLocalMetadataTransitions && previousLocalMetadataTransitions[0].length > 0 && previousLocalMetadataTransitions[1].length > 0;
    const reinitializing = transitionMetadata && previousLocalMetadataTransitionsExists; // are we reinitializing the SDK?
    // in the case we're reinitializing whilst newKeyAssign has not been synced
    const reinitializingWithNewKeyAssign = reinitializing && previouslyFetchedCloudMetadata === undefined;
    let shareStore;
    if (withShare instanceof common_types_namespaceObject.ShareStore) {
      shareStore = withShare;
    } else if (typeof withShare === "object") {
      shareStore = common_types_namespaceObject.ShareStore.fromJSON(withShare);
    } else if (!withShare) {
      // default to use service provider
      // first we see if a share has been kept for us
      const spIncludeLocalMetadataTransitions = reinitializingWithNewKeyAssign;
      const spLocalMetadataTransitions = reinitializingWithNewKeyAssign ? previousLocalMetadataTransitions : undefined;
      const rawServiceProviderShare = await this.getGenericMetadataWithTransitionStates({
        serviceProvider: this.serviceProvider,
        includeLocalMetadataTransitions: spIncludeLocalMetadataTransitions,
        _localMetadataTransitions: spLocalMetadataTransitions,
        fromJSONConstructor: {
          fromJSON(val) {
            return val;
          }
        }
      });
      const noKeyFound = rawServiceProviderShare;
      if (noKeyFound.message === common_types_namespaceObject.KEY_NOT_FOUND) {
        if (neverInitializeNewKey) {
          throw errors["default"]("key has not been generated yet");
        }

        // no metadata set, assumes new user
        // check for serviceprovider migratableKey for import key from service provider for new user
        // provided no importKey is provided ( importKey take precedent )
        if (this.serviceProvider.migratableKey && !(importKey || importEd25519Seed)) {
          // importkey from server provider need to be atomic, hence manual sync is required.
          const tempStateManualSync = this.manualSync; // temp store manual sync flag
          this.manualSync = true; // Setting this as true since _initializeNewKey has a check where for importkey from server provider need to be atomic, hence manual sync is required.
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: this.serviceProvider.migratableKey,
            delete1OutOf1: true
          });
          if (!tempStateManualSync) await this.syncLocalMetadataTransitions(); // Only sync if we were not in manual sync mode, if manual sync is set by developer, they should handle it themselves
          // restore manual sync flag
          this.manualSync = tempStateManualSync;
        } else {
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: importKey,
            delete1OutOf1: p.delete1OutOf1,
            importEd25519Seed
          });
        }

        // return after created new tkey account ( skip other steps)
        return this.getKeyDetails();
      }
      // else we continue with catching up share and metadata
      shareStore = common_types_namespaceObject.ShareStore.fromJSON(rawServiceProviderShare);
    } else {
      throw errors["default"]("Input is not supported");
    }

    // We determine the latest metadata on the SDK and if there has been
    // needed transitions to include
    let currentMetadata;
    let latestCloudMetadata;
    // we fetch the latest metadata for the account from the share
    let latestShareDetails;
    try {
      latestShareDetails = await this.catchupToLatestShare({
        shareStore
      });
    } catch (error) {
      // check if error is not the undefined error
      // if so we don't throw immediately incase there is valid transition metadata
      const err = error;
      const noMetadataExistsForShare = err.code === 1503;
      if (!noMetadataExistsForShare || !reinitializing) {
        throw err;
      }
    }

    // lets check if the cloud metadata has been updated or not from previously if we are reinitializing
    if (reinitializing && !reinitializingWithNewKeyAssign) {
      if (previouslyFetchedCloudMetadata.nonce < latestShareDetails.shareMetadata.nonce) {
        throw errors.fromCode(1104);
      } else if (previouslyFetchedCloudMetadata.nonce > latestShareDetails.shareMetadata.nonce) {
        throw errors.fromCode(1105);
      }
      latestCloudMetadata = previouslyFetchedCloudMetadata;
    } else {
      latestCloudMetadata = latestShareDetails ? latestShareDetails.shareMetadata.clone() : undefined;
    }

    // If we've been provided with transition metadata we use that as the current metadata instead
    // as we want to maintain state before and after serialization.
    // (Given that the checks for cloud metadata pass)
    if (reinitializing) {
      currentMetadata = transitionMetadata;
      this._localMetadataTransitions = previousLocalMetadataTransitions;
    } else {
      currentMetadata = latestShareDetails.shareMetadata;
    }
    this.lastFetchedCloudMetadata = latestCloudMetadata;
    this.metadata = currentMetadata;
    const latestShare = latestShareDetails ? latestShareDetails.latestShare : shareStore;
    this.inputShareStore(latestShare);
    if (importEd25519Seed && this.getEd25519PublicKey()) {
      throw errors["default"]("Ed25119 key already exists");
    }

    // initialize modules
    await this.initializeModules();
    return this.getKeyDetails();
  }

  /**
   * catchupToLatestShare recursively loops fetches metadata of the provided share and checks if there is an encrypted share for it.
   * @param shareStore - share to start of with
   * @param polyID - if specified, polyID to refresh to if it exists
   */
  async catchupToLatestShare(params) {
    const {
      shareStore,
      polyID,
      includeLocalMetadataTransitions
    } = params;
    let shareMetadata;
    try {
      shareMetadata = await this.getAuthMetadata({
        privKey: shareStore.share.share,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      // delete share error
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      const prettyError = await (0,common_types_namespaceObject.prettyPrintError)(err);
      throw errors.authMetadataGetUnavailable(`, ${prettyError.message}`);
    }
    try {
      // if matches specified polyID return it
      if (polyID) {
        if (shareStore.polynomialID === polyID) {
          return {
            latestShare: shareStore,
            shareMetadata
          };
        }
      }
      const nextShare = await shareMetadata.getEncryptedShare(shareStore);
      return await this.catchupToLatestShare({
        shareStore: nextShare,
        polyID,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      // delete share error
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      return {
        latestShare: shareStore,
        shareMetadata
      };
    }
  }
  async reconstructKey(_reconstructKeyMiddleware = true) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const requiredThreshold = pubPoly.getThreshold();
    const pubPolyID = pubPoly.getPolynomialID();

    // check if we have enough shares to meet threshold
    let sharesLeft = requiredThreshold;
    // we don't just check the latest poly but
    // we check if the shares on previous polynomials in our stores have the share indexes we require
    const fullShareList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const shareIndexesRequired = {};
    for (let i = 0; i < fullShareList.length; i += 1) {
      shareIndexesRequired[fullShareList[i]] = true;
    }
    const sharesToInput = [];
    for (let z = this.metadata.polyIDList.length - 1; z >= 0 && sharesLeft > 0; z -= 1) {
      const sharesForPoly = this.shares[this.metadata.polyIDList[z][0]];
      if (sharesForPoly) {
        const shareIndexesForPoly = Object.keys(sharesForPoly);
        for (let k = 0; k < shareIndexesForPoly.length && sharesLeft > 0; k += 1) {
          if (shareIndexesForPoly[k] in shareIndexesRequired) {
            const currentShareForPoly = sharesForPoly[shareIndexesForPoly[k]];
            if (currentShareForPoly.polynomialID === pubPolyID) {
              sharesToInput.push(currentShareForPoly);
            } else {
              const latestShareRes = await this.catchupToLatestShare({
                shareStore: currentShareForPoly,
                polyID: pubPolyID,
                includeLocalMetadataTransitions: true
              });
              if (latestShareRes.latestShare.polynomialID === pubPolyID) {
                sharesToInput.push(latestShareRes.latestShare);
              } else {
                throw new errors(1304, "Share found in unexpected polynomial"); // Share found in unexpected polynomial
              }
            }
            delete shareIndexesRequired[shareIndexesForPoly[k]];
            sharesLeft -= 1;
          }
        }
      }
    }

    // Input shares to ensure atomicity
    sharesToInput.forEach(share => {
      this.inputShareStore(share);
    });
    if (sharesLeft > 0) {
      throw errors.unableToReconstruct(` require ${requiredThreshold} but have ${requiredThreshold - sharesLeft}`);
    }
    const polyShares = Object.keys(this.shares[pubPolyID]);
    const shareArr = [];
    const shareIndexArr = [];
    for (let i = 0; i < requiredThreshold; i += 1) {
      shareArr.push(this.shares[pubPolyID][polyShares[i]].share.share);
      shareIndexArr.push(this.shares[pubPolyID][polyShares[i]].share.shareIndex);
    }
    const privKey = lagrangeInterpolation(shareArr, shareIndexArr);
    // check that priv key regenerated is correct
    const reconstructedPubKey = (0,common_types_namespaceObject.getPubKeyPoint)(privKey);
    if (this.metadata.pubKey.x.cmp(reconstructedPubKey.x) !== 0) {
      throw errors.incorrectReconstruction();
    }
    this.secp256k1Key = privKey;
    const returnObject = {
      allKeys: [privKey]
    };
    if (_reconstructKeyMiddleware && Object.keys(this._reconstructKeyMiddleware).length > 0) {
      // retireve/reconstruct extra keys that live on metadata
      await Promise.all(Object.keys(this._reconstructKeyMiddleware).map(async x => {
        if (Object.prototype.hasOwnProperty.call(this._reconstructKeyMiddleware, x)) {
          const extraKeys = await this._reconstructKeyMiddleware[x]();
          returnObject[x] = extraKeys;
          returnObject.allKeys.push(...extraKeys);
        }
      }));
    }

    // ed25519key
    if (this.getEd25519PublicKey()) {
      const seed = await this.retrieveEd25519Seed();
      if (!seed) {
        throw errors["default"]("Ed25519 seed not found");
      }
      this._ed25519Seed = seed;
    }
    return objectSpread2_default()({
      secp256k1Key: privKey,
      ed25519Seed: this._ed25519Seed
    }, returnObject);
  }
  reconstructLatestPoly() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw errors.unableToReconstruct("not enough shares to reconstruct poly");
    }
    if (new Set(sharesForExistingPoly).size !== sharesForExistingPoly.length) {
      throw errors["default"]("share indexes should be unique");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new common_types_namespaceObject.Point(new (external_bn_js_default())(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    return lagrangeInterpolatePolynomial(pointsArr);
  }
  async deleteShare(shareIndex) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    const shareIndexToDelete = new (external_bn_js_default())(shareIndex, "hex");
    const shareToDelete = this.outputShareStore(shareIndexToDelete);
    if (shareIndexToDelete.cmp(new (external_bn_js_default())("1", "hex")) === 0) {
      throw new errors(1001, "Unable to delete service provider share");
    }

    // Get existing shares
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const newShareIndexes = [];
    existingShareIndexes.forEach(el => {
      const bn = new (external_bn_js_default())(el, "hex");
      if (bn.cmp(shareIndexToDelete) !== 0) {
        newShareIndexes.push(bn.toString("hex"));
      }
    });

    // Update shares
    if (existingShareIndexes.length === newShareIndexes.length) {
      throw errors["default"]("Share index does not exist in latest polynomial");
    } else if (newShareIndexes.length < pubPoly.getThreshold()) {
      throw errors["default"](`Minimum ${pubPoly.getThreshold()} shares are required for tkey. Unable to delete share`);
    }
    const results = await this._refreshShares(pubPoly.getThreshold(), [...newShareIndexes], previousPolyID);
    const newShareStores = results.shareStores;
    await this.addLocalMetadataTransitions({
      input: [{
        message: common_types_namespaceObject.SHARE_DELETED,
        dateAdded: Date.now()
      }],
      privKey: [shareToDelete.share.share]
    });
    return {
      newShareStores
    };
  }
  async generateNewShare() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!this.secp256k1Key) {
      throw errors.privateKeyUnavailable();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const existingShareIndexesBN = existingShareIndexes.map(el => new (external_bn_js_default())(el, "hex"));
    const newShareIndex = new (external_bn_js_default())((0,common_types_namespaceObject.generatePrivateExcludingIndexes)(existingShareIndexesBN));
    const results = await this._refreshShares(pubPoly.getThreshold(), [...existingShareIndexes, newShareIndex.toString("hex")], previousPolyID);
    const newShareStores = results.shareStores;
    return {
      newShareStores,
      newShareIndex
    };
  }
  getEd25519PublicKey() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    return result === null || result === void 0 ? void 0 : result.publicKey;
  }
  async retrieveEd25519Seed() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    const seed = await this.decrypt(result.message);
    this._ed25519Seed = seed;
    return seed;
  }
  async addLocalMetadataTransitions(params) {
    const {
      privKey,
      input
    } = params;
    this._localMetadataTransitions[0] = [...this._localMetadataTransitions[0], ...privKey];
    this._localMetadataTransitions[1] = [...this._localMetadataTransitions[1], ...input];
    if (!this.manualSync) await this.syncLocalMetadataTransitions();
  }
  async syncLocalMetadataTransitions() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!(Array.isArray(this._localMetadataTransitions[0]) && this._localMetadataTransitions[0].length > 0)) return;

    // get lock
    let acquiredLock = false;
    if (this.lastFetchedCloudMetadata) {
      await this.acquireWriteMetadataLock();
      acquiredLock = true;
    }
    try {
      await this.storageLayer.setMetadataStream({
        input: this._localMetadataTransitions[1],
        privKey: this._localMetadataTransitions[0],
        serviceProvider: this.serviceProvider
      });
      this._localMetadataTransitions = [[], []];
      this.lastFetchedCloudMetadata = this.metadata.clone();
    } catch (error) {
      const prettyError = await (0,common_types_namespaceObject.prettyPrintError)(error);
      throw errors.metadataPostFailed(prettyError.message);
    } finally {
      // release lock
      if (acquiredLock) await this.releaseWriteMetadataLock();
    }
  }
  async readMetadata(privKey) {
    return this.storageLayer.getMetadata({
      privKey
    });
  }

  // Returns a new instance of metadata with a clean state. All the previous state will be reset.
  async updateSDK(params) {
    const tb = new ThresholdKey({
      enableLogging: this.enableLogging,
      modules: this.modules,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer,
      manualSync: this.manualSync
    });
    try {
      await tb.initialize({
        neverInitializeNewKey: true,
        withShare: params && params.withShare
      });
    } catch (err) {
      throw errors.fromCode(1103, `${err.message}`);
    }

    // Delete unnecessary polyIDs and shareStores
    const allPolyIDList = tb.metadata.polyIDList;
    let lastValidPolyID;
    Object.keys(this.shares).forEach(x => {
      if (allPolyIDList.find(id => id[0] === x)) {
        lastValidPolyID = x;
      } else {
        delete this.shares[x];
      }
    });

    // catchup to latest shareStore for all latest available shares.
    // TODO: fix edge cases where shares are deleted in the newer polynomials
    // TODO: maybe assign this.shares directly rather than output and inputsharestore.
    const shareStoresForLastValidPolyID = Object.keys(this.shares[lastValidPolyID]).map(x => tb.inputShareStoreSafe(this.outputShareStore(x, lastValidPolyID)));
    await Promise.all(shareStoresForLastValidPolyID);
    return tb;
  }

  // NOTE: This API will be DEPRECATED in the future in favour of inputShareStoreSafe()
  inputShareStore(shareStore) {
    let ss;
    if (shareStore instanceof common_types_namespaceObject.ShareStore) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = common_types_namespaceObject.ShareStore.fromJSON(shareStore);
    } else {
      throw errors["default"]("can only add type ShareStore into shares");
    }
    if (!(ss.polynomialID in this.shares)) {
      this.shares[ss.polynomialID] = {};
    }
    this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
  }

  // inputs a share ensuring that the share is the latest share AND metadata is updated to its latest state
  async inputShareStoreSafe(shareStore, autoUpdateMetadata = false) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    let ss;
    if (shareStore instanceof common_types_namespaceObject.ShareStore) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = common_types_namespaceObject.ShareStore.fromJSON(shareStore);
    } else {
      throw errors["default"]("can only add type ShareStore into shares");
    }
    const polynomialId = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    if (ss.polynomialID !== polynomialId) {
      const latestShareRes = await this.catchupToLatestShare({
        shareStore: ss,
        includeLocalMetadataTransitions: true
      });
      // check if the latest share is part of the current tkey instances
      // to avoid random share getting input into metadata
      if (!latestShareRes.shareMetadata.polyIDList.find(tuple => tuple[0] === polynomialId)) {
        throw errors.fromCode(1307);
      }
      // if latest share's polynomial is not equal with tkey latest polynomial, tkey's metadata is outdated
      if (polynomialId !== latestShareRes.latestShare.polynomialID) {
        if (!autoUpdateMetadata) throw errors["default"](`TKey SDK metadata seems to be outdated because shareIndex: ` + `${latestShareRes.latestShare.share.shareIndex.toString("hex")} has a more recent metadata. Please call updateSDK first`);else this.metadata = latestShareRes.shareMetadata;
      }
      if (!(latestShareRes.latestShare.polynomialID in this.shares)) {
        this.shares[latestShareRes.latestShare.polynomialID] = {};
      }
      this.shares[latestShareRes.latestShare.polynomialID][latestShareRes.latestShare.share.shareIndex.toString("hex")] = latestShareRes.latestShare;
    } else {
      if (!(ss.polynomialID in this.shares)) {
        this.shares[ss.polynomialID] = {};
      }
      this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
    }
  }
  outputShareStore(shareIndex, polyID) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    let shareIndexParsed;
    if (typeof shareIndex === "number") {
      shareIndexParsed = new (external_bn_js_default())(shareIndex);
    } else if (external_bn_js_default().isBN(shareIndex)) {
      shareIndexParsed = shareIndex;
    } else if (typeof shareIndex === "string") {
      shareIndexParsed = new (external_bn_js_default())(shareIndex, "hex");
    }
    let polyIDToSearch;
    if (polyID) {
      polyIDToSearch = polyID;
    } else {
      polyIDToSearch = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    }
    if (!this.metadata.getShareIndexesForPolynomial(polyIDToSearch).includes(shareIndexParsed.toString("hex"))) {
      throw new errors(1002, "no such share index created");
    }
    const shareFromStore = this.shares[polyIDToSearch][shareIndexParsed.toString("hex")];
    if (shareFromStore) return shareFromStore;
    const poly = this.reconstructLatestPoly();
    const shareMap = poly.generateShares([shareIndexParsed]);
    return new common_types_namespaceObject.ShareStore(shareMap[shareIndexParsed.toString("hex")], polyIDToSearch);
  }
  getCurrentShareIndexes() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const latestPolynomial = this.metadata.getLatestPublicPolynomial();
    const latestPolynomialId = latestPolynomial.getPolynomialID();
    const currentShareIndexes = Object.keys(this.shares[latestPolynomialId]);
    return currentShareIndexes;
  }
  getKeyDetails() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const poly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = poly.getPolynomialID();
    const requiredShares = poly.getThreshold() - Object.keys(this.shares[previousPolyID]).length;
    let shareDescriptions = this.metadata.getShareDescription();
    if (shareDescriptions) {
      const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
      shareDescriptions = Object.keys(shareDescriptions).reduce((acc, index) => {
        if (existingShareIndexes.indexOf(index) >= 0) acc[index] = shareDescriptions[index];
        return acc;
      }, {});
    }
    return {
      pubKey: this.metadata.pubKey,
      ed25519PublicKey: this.getEd25519PublicKey(),
      requiredShares,
      threshold: poly.getThreshold(),
      totalShares: this.metadata.getShareIndexesForPolynomial(previousPolyID).length,
      shareDescriptions
    };
  }

  // Auth functions

  generateAuthMetadata(params) {
    const {
      input
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new src_authMetadata(input[i], this.privKey));
    }
    return authMetadatas;
  }
  setAuthMetadata(params) {
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadata = new src_authMetadata(input, this.privKey);
    return this.storageLayer.setMetadata({
      input: authMetadata,
      serviceProvider,
      privKey
    });
  }
  async setAuthMetadataBulk(params) {
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new src_authMetadata(input[i], this.privKey));
    }
    await this.addLocalMetadataTransitions({
      input: authMetadatas,
      serviceProvider,
      privKey
    });
  }
  async getAuthMetadata(params) {
    const raw = await this.getGenericMetadataWithTransitionStates(objectSpread2_default()(objectSpread2_default()({}, params), {}, {
      fromJSONConstructor: src_authMetadata
    }));
    const authMetadata = raw;
    return authMetadata.metadata;
  }

  // fetches the latest metadata potentially searching in local transition states first
  async getGenericMetadataWithTransitionStates(params) {
    if (!(params.serviceProvider && params.serviceProvider.postboxKey.toString("hex") !== "0" || params.privKey)) {
      throw errors["default"]("require either serviceProvider or priv key in getGenericMetadataWithTransitionStates");
    }
    if (params.includeLocalMetadataTransitions) {
      const transitions = params._localMetadataTransitions ? params._localMetadataTransitions : this._localMetadataTransitions;
      let index = null;
      for (let i = transitions[0].length - 1; i >= 0; i -= 1) {
        const x = transitions[0][i];
        if (params.privKey && x && x.cmp(params.privKey) === 0) index = i;else if (params.serviceProvider && !x) index = i;
        if (index !== null) break;
      }
      if (index !== null) {
        return transitions[1][index];
      }
    }
    let raw;
    try {
      raw = await this.storageLayer.getMetadata(params);
    } catch (err) {
      const prettyError = await (0,common_types_namespaceObject.prettyPrintError)(err);
      throw errors.metadataGetFailed(prettyError.message);
    }
    if (raw.message === common_types_namespaceObject.SHARE_DELETED) {
      throw errors.fromCode(1308);
    }
    return params.fromJSONConstructor.fromJSON(raw);
  }

  // Lock functions
  async acquireWriteMetadataLock() {
    if (this.haveWriteMetadataLock) return this.metadata.nonce;
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }

    // we check the metadata of a random share we have on the latest polynomial we know that reflects the cloud
    // below we cater for if we have an existing share or need to create the share in the SDK
    let randomShareStore;
    const latestPolyIDOnCloud = this.lastFetchedCloudMetadata.getLatestPublicPolynomial().getPolynomialID();
    const shareIndexesExistInSDK = Object.keys(this.shares[latestPolyIDOnCloud]);
    const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
    if (shareIndexesExistInSDK.length >= 1) {
      randomShareStore = this.shares[latestPolyIDOnCloud][randomIndex];
    } else {
      randomShareStore = this.outputShareStore(randomIndex, latestPolyIDOnCloud);
    }
    const latestRes = await this.catchupToLatestShare({
      shareStore: randomShareStore
    });
    const latestMetadata = latestRes.shareMetadata;

    // read errors for what each means
    if (latestMetadata.nonce > this.lastFetchedCloudMetadata.nonce) {
      throw errors.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
           being lower than last written metadata nonce (${latestMetadata.nonce}). perhaps update metadata SDK (create new tKey and init)`);
    } else if (latestMetadata.nonce < this.lastFetchedCloudMetadata.nonce) {
      throw errors.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
      being higher than last written metadata nonce (${latestMetadata.nonce}). this should never happen as it 
      should only ever be updated by getting metadata)`);
    }
    const res = await this.storageLayer.acquireWriteLock({
      privKey: this.privKey
    });
    if (res.status !== 1) throw errors.acquireLockFailed(`lock cannot be acquired from storage layer status code: ${res.status}`);

    // increment metadata nonce for write session
    // this.metadata.nonce += 1;
    this.haveWriteMetadataLock = res.id;
    return this.metadata.nonce;
  }
  async releaseWriteMetadataLock() {
    if (!this.haveWriteMetadataLock) throw errors.releaseLockFailed("releaseWriteMetadataLock - don't have metadata lock to release");
    const res = await this.storageLayer.releaseWriteLock({
      privKey: this.privKey,
      id: this.haveWriteMetadataLock
    });
    if (res.status !== 1) throw errors.releaseLockFailed(`lock cannot be released from storage layer status code: ${res.status}`);
    this.haveWriteMetadataLock = "";
  }

  // Module functions

  async _syncShareMetadata(adjustScopedStore) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const shareArray = this.getAllShareStoresForLatestPolynomial().map(x => x.share.share);
    await this.syncMultipleShareMetadata(shareArray, adjustScopedStore);
  }
  async syncMultipleShareMetadata(shares, adjustScopedStore) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    this.metadata.nonce += 1;
    const newMetadataPromise = shares.map(async share => {
      const newMetadata = this.metadata.clone();
      let specificShareMetadata;
      try {
        specificShareMetadata = await this.getAuthMetadata({
          privKey: share,
          includeLocalMetadataTransitions: true
        });
      } catch (err) {
        const prettyError = await (0,common_types_namespaceObject.prettyPrintError)(err);
        throw errors.authMetadataGetUnavailable(prettyError.message);
      }
      let scopedStoreToBeSet;
      if (adjustScopedStore) {
        scopedStoreToBeSet = adjustScopedStore(specificShareMetadata.scopedStore);
      } else {
        scopedStoreToBeSet = specificShareMetadata.scopedStore;
      }
      newMetadata.scopedStore = scopedStoreToBeSet;
      return newMetadata;
    });
    const newMetadata = await Promise.all(newMetadataPromise);
    return this.setAuthMetadataBulk({
      input: newMetadata,
      privKey: shares
    });
  }
  _addRefreshMiddleware(moduleName, middleware) {
    this._refreshMiddleware[moduleName] = middleware;
  }
  _addReconstructKeyMiddleware(moduleName, middleware) {
    this._reconstructKeyMiddleware[moduleName] = middleware;
  }
  _addShareSerializationMiddleware(serialize, deserialize) {
    this._shareSerializationMiddleware = {
      serialize,
      deserialize
    };
  }
  _setDeviceStorage(storeDeviceStorage) {
    if (this.storeDeviceShare) {
      throw errors["default"]("storeDeviceShare already set");
    }
    this.storeDeviceShare = storeDeviceStorage;
  }
  async addShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    this.metadata.addShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async deleteShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    this.metadata.deleteShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async updateShareDescription(shareIndex, oldDescription, newDescription, updateMetadata) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    this.metadata.updateShareDescription(shareIndex, oldDescription, newDescription);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async encrypt(data) {
    if (!this.privKey) throw errors.privateKeyUnavailable();
    return (0,common_types_namespaceObject.encrypt)((0,common_types_namespaceObject.getPubKeyECC)(this.privKey), data);
  }
  async decrypt(encryptedMessage) {
    if (!this.privKey) throw errors.privateKeyUnavailable();
    return (0,common_types_namespaceObject.decrypt)((0,common_types_namespaceObject.toPrivKeyECC)(this.privKey), encryptedMessage);
  }
  async _setTKeyStoreItem(moduleName, data) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const encryptedData = await this.encrypt(Buffer.from(external_json_stable_stringify_default()(data)));
    const duplicateItemIndex = decryptedItems.findIndex(x => x.id === data.id);
    if (duplicateItemIndex > -1) {
      rawTkeyStoreItems[duplicateItemIndex] = encryptedData;
    } else {
      rawTkeyStoreItems.push(encryptedData);
    }

    // update metadataStore
    this.metadata.setTkeyStoreDomain(moduleName, rawTkeyStoreItems);
    await this._syncShareMetadata();
  }
  async _deleteTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const finalItems = decryptedItems.filter(x => x.id !== id);
    this.metadata.setTkeyStoreDomain(moduleName, finalItems);
    await this._syncShareMetadata();
  }
  async getTKeyStore(moduleName) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    return decryptedItems;
  }
  async getTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async x => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const item = decryptedItems.find(x => x.id === id);
    return item;
  }

  // Import export shares
  async outputShare(shareIndex, type) {
    const {
      share
    } = this.outputShareStore(shareIndex).share;
    if (!type) return share;
    return this._shareSerializationMiddleware.serialize(share, type);
  }
  async inputShare(share, type) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    let shareStore;
    if (!type) shareStore = this.metadata.shareToShareStore(share);else {
      const deserialized = await this._shareSerializationMiddleware.deserialize(share, type);
      shareStore = this.metadata.shareToShareStore(deserialized);
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const fullShareIndexesList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    if (!fullShareIndexesList.includes(shareStore.share.shareIndex.toString("hex"))) {
      throw errors["default"]("Latest poly doesn't include this share");
    }
    await this.inputShareStoreSafe(shareStore);
  }
  toJSON() {
    return {
      shares: this.shares,
      enableLogging: this.enableLogging,
      privKey: this.privKey ? this.privKey.toString("hex") : undefined,
      metadata: this.metadata,
      lastFetchedCloudMetadata: this.lastFetchedCloudMetadata,
      _localMetadataTransitions: this._localMetadataTransitions,
      manualSync: this.manualSync,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer
    };
  }
  getAllShareStoresForLatestPolynomial() {
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw errors.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new common_types_namespaceObject.Point(new (external_bn_js_default())(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    const currentPoly = lagrangeInterpolatePolynomial(pointsArr);
    const allExistingShares = currentPoly.generateShares(existingShareIndexes);
    const shareArray = existingShareIndexes.map(shareIndex => {
      return this.metadata.shareToShareStore(allExistingShares[shareIndex].share);
    });
    return shareArray;
  }

  /// Destructive method. All data will be wiped!
  async CRITICAL_deleteTkey() {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    if (this._localMetadataTransitions[0].length > 0 || this._localMetadataTransitions[1].length > 0) {
      throw errors["default"]("Please sync all local state before calling this function");
    }

    // Construct all shares
    const shareArray = this.getAllShareStoresForLatestPolynomial();
    await this.addLocalMetadataTransitions({
      input: [...Array(shareArray.length).fill({
        message: common_types_namespaceObject.SHARE_DELETED,
        dateAdded: Date.now()
      }), {
        message: common_types_namespaceObject.KEY_NOT_FOUND
      }],
      privKey: [...shareArray.map(x => x.share.share), undefined]
    });
    await this.syncLocalMetadataTransitions(); // forcesync

    this.privKey = undefined;
    this.metadata = undefined;
    this.shares = {};
    this.lastFetchedCloudMetadata = undefined;
  }
  getApi() {
    return {
      getMetadata: this.getMetadata.bind(this),
      getStorageLayer: this.getStorageLayer.bind(this),
      initialize: this.initialize.bind(this),
      catchupToLatestShare: this.catchupToLatestShare.bind(this),
      _syncShareMetadata: this._syncShareMetadata.bind(this),
      _addRefreshMiddleware: this._addRefreshMiddleware.bind(this),
      _addReconstructKeyMiddleware: this._addReconstructKeyMiddleware.bind(this),
      _addShareSerializationMiddleware: this._addShareSerializationMiddleware.bind(this),
      addShareDescription: this.addShareDescription.bind(this),
      generateNewShare: this.generateNewShare.bind(this),
      inputShareStore: this.inputShareStore.bind(this),
      inputShareStoreSafe: this.inputShareStoreSafe.bind(this),
      outputShareStore: this.outputShareStore.bind(this),
      inputShare: this.inputShare.bind(this),
      outputShare: this.outputShare.bind(this),
      _setDeviceStorage: this._setDeviceStorage.bind(this),
      encrypt: this.encrypt.bind(this),
      decrypt: this.decrypt.bind(this),
      getTKeyStore: this.getTKeyStore.bind(this),
      getTKeyStoreItem: this.getTKeyStoreItem.bind(this),
      _setTKeyStoreItem: this._setTKeyStoreItem.bind(this),
      _deleteTKeyStoreItem: this._deleteTKeyStoreItem.bind(this),
      deleteShare: this.deleteShare.bind(this)
    };
  }
  setModuleReferences() {
    Object.keys(this.modules).map(x => this.modules[x].setModuleReferences(this.getApi()));
  }
  async initializeModules() {
    return Promise.all(Object.keys(this.modules).map(x => this.modules[x].initialize()));
  }
  async _refreshShares(threshold, newShareIndexes, previousPolyID) {
    if (!this.metadata) {
      throw errors.metadataUndefined();
    }
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    if (threshold > newShareIndexes.length) {
      throw errors["default"](`threshold should not be greater than share indexes. ${threshold} > ${newShareIndexes.length}`);
    }

    // update metadata nonce
    this.metadata.nonce += 1;
    const poly = generateRandomPolynomial(threshold - 1, this.privKey);
    const shares = poly.generateShares(newShareIndexes);
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[previousPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw errors.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new common_types_namespaceObject.Point(new (external_bn_js_default())(sharesForExistingPoly[i], "hex"), this.shares[previousPolyID][sharesForExistingPoly[i]].share.share));
    }
    const oldPoly = lagrangeInterpolatePolynomial(pointsArr);
    const shareIndexesNeedingEncryption = [];
    for (let index = 0; index < existingShareIndexes.length; index += 1) {
      const shareIndexHex = existingShareIndexes[index];
      // define shares that need encryption/relaying
      if (newShareIndexes.includes(shareIndexHex)) {
        shareIndexesNeedingEncryption.push(shareIndexHex);
      }
    }

    // add metadata new poly to metadata
    this.metadata.addFromPolynomialAndShares(poly, shares);

    // change to share stores for public storing
    const oldShareStores = {};
    const newShareStores = {};
    const polyID = poly.getPolynomialID();
    newShareIndexes.forEach(shareIndexHex => {
      newShareStores[shareIndexHex] = new common_types_namespaceObject.ShareStore(shares[shareIndexHex], polyID);
    });

    // evaluate oldPoly for old shares and set new metadata with encrypted share for new polynomial

    const m = this.metadata.clone();
    const newScopedStore = {};
    const sharesToPush = await Promise.all(shareIndexesNeedingEncryption.map(async shareIndex => {
      const oldShare = oldPoly.polyEval(new (external_bn_js_default())(shareIndex, "hex"));
      const encryptedShare = await (0,common_types_namespaceObject.encrypt)((0,common_types_namespaceObject.getPubKeyECC)(oldShare), Buffer.from(JSON.stringify(newShareStores[shareIndex])));
      newScopedStore[(0,common_types_namespaceObject.getPubKeyPoint)(oldShare).x.toString("hex")] = encryptedShare;
      oldShareStores[shareIndex] = new common_types_namespaceObject.ShareStore(new common_types_namespaceObject.Share(shareIndex, oldShare), previousPolyID);
      return oldShare;
    }));
    m.setScopedStore("encryptedShares", newScopedStore);
    const metadataToPush = Array(sharesToPush.length).fill(m);

    // run refreshShare middleware
    // If a shareIndex is left out during refresh shares, we assume that it being explicitly deleted.
    for (const moduleName in this._refreshMiddleware) {
      if (Object.prototype.hasOwnProperty.call(this._refreshMiddleware, moduleName)) {
        const adjustedGeneralStore = this._refreshMiddleware[moduleName](this.metadata.getGeneralStoreDomain(moduleName), oldShareStores, newShareStores);
        if (!adjustedGeneralStore) this.metadata.deleteGeneralStoreDomain(moduleName);else this.metadata.setGeneralStoreDomain(moduleName, adjustedGeneralStore);
      }
    }
    const newShareMetadataToPush = [];
    const newShareStoreSharesToPush = newShareIndexes.map(shareIndex => {
      const me = this.metadata.clone();
      newShareMetadataToPush.push(me);
      return newShareStores[shareIndex].share.share;
    });
    const AuthMetadatas = this.generateAuthMetadata({
      input: [...metadataToPush, ...newShareMetadataToPush]
    });

    // Combine Authmetadata and service provider ShareStore
    await this.addLocalMetadataTransitions({
      input: [...AuthMetadatas, newShareStores["1"]],
      privKey: [...sharesToPush, ...newShareStoreSharesToPush, undefined]
    });

    // update this.shares with these new shares
    for (let index = 0; index < newShareIndexes.length; index += 1) {
      const shareIndex = newShareIndexes[index];
      this.inputShareStore(newShareStores[shareIndex]);
    }
    // await this.releaseWriteMetadataLock();
    return {
      shareStores: newShareStores
    };
  }
  async _initializeNewKey({
    determinedShare,
    initializeModules,
    importedKey,
    importEd25519Seed,
    delete1OutOf1
  } = {}) {
    if (!importedKey) {
      const tmpPriv = generatePrivateBN();
      this.secp256k1Key = tmpPriv;
    } else {
      this.secp256k1Key = importedKey;
    }

    // create a random poly and respective shares
    // 1 is defined as the serviceProvider share
    // 0 is for tKey
    const shareIndexForDeviceStorage = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)([new (external_bn_js_default())(1), new (external_bn_js_default())(0)]);
    const shareIndexes = [new (external_bn_js_default())(1), shareIndexForDeviceStorage];
    let poly;
    if (determinedShare) {
      const shareIndexForDeterminedShare = (0,common_types_namespaceObject.generatePrivateExcludingIndexes)([new (external_bn_js_default())(1), new (external_bn_js_default())(0)]);
      poly = generateRandomPolynomial(1, this.privKey, [new common_types_namespaceObject.Share(shareIndexForDeterminedShare, determinedShare)]);
      shareIndexes.push(shareIndexForDeterminedShare);
    } else {
      poly = generateRandomPolynomial(1, this.privKey);
    }
    const shares = poly.generateShares(shareIndexes);

    // create metadata to be stored
    const metadata = new src_metadata((0,common_types_namespaceObject.getPubKeyPoint)(this.privKey));
    metadata.addFromPolynomialAndShares(poly, shares);
    const serviceProviderShare = shares[shareIndexes[0].toString("hex")];
    const shareStore = new common_types_namespaceObject.ShareStore(serviceProviderShare, poly.getPolynomialID());
    this.metadata = metadata;

    // setup ed25519 seed after metadata is set
    // import/gen ed25519 seed
    await this.setupEd25519Seed(importEd25519Seed);

    // initialize modules
    if (initializeModules) {
      await this.initializeModules();
    }
    const metadataToPush = [];
    const sharesToPush = shareIndexes.map(shareIndex => {
      metadataToPush.push(this.metadata);
      return shares[shareIndex.toString("hex")].share;
    });
    const authMetadatas = this.generateAuthMetadata({
      input: metadataToPush
    });

    // because this is the first time we're setting metadata there is no need to acquire a lock
    // acquireLock: false. Force push
    await this.addLocalMetadataTransitions({
      input: [...authMetadatas, shareStore],
      privKey: [...sharesToPush, undefined]
    });
    if (delete1OutOf1) {
      await this.addLocalMetadataTransitions({
        input: [{
          message: common_types_namespaceObject.ONE_KEY_DELETE_NONCE
        }],
        privKey: [this.serviceProvider.postboxKey]
      });
    }

    // store metadata on metadata respective to shares
    for (let index = 0; index < shareIndexes.length; index += 1) {
      const shareIndex = shareIndexes[index];
      // also add into our share store
      this.inputShareStore(new common_types_namespaceObject.ShareStore(shares[shareIndex.toString("hex")], poly.getPolynomialID()));
    }
    if (this.storeDeviceShare) {
      await this.storeDeviceShare(new common_types_namespaceObject.ShareStore(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()));
    }
    const result = {
      secp256k1Key: this.privKey,
      deviceShare: new common_types_namespaceObject.ShareStore(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()),
      userShare: undefined
    };
    if (determinedShare) {
      result.userShare = new common_types_namespaceObject.ShareStore(shares[shareIndexes[2].toString("hex")], poly.getPolynomialID());
    }
    return result;
  }
  async importEd25519Seed(seed) {
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    if (this.getEd25519PublicKey()) {
      throw errors["default"]("Ed25519 key already exists");
    }

    // derive key pair (scalar, public key point) from seed
    const keyPair = (0,torus_js_namespaceObject.getEd25519ExtendedPublicKey)(seed);
    this.metadata.setGeneralStoreDomain(ed25519SeedConst, {
      message: await this.encrypt(seed),
      publicKey: keyPair.point.encode("hex", false)
    });
    this._ed25519Seed = seed;
  }
  async setupEd25519Seed(seed) {
    if (!this.privKey) {
      throw errors.privateKeyUnavailable();
    }
    let seedToUse = seed;
    if (!seed) {
      const newEd25519Seed = await getRandomBytes(32);
      seedToUse = Buffer.from(newEd25519Seed);
    }
    await this.importEd25519Seed(seedToUse);
  }
}
/* harmony default export */ const core = (ThresholdKey);
;// CONCATENATED MODULE: ./src/index.ts





module.exports = __webpack_exports__;
/******/ })()
;