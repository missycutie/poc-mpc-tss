import {
  sha512
} from "./chunk-URIYOKWX.js";
import {
  getRandomBytes
} from "./chunk-H6CUK76M.js";
import {
  _defineProperty,
  _objectSpread2,
  generateJsonRPCObject,
  get,
  post,
  require_elliptic,
  require_json_stable_stringify,
  require_loglevel,
  setAPIKey,
  setEmbedHost
} from "./chunk-NYBMST6M.js";
import {
  keccak256,
  wrapHash
} from "./chunk-O35336FG.js";
import {
  require_bn
} from "./chunk-J3UDRN3X.js";
import {
  __toESM
} from "./chunk-OL46QLBJ.js";

// node_modules/@toruslabs/torus.js/dist/lib.esm/constants.js
var JRPC_METHODS = {
  GET_OR_SET_KEY: "GetPubKeyOrKeyAssign",
  VERIFIER_LOOKUP: "VerifierLookupRequest",
  COMMITMENT_REQUEST: "CommitmentRequest",
  IMPORT_SHARES: "ImportShares",
  GET_SHARE_OR_KEY_ASSIGN: "GetShareOrKeyAssign"
};
var SAPPHIRE_METADATA_URL = "https://node-1.node.web3auth.io/metadata";
var SAPPHIRE_DEVNET_METADATA_URL = "https://node-1.dev-node.web3auth.io/metadata";

// node_modules/@toruslabs/torus.js/dist/lib.esm/Point.js
var import_bn = __toESM(require_bn());
var Point = class {
  constructor(x, y, ecCurve) {
    _defineProperty(this, "x", void 0);
    _defineProperty(this, "y", void 0);
    _defineProperty(this, "ecCurve", void 0);
    this.x = new import_bn.default(x, "hex");
    this.y = new import_bn.default(y, "hex");
    this.ecCurve = ecCurve;
  }
  encode(enc) {
    switch (enc) {
      case "arr":
        return Buffer.concat([Buffer.from("04", "hex"), Buffer.from(this.x.toString("hex", 64), "hex"), Buffer.from(this.y.toString("hex", 64), "hex")]);
      case "elliptic-compressed": {
        const key = this.ecCurve.keyFromPublic({
          x: this.x.toString("hex", 64),
          y: this.y.toString("hex", 64)
        }, "hex");
        return Buffer.from(key.getPublic(true, "hex"));
      }
      default:
        throw new Error("encoding doesn't exist in Point");
    }
  }
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/Polynomial.js
var import_bn3 = __toESM(require_bn());

// node_modules/@toruslabs/torus.js/dist/lib.esm/Share.js
var import_bn2 = __toESM(require_bn());
var Share = class _Share {
  constructor(shareIndex, share) {
    _defineProperty(this, "share", void 0);
    _defineProperty(this, "shareIndex", void 0);
    this.share = new import_bn2.default(share, "hex");
    this.shareIndex = new import_bn2.default(shareIndex, "hex");
  }
  static fromJSON(value) {
    const {
      share,
      shareIndex
    } = value;
    return new _Share(shareIndex, share);
  }
  toJSON() {
    return {
      share: this.share.toString("hex", 64),
      shareIndex: this.shareIndex.toString("hex", 64)
    };
  }
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/Polynomial.js
var Polynomial = class {
  constructor(polynomial, ecCurve) {
    _defineProperty(this, "polynomial", void 0);
    _defineProperty(this, "ecCurve", void 0);
    this.polynomial = polynomial;
    this.ecCurve = ecCurve;
  }
  getThreshold() {
    return this.polynomial.length;
  }
  polyEval(x) {
    const tmpX = new import_bn3.default(x, "hex");
    let xi = new import_bn3.default(tmpX);
    let sum = new import_bn3.default(0);
    sum = sum.add(this.polynomial[0]);
    for (let i = 1; i < this.polynomial.length; i += 1) {
      const tmp = xi.mul(this.polynomial[i]);
      sum = sum.add(tmp);
      sum = sum.umod(this.ecCurve.n);
      xi = xi.mul(new import_bn3.default(tmpX));
      xi = xi.umod(this.ecCurve.n);
    }
    return sum;
  }
  generateShares(shareIndexes) {
    const newShareIndexes = shareIndexes.map((index) => {
      if (typeof index === "number") {
        return new import_bn3.default(index);
      }
      if (index instanceof import_bn3.default) {
        return index;
      }
      if (typeof index === "string") {
        return new import_bn3.default(index, "hex");
      }
      return index;
    });
    const shares = {};
    for (let x = 0; x < newShareIndexes.length; x += 1) {
      shares[newShareIndexes[x].toString("hex", 64)] = new Share(newShareIndexes[x], this.polyEval(newShareIndexes[x]));
    }
    return shares;
  }
};

// node_modules/@toruslabs/torus.js/node_modules/@toruslabs/constants/dist/lib.esm/constants.js
var TORUS_LEGACY_NETWORK = {
  MAINNET: "mainnet",
  TESTNET: "testnet",
  CYAN: "cyan",
  AQUA: "aqua",
  CELESTE: "celeste"
};
var TORUS_SAPPHIRE_NETWORK = {
  SAPPHIRE_DEVNET: "sapphire_devnet",
  SAPPHIRE_MAINNET: "sapphire_mainnet"
};
var PROXY_CONTRACT_ADDRESS = {
  [TORUS_LEGACY_NETWORK.MAINNET]: "0xf20336e16B5182637f09821c27BDe29b0AFcfe80",
  [TORUS_LEGACY_NETWORK.TESTNET]: "0xd084604e5FA387FbC2Da8bAab07fDD6aDED4614A",
  [TORUS_LEGACY_NETWORK.CYAN]: "0x9f072ba19b3370e512aa1b4bfcdaf97283168005",
  [TORUS_LEGACY_NETWORK.AQUA]: "0x29Dea82a0509153b91040ee13cDBba0f03efb625",
  [TORUS_LEGACY_NETWORK.CELESTE]: "0x6Bffb4e89453069E7487f0fa5c9f4a2D771cce6c"
};
var LEGACY_NETWORKS_ROUTE_MAP = {
  [TORUS_LEGACY_NETWORK.AQUA]: {
    migrationCompleted: true,
    networkIdentifier: "aqua",
    networkMigratedTo: TORUS_SAPPHIRE_NETWORK.SAPPHIRE_MAINNET
  },
  [TORUS_LEGACY_NETWORK.CELESTE]: {
    migrationCompleted: true,
    networkIdentifier: "celeste",
    networkMigratedTo: TORUS_SAPPHIRE_NETWORK.SAPPHIRE_MAINNET
  },
  [TORUS_LEGACY_NETWORK.CYAN]: {
    migrationCompleted: true,
    networkIdentifier: "cyan",
    networkMigratedTo: TORUS_SAPPHIRE_NETWORK.SAPPHIRE_MAINNET
  },
  [TORUS_LEGACY_NETWORK.MAINNET]: {
    migrationCompleted: true,
    networkIdentifier: "mainnet",
    networkMigratedTo: TORUS_SAPPHIRE_NETWORK.SAPPHIRE_MAINNET
  },
  [TORUS_LEGACY_NETWORK.TESTNET]: {
    migrationCompleted: true,
    networkIdentifier: "teal",
    networkMigratedTo: TORUS_SAPPHIRE_NETWORK.SAPPHIRE_DEVNET
  }
};
var NETWORK_MAP = {
  [TORUS_LEGACY_NETWORK.MAINNET]: "mainnet",
  [TORUS_LEGACY_NETWORK.TESTNET]: "goerli",
  [TORUS_LEGACY_NETWORK.CYAN]: "polygon-mainnet",
  [TORUS_LEGACY_NETWORK.AQUA]: "polygon-mainnet",
  [TORUS_LEGACY_NETWORK.CELESTE]: "polygon-mainnet"
};
var SIGNER_MAP = {
  [TORUS_SAPPHIRE_NETWORK.SAPPHIRE_MAINNET]: "https://signer.web3auth.io",
  [TORUS_SAPPHIRE_NETWORK.SAPPHIRE_DEVNET]: "https://signer.web3auth.io",
  [TORUS_LEGACY_NETWORK.MAINNET]: "https://signer.web3auth.io",
  [TORUS_LEGACY_NETWORK.TESTNET]: "https://signer.web3auth.io",
  [TORUS_LEGACY_NETWORK.CYAN]: "https://signer-polygon.web3auth.io",
  [TORUS_LEGACY_NETWORK.AQUA]: "https://signer-polygon.web3auth.io",
  [TORUS_LEGACY_NETWORK.CELESTE]: "https://signer-polygon.web3auth.io"
};
var METADATA_MAP = {
  [TORUS_LEGACY_NETWORK.MAINNET]: "https://metadata.web3auth.io",
  [TORUS_LEGACY_NETWORK.TESTNET]: "https://metadata.web3auth.io",
  [TORUS_LEGACY_NETWORK.CYAN]: "https://metadata.web3auth.io",
  [TORUS_LEGACY_NETWORK.AQUA]: "https://metadata.web3auth.io",
  [TORUS_LEGACY_NETWORK.CELESTE]: "https://metadata.web3auth.io"
};
var KEY_TYPE = {
  SECP256K1: "secp256k1",
  ED25519: "ed25519"
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/torus.js
var import_bn9 = __toESM(require_bn());
var import_elliptic4 = __toESM(require_elliptic());

// node_modules/@toruslabs/torus.js/dist/lib.esm/config.js
var config = {
  logRequestTracing: false
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/loglevel.js
var import_loglevel = __toESM(require_loglevel());
var log = import_loglevel.default.getLogger("torus.js");
log.disableAll();

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/errorUtils.js
var GetOrSetNonceError = class extends Error {
};

// node_modules/@toruslabs/torus.js/node_modules/@toruslabs/eccrypto/dist/lib.esm/index.js
var import_elliptic = __toESM(require_elliptic());
var ec = new import_elliptic.ec("secp256k1");
var browserCrypto = globalThis.crypto || globalThis.msCrypto || {};
var subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;
var EC_GROUP_ORDER = Buffer.from("fffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141", "hex");
var ZERO32 = Buffer.alloc(32, 0);
function assert(condition, message) {
  if (!condition) {
    throw new Error(message || "Assertion failed");
  }
}
function isScalar(x) {
  return Buffer.isBuffer(x) && x.length === 32;
}
function isValidPrivateKey(privateKey) {
  if (!isScalar(privateKey)) {
    return false;
  }
  return privateKey.compare(ZERO32) > 0 && // > 0
  privateKey.compare(EC_GROUP_ORDER) < 0;
}
function equalConstTime(b1, b2) {
  if (b1.length !== b2.length) {
    return false;
  }
  let res = 0;
  for (let i = 0; i < b1.length; i++) {
    res |= b1[i] ^ b2[i];
  }
  return res === 0;
}
function randomBytes(size) {
  if (typeof browserCrypto.getRandomValues === "undefined") {
    return Buffer.from(browserCrypto.randomBytes(size));
  }
  const arr = new Uint8Array(size);
  browserCrypto.getRandomValues(arr);
  return Buffer.from(arr);
}
async function sha5122(msg) {
  if (!browserCrypto.createHash) {
    const hash2 = await subtle.digest("SHA-512", msg);
    const result2 = new Uint8Array(hash2);
    return result2;
  }
  const hash = browserCrypto.createHash("sha512");
  const result = hash.update(msg).digest();
  return new Uint8Array(result);
}
function getAes(op) {
  return async function(iv, key, data) {
    if (subtle && subtle[op] && subtle.importKey) {
      const importAlgorithm = {
        name: "AES-CBC"
      };
      const cryptoKey = await subtle.importKey("raw", key, importAlgorithm, false, [op]);
      const encAlgorithm = {
        name: "AES-CBC",
        iv
      };
      const result = await subtle[op](encAlgorithm, cryptoKey, data);
      return Buffer.from(new Uint8Array(result));
    } else if (op === "encrypt" && browserCrypto.createCipheriv) {
      const cipher = browserCrypto.createCipheriv("aes-256-cbc", key, iv);
      const firstChunk = cipher.update(data);
      const secondChunk = cipher.final();
      return Buffer.concat([firstChunk, secondChunk]);
    } else if (op === "decrypt" && browserCrypto.createDecipheriv) {
      const decipher = browserCrypto.createDecipheriv("aes-256-cbc", key, iv);
      const firstChunk = decipher.update(data);
      const secondChunk = decipher.final();
      return Buffer.concat([firstChunk, secondChunk]);
    }
    throw new Error(`Unsupported operation: ${op}`);
  };
}
var aesCbcEncrypt = getAes("encrypt");
var aesCbcDecrypt = getAes("decrypt");
async function hmacSha256Sign(key, msg) {
  if (!browserCrypto.createHmac) {
    const importAlgorithm = {
      name: "HMAC",
      hash: {
        name: "SHA-256"
      }
    };
    const cryptoKey = await subtle.importKey("raw", new Uint8Array(key), importAlgorithm, false, ["sign", "verify"]);
    const sig = await subtle.sign("HMAC", cryptoKey, msg);
    const result2 = Buffer.from(new Uint8Array(sig));
    return result2;
  }
  const hmac = browserCrypto.createHmac("sha256", Buffer.from(key));
  hmac.update(msg);
  const result = hmac.digest();
  return result;
}
async function hmacSha256Verify(key, msg, sig) {
  const expectedSig = await hmacSha256Sign(key, msg);
  return equalConstTime(expectedSig, sig);
}
var generatePrivate = function() {
  let privateKey = randomBytes(32);
  while (!isValidPrivateKey(privateKey)) {
    privateKey = randomBytes(32);
  }
  return privateKey;
};
var getPublic = function(privateKey) {
  assert(privateKey.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKey), "Bad private key");
  return Buffer.from(ec.keyFromPrivate(privateKey).getPublic("array"));
};
var derive = async function(privateKeyA, publicKeyB) {
  assert(Buffer.isBuffer(privateKeyA), "Bad private key");
  assert(Buffer.isBuffer(publicKeyB), "Bad public key");
  assert(privateKeyA.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKeyA), "Bad private key");
  assert(publicKeyB.length === 65 || publicKeyB.length === 33, "Bad public key");
  if (publicKeyB.length === 65) {
    assert(publicKeyB[0] === 4, "Bad public key");
  }
  if (publicKeyB.length === 33) {
    assert(publicKeyB[0] === 2 || publicKeyB[0] === 3, "Bad public key");
  }
  const keyA = ec.keyFromPrivate(privateKeyA);
  const keyB = ec.keyFromPublic(publicKeyB);
  const Px = keyA.derive(keyB.getPublic());
  return Buffer.from(Px.toArray());
};
var deriveUnpadded = derive;
var derivePadded = async function(privateKeyA, publicKeyB) {
  assert(Buffer.isBuffer(privateKeyA), "Bad private key");
  assert(Buffer.isBuffer(publicKeyB), "Bad public key");
  assert(privateKeyA.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKeyA), "Bad private key");
  assert(publicKeyB.length === 65 || publicKeyB.length === 33, "Bad public key");
  if (publicKeyB.length === 65) {
    assert(publicKeyB[0] === 4, "Bad public key");
  }
  if (publicKeyB.length === 33) {
    assert(publicKeyB[0] === 2 || publicKeyB[0] === 3, "Bad public key");
  }
  const keyA = ec.keyFromPrivate(privateKeyA);
  const keyB = ec.keyFromPublic(publicKeyB);
  const Px = keyA.derive(keyB.getPublic());
  return Buffer.from(Px.toString(16, 64), "hex");
};
var encrypt = async function(publicKeyTo, msg, opts) {
  opts = opts || {};
  let ephemPrivateKey = opts.ephemPrivateKey || randomBytes(32);
  while (!isValidPrivateKey(ephemPrivateKey)) {
    ephemPrivateKey = opts.ephemPrivateKey || randomBytes(32);
  }
  const ephemPublicKey = getPublic(ephemPrivateKey);
  const Px = await deriveUnpadded(ephemPrivateKey, publicKeyTo);
  const hash = await sha5122(Px);
  const iv = opts.iv || randomBytes(16);
  const encryptionKey = hash.slice(0, 32);
  const macKey = hash.slice(32);
  const data = await aesCbcEncrypt(iv, Buffer.from(encryptionKey), msg);
  const ciphertext = data;
  const dataToMac = Buffer.concat([iv, ephemPublicKey, ciphertext]);
  const mac = await hmacSha256Sign(Buffer.from(macKey), dataToMac);
  return {
    iv,
    ephemPublicKey,
    ciphertext,
    mac
  };
};
var decrypt = async function(privateKey, opts, _padding) {
  const padding = _padding !== null && _padding !== void 0 ? _padding : false;
  const deriveLocal = padding ? derivePadded : deriveUnpadded;
  const Px = await deriveLocal(privateKey, opts.ephemPublicKey);
  const hash = await sha5122(Px);
  const encryptionKey = hash.slice(0, 32);
  const macKey = hash.slice(32);
  const dataToMac = Buffer.concat([opts.iv, opts.ephemPublicKey, opts.ciphertext]);
  const macGood = await hmacSha256Verify(Buffer.from(macKey), dataToMac, opts.mac);
  if (!macGood && padding === false) {
    return decrypt(privateKey, opts, true);
  } else if (!macGood && padding === true) {
    throw new Error("bad MAC after trying padded");
  }
  const msg = await aesCbcDecrypt(opts.iv, Buffer.from(encryptionKey), opts.ciphertext);
  return Buffer.from(new Uint8Array(msg));
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/nodeUtils.js
var import_bn8 = __toESM(require_bn());

// node_modules/@toruslabs/torus.js/dist/lib.esm/some.js
function capitalizeFirstLetter(str) {
  return str.charAt(0).toUpperCase() + str.slice(1);
}
var SomeError = class extends Error {
  constructor({
    errors,
    responses,
    predicate
  }) {
    const message = `Unable to resolve enough promises. 
      errors: ${errors.map((x) => (x === null || x === void 0 ? void 0 : x.message) || x).join(", ")}, 
      predicate error: ${predicate},
      ${responses.length} responses,
      responses: ${JSON.stringify(responses)}`;
    super(message);
    _defineProperty(this, "errors", void 0);
    _defineProperty(this, "responses", void 0);
    _defineProperty(this, "predicate", void 0);
    this.errors = errors;
    this.responses = responses;
    this.predicate = predicate;
  }
  get message() {
    return `${super.message}. errors: ${this.errors.map((x) => (x === null || x === void 0 ? void 0 : x.message) || x).join(", ")} and ${this.responses.length} responses: ${JSON.stringify(this.responses)},
      predicate error: ${this.predicate}`;
  }
  toString() {
    return this.message;
  }
};
var Some = (promises, predicate) => new Promise((resolve, reject) => {
  let finishedCount = 0;
  const sharedState = {
    resolved: false
  };
  const errorArr = new Array(promises.length).fill(void 0);
  const resultArr = new Array(promises.length).fill(void 0);
  let predicateError;
  promises.forEach((x, index) => {
    x.then((resp) => {
      resultArr[index] = resp;
      return void 0;
    }).catch((error) => {
      errorArr[index] = error;
    }).finally(() => {
      if (sharedState.resolved) return;
      return predicate(resultArr.slice(0), sharedState).then((data) => {
        sharedState.resolved = true;
        resolve(data);
        return void 0;
      }).catch((error) => {
        predicateError = error;
      }).finally(() => {
        finishedCount += 1;
        if (finishedCount === promises.length) {
          const errors = Object.values(resultArr.reduce((acc, z) => {
            if (z) {
              var _error$data;
              const {
                id,
                error
              } = z;
              if ((error === null || error === void 0 || (_error$data = error.data) === null || _error$data === void 0 ? void 0 : _error$data.length) > 0) {
                if (error.data.startsWith("Error occurred while verifying params")) acc[id] = capitalizeFirstLetter(error.data);
                else acc[id] = error.data;
              }
            }
            return acc;
          }, {}));
          if (errors.length > 0) {
            const msg = errors.length > 1 ? `
${errors.map((it) => `â€¢ ${it}`).join("\n")}` : errors[0];
            reject(new Error(msg));
          } else {
            var _predicateError;
            reject(new SomeError({
              errors: errorArr,
              responses: resultArr,
              predicate: ((_predicateError = predicateError) === null || _predicateError === void 0 ? void 0 : _predicateError.message) || predicateError
            }));
          }
        }
      });
    });
  });
});

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/common.js
var import_bn4 = __toESM(require_bn());
var import_elliptic2 = __toESM(require_elliptic());
var import_json_stable_stringify = __toESM(require_json_stable_stringify());
function keccak2562(a) {
  const hash = Buffer.from(keccak256(a)).toString("hex");
  return `0x${hash}`;
}
var generatePrivateKey = (ecCurve, buf) => {
  return ecCurve.genKeyPair().getPrivate().toArrayLike(buf);
};
var getKeyCurve = (keyType) => {
  if (keyType === KEY_TYPE.ED25519) {
    return new import_elliptic2.ec(KEY_TYPE.ED25519);
  } else if (keyType === KEY_TYPE.SECP256K1) {
    return new import_elliptic2.ec(KEY_TYPE.SECP256K1);
  }
  throw new Error(`Invalid keyType: ${keyType}`);
};
var normalizeKeysResult = (result) => {
  const finalResult = {
    keys: [],
    is_new_key: result.is_new_key
  };
  if (result && result.keys && result.keys.length > 0) {
    const finalKey = result.keys[0];
    finalResult.keys = [{
      pub_key_X: finalKey.pub_key_X,
      pub_key_Y: finalKey.pub_key_Y,
      address: finalKey.address
    }];
  }
  return finalResult;
};
var normalizeLookUpResult = (result) => {
  const finalResult = {
    keys: []
  };
  if (result && result.keys && result.keys.length > 0) {
    const finalKey = result.keys[0];
    finalResult.keys = [{
      pub_key_X: finalKey.pub_key_X,
      pub_key_Y: finalKey.pub_key_Y,
      address: finalKey.address
    }];
  }
  return finalResult;
};
var kCombinations = (s, k) => {
  let set = s;
  if (typeof set === "number") {
    set = Array.from({
      length: set
    }, (_, i) => i);
  }
  if (k > set.length || k <= 0) {
    return [];
  }
  if (k === set.length) {
    return [set];
  }
  if (k === 1) {
    return set.reduce((acc, cur) => [...acc, [cur]], []);
  }
  const combs = [];
  let tailCombs = [];
  for (let i = 0; i <= set.length - k + 1; i += 1) {
    tailCombs = kCombinations(set.slice(i + 1), k - 1);
    for (let j = 0; j < tailCombs.length; j += 1) {
      combs.push([set[i], ...tailCombs[j]]);
    }
  }
  return combs;
};
var thresholdSame = (arr, t) => {
  const hashMap = {};
  for (let i = 0; i < arr.length; i += 1) {
    const str = (0, import_json_stable_stringify.default)(arr[i]);
    hashMap[str] = hashMap[str] ? hashMap[str] + 1 : 1;
    if (hashMap[str] === t) {
      return arr[i];
    }
  }
  return void 0;
};
function encParamsBufToHex(encParams) {
  return {
    iv: Buffer.from(encParams.iv).toString("hex"),
    ephemPublicKey: Buffer.from(encParams.ephemPublicKey).toString("hex"),
    ciphertext: Buffer.from(encParams.ciphertext).toString("hex"),
    mac: Buffer.from(encParams.mac).toString("hex"),
    mode: "AES256"
  };
}
function encParamsHexToBuf(eciesData) {
  return {
    ephemPublicKey: Buffer.from(eciesData.ephemPublicKey, "hex"),
    iv: Buffer.from(eciesData.iv, "hex"),
    mac: Buffer.from(eciesData.mac, "hex")
  };
}
function getProxyCoordinatorEndpointIndex(endpoints, verifier, verifierId) {
  const verifierIdStr = `${verifier}${verifierId}`;
  const hashedVerifierId = keccak2562(Buffer.from(verifierIdStr, "utf8")).slice(2);
  const proxyEndpointNum = new import_bn4.BN(hashedVerifierId, "hex").mod(new import_bn4.BN(endpoints.length)).toNumber();
  return proxyEndpointNum;
}
function calculateMedian(arr) {
  const arrSize = arr.length;
  if (arrSize === 0) return 0;
  const sortedArr = arr.sort(function(a, b) {
    return a - b;
  });
  if (arrSize % 2 !== 0) {
    return sortedArr[Math.floor(arrSize / 2)];
  }
  const mid1 = sortedArr[arrSize / 2 - 1];
  const mid2 = sortedArr[arrSize / 2];
  return (mid1 + mid2) / 2;
}
function waitFor(milliseconds) {
  return new Promise((resolve, reject) => {
    if (milliseconds > 0) {
      setTimeout(resolve, milliseconds);
    } else {
      reject(new Error("value of milliseconds must be greater than 0"));
    }
  });
}
function retryCommitment(executionPromise, maxRetries) {
  async function retryWithBackoff(retries) {
    try {
      if (retries > 0) {
        const timeToWait = 2 ** retries * 100;
        await waitFor(timeToWait);
      }
      const a = await executionPromise();
      return a;
    } catch (e) {
      const errorMsg = e.message;
      const acceptedErrorMsgs = [
        // Slow node
        "Timed out",
        "Failed to fetch",
        "fetch failed",
        "Load failed",
        "cancelled",
        "NetworkError when attempting to fetch resource.",
        // Happens when the node is not reachable (dns issue etc)
        "TypeError: Failed to fetch",
        // All except iOS and Firefox
        "TypeError: cancelled",
        // iOS
        "TypeError: NetworkError when attempting to fetch resource."
        // Firefox
      ];
      if (retries < maxRetries && (acceptedErrorMsgs.includes(errorMsg) || errorMsg && errorMsg.includes("reason: getaddrinfo EAI_AGAIN"))) {
        return retryWithBackoff(retries + 1);
      }
      throw e;
    }
  }
  return retryWithBackoff(0);
}

// node_modules/@toruslabs/bs58/dist/lib.esm/bs58.js
var base = (ALPHABET2) => {
  if (ALPHABET2.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  const BASE_MAP = new Uint8Array(256);
  for (let j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (let i = 0; i < ALPHABET2.length; i++) {
    const x = ALPHABET2.charAt(i);
    const xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(`${x} is ambiguous`);
    }
    BASE_MAP[xc] = i;
  }
  const BASE = ALPHABET2.length;
  const LEADER = ALPHABET2.charAt(0);
  const FACTOR = Math.log(BASE) / Math.log(256);
  const iFACTOR = Math.log(256) / Math.log(BASE);
  function encode(source) {
    if (source instanceof Uint8Array) ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    let zeroes = 0;
    let length = 0;
    let pbegin = 0;
    const pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    const size = (pend - pbegin) * iFACTOR + 1 >>> 0;
    const b58 = new Uint8Array(size);
    while (pbegin !== pend) {
      let carry = source[pbegin];
      let i = 0;
      for (let it1 = size - 1; (carry !== 0 || i < length) && it1 !== -1; it1--, i++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length = i;
      pbegin++;
    }
    let it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
    let str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) {
      str += ALPHABET2.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    let psz = 0;
    let zeroes = 0;
    let length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    const size = (source.length - psz) * FACTOR + 1 >>> 0;
    const b256 = new Uint8Array(size);
    while (source[psz]) {
      let carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      let i = 0;
      for (let it3 = size - 1; (carry !== 0 || i < length) && it3 !== -1; it3--, i++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length = i;
      psz++;
    }
    let it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    const vch = new Uint8Array(zeroes + (size - it4));
    let j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch;
  }
  function decode(s) {
    const buffer = decodeUnsafe(s);
    if (buffer) {
      return buffer;
    }
    throw new Error(`Non-base${BASE} character`);
  }
  return {
    encode,
    decodeUnsafe,
    decode
  };
};
var ALPHABET = "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz";
var bs58 = base(ALPHABET);

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/keyUtils.js
var import_bn7 = __toESM(require_bn());
var import_elliptic3 = __toESM(require_elliptic());

// node_modules/ethereum-cryptography/esm/sha512.js
var sha5123 = wrapHash(sha512);

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/keyUtils.js
var import_json_stable_stringify3 = __toESM(require_json_stable_stringify());
var import_loglevel3 = __toESM(require_loglevel());

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/langrangeInterpolatePoly.js
var import_bn5 = __toESM(require_bn());
function generatePrivateExcludingIndexes(shareIndexes, ecCurve) {
  const key = new import_bn5.default(generatePrivateKey(ecCurve, Buffer));
  if (shareIndexes.find((el) => el.eq(key))) {
    return generatePrivateExcludingIndexes(shareIndexes, ecCurve);
  }
  return key;
}
var generateEmptyBNArray = (length) => Array.from({
  length
}, () => new import_bn5.default(0));
var denominator = (ecCurve, i, innerPoints) => {
  let result = new import_bn5.default(1);
  const xi = innerPoints[i].x;
  for (let j = innerPoints.length - 1; j >= 0; j -= 1) {
    if (i !== j) {
      let tmp = new import_bn5.default(xi);
      tmp = tmp.sub(innerPoints[j].x);
      tmp = tmp.umod(ecCurve.n);
      result = result.mul(tmp);
      result = result.umod(ecCurve.n);
    }
  }
  return result;
};
var interpolationPoly = (ecCurve, i, innerPoints) => {
  let coefficients = generateEmptyBNArray(innerPoints.length);
  const d = denominator(ecCurve, i, innerPoints);
  if (d.cmp(new import_bn5.default(0)) === 0) {
    throw new Error("Denominator for interpolationPoly is 0");
  }
  coefficients[0] = d.invm(ecCurve.n);
  for (let k = 0; k < innerPoints.length; k += 1) {
    const newCoefficients = generateEmptyBNArray(innerPoints.length);
    if (k !== i) {
      let j;
      if (k < i) {
        j = k + 1;
      } else {
        j = k;
      }
      j -= 1;
      for (; j >= 0; j -= 1) {
        newCoefficients[j + 1] = newCoefficients[j + 1].add(coefficients[j]).umod(ecCurve.n);
        let tmp = new import_bn5.default(innerPoints[k].x);
        tmp = tmp.mul(coefficients[j]).umod(ecCurve.n);
        newCoefficients[j] = newCoefficients[j].sub(tmp).umod(ecCurve.n);
      }
      coefficients = newCoefficients;
    }
  }
  return coefficients;
};
var pointSort = (innerPoints) => {
  const pointArrClone = [...innerPoints];
  pointArrClone.sort((a, b) => a.x.cmp(b.x));
  return pointArrClone;
};
var lagrange = (ecCurve, unsortedPoints) => {
  const sortedPoints = pointSort(unsortedPoints);
  const polynomial = generateEmptyBNArray(sortedPoints.length);
  for (let i = 0; i < sortedPoints.length; i += 1) {
    const coefficients = interpolationPoly(ecCurve, i, sortedPoints);
    for (let k = 0; k < sortedPoints.length; k += 1) {
      let tmp = new import_bn5.default(sortedPoints[i].y);
      tmp = tmp.mul(coefficients[k]);
      polynomial[k] = polynomial[k].add(tmp).umod(ecCurve.n);
    }
  }
  return new Polynomial(polynomial, ecCurve);
};
function lagrangeInterpolatePolynomial(ecCurve, points) {
  return lagrange(ecCurve, points);
}
function lagrangeInterpolation(ecCurve, shares, nodeIndex) {
  if (shares.length !== nodeIndex.length) {
    throw new Error("shares not equal to nodeIndex length in lagrangeInterpolation");
  }
  let secret = new import_bn5.default(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new import_bn5.default(1);
    let lower = new import_bn5.default(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(ecCurve.n);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(ecCurve.n);
        lower = lower.mul(temp).umod(ecCurve.n);
      }
    }
    let delta = upper.mul(lower.invm(ecCurve.n)).umod(ecCurve.n);
    delta = delta.mul(shares[i]).umod(ecCurve.n);
    secret = secret.add(delta);
  }
  return secret.umod(ecCurve.n);
}
function generateRandomPolynomial(ecCurve, degree, secret, deterministicShares) {
  let actualS = secret;
  if (!secret) {
    actualS = generatePrivateExcludingIndexes([new import_bn5.default(0)], ecCurve);
  }
  if (!deterministicShares) {
    const poly = [actualS];
    for (let i = 0; i < degree; i += 1) {
      const share = generatePrivateExcludingIndexes(poly, ecCurve);
      poly.push(share);
    }
    return new Polynomial(poly, ecCurve);
  }
  if (!Array.isArray(deterministicShares)) {
    throw new Error("deterministic shares in generateRandomPolynomial should be an array");
  }
  if (deterministicShares.length > degree) {
    throw new Error("deterministicShares in generateRandomPolynomial should be less or equal than degree to ensure an element of randomness");
  }
  const points = {};
  deterministicShares.forEach((share) => {
    points[share.shareIndex.toString("hex", 64)] = new Point(share.shareIndex, share.share, ecCurve);
  });
  for (let i = 0; i < degree - deterministicShares.length; i += 1) {
    let shareIndex = generatePrivateExcludingIndexes([new import_bn5.default(0)], ecCurve);
    while (points[shareIndex.toString("hex", 64)] !== void 0) {
      shareIndex = generatePrivateExcludingIndexes([new import_bn5.default(0)], ecCurve);
    }
    points[shareIndex.toString("hex", 64)] = new Point(shareIndex, new import_bn5.default(generatePrivateKey(ecCurve, Buffer)), ecCurve);
  }
  points["0"] = new Point(new import_bn5.default(0), actualS, ecCurve);
  return lagrangeInterpolatePolynomial(ecCurve, Object.values(points));
}

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/metadataUtils.js
var import_bn6 = __toESM(require_bn());
var import_json_stable_stringify2 = __toESM(require_json_stable_stringify());
var import_loglevel2 = __toESM(require_loglevel());
var getSecpKeyFromEd25519 = (ed25519Scalar) => {
  const secp256k1Curve = getKeyCurve(KEY_TYPE.SECP256K1);
  const ed25519Key = ed25519Scalar.toString("hex", 64);
  const keyHash = keccak256(Buffer.from(ed25519Key, "hex"));
  const secpKey = new import_bn6.default(keyHash).umod(secp256k1Curve.n).toString("hex", 64);
  const bufferKey = Buffer.from(secpKey, "hex");
  const secpKeyPair = secp256k1Curve.keyFromPrivate(bufferKey);
  if (bufferKey.length !== 32) {
    throw new Error(`Key length must be equal to 32. got ${bufferKey.length}`);
  }
  return {
    scalar: secpKeyPair.getPrivate(),
    point: secpKeyPair.getPublic()
  };
};
function convertMetadataToNonce(params) {
  if (!params || !params.message) {
    return new import_bn6.default(0);
  }
  return new import_bn6.default(params.message, 16);
}
async function decryptNodeData(eciesData, ciphertextHex, privKey) {
  const metadata = encParamsHexToBuf(eciesData);
  const decryptedSigBuffer = await decrypt(privKey, _objectSpread2(_objectSpread2({}, metadata), {}, {
    ciphertext: Buffer.from(ciphertextHex, "hex")
  }));
  return decryptedSigBuffer;
}
async function decryptNodeDataWithPadding(eciesData, ciphertextHex, privKey) {
  const metadata = encParamsHexToBuf(eciesData);
  try {
    const decryptedSigBuffer = await decrypt(privKey, _objectSpread2(_objectSpread2({}, metadata), {}, {
      ciphertext: Buffer.from(ciphertextHex, "hex")
    }));
    return decryptedSigBuffer;
  } catch (error) {
    const ciphertextHexPadding = ciphertextHex.padStart(64, "0");
    import_loglevel2.default.warn("Failed to decrypt padded share cipher", error);
    return decrypt(privKey, _objectSpread2(_objectSpread2({}, metadata), {}, {
      ciphertext: Buffer.from(ciphertextHexPadding, "hex")
    }));
  }
}
function generateMetadataParams(ecCurve, serverTimeOffset, message, privateKey) {
  const key = ecCurve.keyFromPrivate(privateKey.toString("hex", 64), "hex");
  const setData = {
    data: message,
    timestamp: new import_bn6.default(~~(serverTimeOffset + Date.now() / 1e3)).toString(16)
  };
  const sig = key.sign(keccak2562(Buffer.from((0, import_json_stable_stringify2.default)(setData), "utf8")).slice(2));
  return {
    pub_key_X: key.getPublic().getX().toString("hex"),
    // DO NOT PAD THIS. BACKEND DOESN'T
    pub_key_Y: key.getPublic().getY().toString("hex"),
    // DO NOT PAD THIS. BACKEND DOESN'T
    set_data: setData,
    signature: Buffer.from(sig.r.toString(16, 64) + sig.s.toString(16, 64) + new import_bn6.default("").toString(16, 2), "hex").toString("base64")
  };
}
async function getMetadata(legacyMetadataHost, data, options = {}) {
  try {
    const metadataResponse = await post(`${legacyMetadataHost}/get`, data, options, {
      useAPIKey: true
    });
    if (!metadataResponse || !metadataResponse.message) {
      return new import_bn6.default(0);
    }
    return new import_bn6.default(metadataResponse.message, 16);
  } catch (error) {
    import_loglevel2.default.error("get metadata error", error);
    return new import_bn6.default(0);
  }
}
function generateNonceMetadataParams(serverTimeOffset, operation, privateKey, keyType, nonce, seed) {
  const key = getKeyCurve(KEY_TYPE.SECP256K1).keyFromPrivate(privateKey.toString("hex", 64), "hex");
  const setData = {
    operation,
    timestamp: new import_bn6.default(~~(serverTimeOffset + Date.now() / 1e3)).toString(16)
  };
  if (nonce) {
    setData.data = nonce.toString("hex", 64);
  }
  if (seed) {
    setData.seed = seed;
  } else {
    setData.seed = "";
  }
  const sig = key.sign(keccak2562(Buffer.from((0, import_json_stable_stringify2.default)(setData), "utf8")).slice(2));
  return {
    pub_key_X: key.getPublic().getX().toString("hex", 64),
    pub_key_Y: key.getPublic().getY().toString("hex", 64),
    set_data: setData,
    key_type: keyType,
    signature: Buffer.from(sig.r.toString(16, 64) + sig.s.toString(16, 64) + new import_bn6.default("").toString(16, 2), "hex").toString("base64")
  };
}
async function getOrSetNonce(metadataHost, ecCurve, serverTimeOffset, X, Y, privKey, getOnly = false, isLegacyMetadata = true, nonce = new import_bn6.default(0), keyType = "secp256k1", seed = "") {
  if (isLegacyMetadata) {
    let data2;
    const msg = getOnly ? "getNonce" : "getOrSetNonce";
    if (privKey) {
      data2 = generateMetadataParams(ecCurve, serverTimeOffset, msg, privKey);
    } else {
      data2 = {
        pub_key_X: X,
        pub_key_Y: Y,
        set_data: {
          data: msg
        }
      };
    }
    return post(`${metadataHost}/get_or_set_nonce`, data2, void 0, {
      useAPIKey: true
    });
  }
  const operation = getOnly ? "getNonce" : "getOrSetNonce";
  if (operation === "getOrSetNonce") {
    if (!privKey) {
      throw new Error("privKey is required while `getOrSetNonce` for non legacy metadata");
    }
    if (nonce.cmp(new import_bn6.default(0)) === 0) {
      throw new Error("nonce is required while `getOrSetNonce` for non legacy metadata");
    }
    if (keyType === KEY_TYPE.ED25519 && !seed) {
      throw new Error("seed is required while `getOrSetNonce` for non legacy metadata for ed25519 key type");
    }
    const data2 = generateNonceMetadataParams(serverTimeOffset, operation, privKey, keyType, nonce, seed);
    return post(`${metadataHost}/get_or_set_nonce`, data2, void 0, {
      useAPIKey: true
    });
  }
  const data = {
    pub_key_X: X,
    pub_key_Y: Y,
    set_data: {
      operation
    },
    key_type: keyType
  };
  return post(`${metadataHost}/get_or_set_nonce`, data, void 0, {
    useAPIKey: true
  });
}
async function getNonce(legacyMetadataHost, ecCurve, serverTimeOffset, X, Y, privKey) {
  return getOrSetNonce(legacyMetadataHost, ecCurve, serverTimeOffset, X, Y, privKey, true);
}
var decryptSeedData = async (seedBase64, finalUserKey) => {
  const decryptionKey = getSecpKeyFromEd25519(finalUserKey);
  const seedUtf8 = Buffer.from(seedBase64, "base64").toString("utf-8");
  const seedJson = JSON.parse(seedUtf8);
  const bufferMetadata = _objectSpread2(_objectSpread2({}, encParamsHexToBuf(seedJson.metadata)), {}, {
    mode: "AES256"
  });
  const bufferKey = decryptionKey.scalar.toArrayLike(Buffer, "be", 32);
  const decText = await decrypt(bufferKey, _objectSpread2(_objectSpread2({}, bufferMetadata), {}, {
    ciphertext: Buffer.from(seedJson.enc_text, "hex")
  }));
  return decText;
};
async function getOrSetSapphireMetadataNonce(network, X, Y, serverTimeOffset, privKey) {
  if (LEGACY_NETWORKS_ROUTE_MAP[network]) {
    throw new Error("getOrSetSapphireMetadataNonce should only be used for sapphire networks");
  }
  let data = {
    pub_key_X: X,
    pub_key_Y: Y,
    key_type: "secp256k1",
    set_data: {
      operation: "getOrSetNonce"
    }
  };
  if (privKey) {
    const key = getKeyCurve(KEY_TYPE.SECP256K1).keyFromPrivate(privKey.toString("hex", 64), "hex");
    const setData = {
      operation: "getOrSetNonce",
      timestamp: new import_bn6.default(~~(serverTimeOffset + Date.now() / 1e3)).toString(16)
    };
    const sig = key.sign(keccak2562(Buffer.from((0, import_json_stable_stringify2.default)(setData), "utf8")).slice(2));
    data = _objectSpread2(_objectSpread2({}, data), {}, {
      set_data: setData,
      signature: Buffer.from(sig.r.toString(16, 64) + sig.s.toString(16, 64) + new import_bn6.default("").toString(16, 2), "hex").toString("base64")
    });
  }
  const metadataUrl = network === TORUS_SAPPHIRE_NETWORK.SAPPHIRE_DEVNET ? SAPPHIRE_DEVNET_METADATA_URL : SAPPHIRE_METADATA_URL;
  return post(`${metadataUrl}/get_or_set_nonce`, data, void 0, {
    useAPIKey: true
  });
}

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/keyUtils.js
function stripHexPrefix(str) {
  return str.startsWith("0x") ? str.slice(2) : str;
}
function toChecksumAddress(hexAddress) {
  const address = stripHexPrefix(hexAddress).toLowerCase();
  const buf = Buffer.from(address, "utf8");
  const hash = Buffer.from(keccak256(buf)).toString("hex");
  let ret = "0x";
  for (let i = 0; i < address.length; i++) {
    if (parseInt(hash[i], 16) >= 8) {
      ret += address[i].toUpperCase();
    } else {
      ret += address[i];
    }
  }
  return ret;
}
function adjustScalarBytes(bytes) {
  bytes[0] &= 248;
  bytes[31] &= 127;
  bytes[31] |= 64;
  return bytes;
}
function getEd25519ExtendedPublicKey(keyBuffer) {
  const ed25519Curve = getKeyCurve(KEY_TYPE.ED25519);
  const len = 32;
  const G = ed25519Curve.g;
  const N = ed25519Curve.n;
  if (keyBuffer.length !== 32) {
    import_loglevel3.default.error("Invalid seed for ed25519 key derivation", keyBuffer.length);
    throw new Error("Invalid seed for ed25519 key derivation");
  }
  const hashed = sha5123(keyBuffer);
  if (hashed.length !== 64) {
    throw new Error("Invalid hash length for ed25519 seed");
  }
  const head = new import_bn7.default(adjustScalarBytes(Buffer.from(hashed.slice(0, len))), "le");
  const scalar = new import_bn7.default(head.umod(N), "le");
  const point = G.mul(scalar);
  return {
    scalar,
    point
  };
}
function encodeEd25519Point(point) {
  const ed25519Curve = getKeyCurve(KEY_TYPE.ED25519);
  const encodingLength = Math.ceil(ed25519Curve.n.bitLength() / 8);
  const enc = point.getY().toArrayLike(Buffer, "le", encodingLength);
  enc[encodingLength - 1] |= point.getX().isOdd() ? 128 : 0;
  return enc;
}
var generateEd25519KeyData = async (ed25519Seed) => {
  const ed25519Curve = getKeyCurve(KEY_TYPE.ED25519);
  const finalEd25519Key = getEd25519ExtendedPublicKey(ed25519Seed);
  const encryptionKey = getSecpKeyFromEd25519(finalEd25519Key.scalar);
  const encryptedSeed = await encrypt(Buffer.from(encryptionKey.point.encodeCompressed("hex"), "hex"), ed25519Seed);
  const encData = {
    enc_text: encryptedSeed.ciphertext.toString("hex"),
    metadata: encParamsBufToHex(encryptedSeed),
    public_key: encodeEd25519Point(finalEd25519Key.point).toString("hex")
  };
  const encDataBase64 = Buffer.from(JSON.stringify(encData), "utf-8").toString("base64");
  const metadataPrivNonce = ed25519Curve.genKeyPair().getPrivate();
  const oauthKey = finalEd25519Key.scalar.sub(metadataPrivNonce).umod(ed25519Curve.n);
  const oauthKeyPair = ed25519Curve.keyFromPrivate(oauthKey.toArrayLike(Buffer));
  const metadataSigningKey = getSecpKeyFromEd25519(oauthKeyPair.getPrivate());
  return {
    oAuthKeyScalar: oauthKeyPair.getPrivate(),
    oAuthPubX: oauthKeyPair.getPublic().getX(),
    oAuthPubY: oauthKeyPair.getPublic().getY(),
    SigningPubX: metadataSigningKey.point.getX(),
    SigningPubY: metadataSigningKey.point.getY(),
    metadataNonce: metadataPrivNonce,
    metadataSigningKey: metadataSigningKey.scalar,
    encryptedSeed: encDataBase64,
    finalUserPubKeyPoint: finalEd25519Key.point
  };
};
var generateSecp256k1KeyData = async (scalarBuffer) => {
  const secp256k1Curve = getKeyCurve(KEY_TYPE.SECP256K1);
  const scalar = new import_bn7.default(scalarBuffer);
  const randomNonce = new import_bn7.default(generatePrivateKey(secp256k1Curve, Buffer));
  const oAuthKey = scalar.sub(randomNonce).umod(secp256k1Curve.n);
  const oAuthKeyPair = secp256k1Curve.keyFromPrivate(oAuthKey.toArrayLike(Buffer));
  const oAuthPubKey = oAuthKeyPair.getPublic();
  const finalUserKeyPair = secp256k1Curve.keyFromPrivate(scalar.toString("hex", 64), "hex");
  return {
    oAuthKeyScalar: oAuthKeyPair.getPrivate(),
    oAuthPubX: oAuthPubKey.getX(),
    oAuthPubY: oAuthPubKey.getY(),
    SigningPubX: oAuthPubKey.getX(),
    SigningPubY: oAuthPubKey.getY(),
    metadataNonce: randomNonce,
    encryptedSeed: "",
    metadataSigningKey: oAuthKeyPair.getPrivate(),
    finalUserPubKeyPoint: finalUserKeyPair.getPublic()
  };
};
function generateAddressFromEcKey(keyType, key) {
  if (keyType === KEY_TYPE.SECP256K1) {
    const publicKey = key.getPublic().encode("hex", false).slice(2);
    const evmAddressLower = `0x${keccak2562(Buffer.from(publicKey, "hex")).slice(64 - 38)}`;
    return toChecksumAddress(evmAddressLower);
  } else if (keyType === KEY_TYPE.ED25519) {
    const publicKey = encodeEd25519Point(key.getPublic());
    const address = bs58.encode(publicKey);
    return address;
  }
  throw new Error(`Invalid keyType: ${keyType}`);
}
function generateAddressFromPrivKey(keyType, privateKey) {
  const ecCurve = getKeyCurve(keyType);
  const key = ecCurve.keyFromPrivate(privateKey.toString("hex", 64), "hex");
  return generateAddressFromEcKey(keyType, key);
}
function generateAddressFromPubKey(keyType, publicKeyX, publicKeyY) {
  const ecCurve = getKeyCurve(keyType);
  const key = ecCurve.keyFromPublic({
    x: publicKeyX.toString("hex", 64),
    y: publicKeyY.toString("hex", 64)
  });
  return generateAddressFromEcKey(keyType, key);
}
function getPostboxKeyFrom1OutOf1(ecCurve, privKey, nonce) {
  const privKeyBN = new import_bn7.default(privKey, 16);
  const nonceBN = new import_bn7.default(nonce, 16);
  return privKeyBN.sub(nonceBN).umod(ecCurve.n).toString("hex");
}
function derivePubKey(ecCurve, sk) {
  const skHex = sk.toString(16, 64);
  return ecCurve.keyFromPrivate(skHex, "hex").getPublic();
}
var getEncryptionEC = () => {
  return new import_elliptic3.ec("secp256k1");
};
var generateShares = async (ecCurve, keyType, serverTimeOffset, nodeIndexes, nodePubkeys, privKey) => {
  const keyData = keyType === KEY_TYPE.ED25519 ? await generateEd25519KeyData(privKey) : await generateSecp256k1KeyData(privKey);
  const {
    metadataNonce,
    oAuthKeyScalar: oAuthKey,
    encryptedSeed,
    metadataSigningKey
  } = keyData;
  const threshold = ~~(nodePubkeys.length / 2) + 1;
  const degree = threshold - 1;
  const nodeIndexesBn = [];
  for (const nodeIndex of nodeIndexes) {
    nodeIndexesBn.push(new import_bn7.default(nodeIndex));
  }
  const oAuthPubKey = ecCurve.keyFromPrivate(oAuthKey.toString("hex", 64), "hex").getPublic();
  const poly = generateRandomPolynomial(ecCurve, degree, oAuthKey);
  const shares = poly.generateShares(nodeIndexesBn);
  const nonceParams = generateNonceMetadataParams(serverTimeOffset, "getOrSetNonce", metadataSigningKey, keyType, metadataNonce, encryptedSeed);
  const nonceData = Buffer.from((0, import_json_stable_stringify3.default)(nonceParams.set_data), "utf8").toString("base64");
  const sharesData = [];
  const encPromises = [];
  for (let i = 0; i < nodeIndexesBn.length; i++) {
    const shareJson = shares[nodeIndexesBn[i].toString("hex", 64)].toJSON();
    if (!nodePubkeys[i]) {
      throw new Error(`Missing node pub key for node index: ${nodeIndexesBn[i].toString("hex", 64)}`);
    }
    const nodePubKey = getEncryptionEC().keyFromPublic({
      x: nodePubkeys[i].X,
      y: nodePubkeys[i].Y
    });
    encPromises.push(encrypt(Buffer.from(nodePubKey.getPublic().encodeCompressed("hex"), "hex"), Buffer.from(shareJson.share.padStart(64, "0"), "hex")));
  }
  const encShares = await Promise.all(encPromises);
  for (let i = 0; i < nodeIndexesBn.length; i += 1) {
    const shareJson = shares[nodeIndexesBn[i].toString("hex", 64)].toJSON();
    const encParams = encShares[i];
    const encParamsMetadata = encParamsBufToHex(encParams);
    const shareData = {
      encrypted_seed: keyData.encryptedSeed,
      final_user_point: keyData.finalUserPubKeyPoint,
      oauth_pub_key_x: oAuthPubKey.getX().toString("hex"),
      oauth_pub_key_y: oAuthPubKey.getY().toString("hex"),
      signing_pub_key_x: keyData.SigningPubX.toString("hex"),
      signing_pub_key_y: keyData.SigningPubY.toString("hex"),
      encrypted_share: encParamsMetadata.ciphertext,
      encrypted_share_metadata: encParamsMetadata,
      node_index: Number.parseInt(shareJson.shareIndex, 16),
      key_type: keyType,
      nonce_data: nonceData,
      nonce_signature: nonceParams.signature
    };
    sharesData.push(shareData);
  }
  return sharesData;
};

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/nodeUtils.js
var GetPubKeyOrKeyAssign = async (params) => {
  const {
    endpoints,
    network,
    verifier,
    verifierId,
    extendedVerifierId,
    keyType
  } = params;
  const minThreshold = ~~(endpoints.length / 2) + 1;
  const lookupPromises = endpoints.map((x) => post(x, generateJsonRPCObject(JRPC_METHODS.GET_OR_SET_KEY, {
    distributed_metadata: true,
    verifier,
    verifier_id: verifierId.toString(),
    extended_verifier_id: extendedVerifierId,
    one_key_flow: true,
    key_type: keyType,
    fetch_node_index: true,
    client_time: Math.floor(Date.now() / 1e3).toString()
  }), {}, {
    logTracingHeader: config.logRequestTracing
  }).catch((err) => log.error(`${JRPC_METHODS.GET_OR_SET_KEY} request failed`, err)));
  let nonceResult;
  const nodeIndexes = [];
  const result = await Some(lookupPromises, async (lookupResults) => {
    const lookupPubKeys = lookupResults.filter((x1) => {
      if (x1 && !x1.error) {
        return x1;
      }
      return false;
    });
    const errorResult = thresholdSame(lookupResults.map((x2) => x2 && x2.error), minThreshold);
    const keyResult = thresholdSame(lookupPubKeys.map((x3) => x3 && normalizeKeysResult(x3.result)), minThreshold);
    if (keyResult && !nonceResult && !extendedVerifierId && !LEGACY_NETWORKS_ROUTE_MAP[network]) {
      for (let i = 0; i < lookupResults.length; i++) {
        const x1 = lookupResults[i];
        if (x1 && !x1.error) {
          var _x1$result;
          const currentNodePubKey = x1.result.keys[0].pub_key_X.toLowerCase();
          const thresholdPubKey = keyResult.keys[0].pub_key_X.toLowerCase();
          const pubNonceX = (_x1$result = x1.result) === null || _x1$result === void 0 || (_x1$result = _x1$result.keys[0].nonce_data) === null || _x1$result === void 0 || (_x1$result = _x1$result.pubNonce) === null || _x1$result === void 0 ? void 0 : _x1$result.x;
          if (pubNonceX && currentNodePubKey === thresholdPubKey) {
            nonceResult = x1.result.keys[0].nonce_data;
            break;
          }
        }
      }
      if (!nonceResult) {
        const metadataNonceResult = await getOrSetSapphireMetadataNonce(network, keyResult.keys[0].pub_key_X, keyResult.keys[0].pub_key_Y);
        if (!nonceResult && metadataNonceResult) {
          nonceResult = metadataNonceResult;
          if (nonceResult.nonce) {
            delete nonceResult.nonce;
          }
        }
      }
    }
    const serverTimeOffsets = [];
    if (keyResult && (nonceResult || extendedVerifierId || LEGACY_NETWORKS_ROUTE_MAP[network]) || errorResult) {
      if (keyResult) {
        lookupResults.forEach((x1) => {
          if (x1 && x1.result) {
            const currentNodePubKey = x1.result.keys[0].pub_key_X.toLowerCase();
            const thresholdPubKey = keyResult.keys[0].pub_key_X.toLowerCase();
            if (currentNodePubKey === thresholdPubKey) {
              const nodeIndex = Number.parseInt(x1.result.node_index);
              if (nodeIndex) nodeIndexes.push(nodeIndex);
            }
            const serverTimeOffset2 = x1.result.server_time_offset ? Number.parseInt(x1.result.server_time_offset, 10) : 0;
            serverTimeOffsets.push(serverTimeOffset2);
          }
        });
      }
      const serverTimeOffset = keyResult ? calculateMedian(serverTimeOffsets) : 0;
      return Promise.resolve({
        keyResult,
        serverTimeOffset,
        nodeIndexes,
        errorResult,
        nonceResult
      });
    }
    return Promise.reject(new Error(`invalid public key result: ${JSON.stringify(lookupResults)} and nonce result:${JSON.stringify(nonceResult || {})} for verifier: ${verifier}, verifierId: ${verifierId} and extendedVerifierId: ${extendedVerifierId} `));
  });
  return result;
};
var VerifierLookupRequest = async (params) => {
  const {
    endpoints,
    verifier,
    verifierId,
    keyType
  } = params;
  const minThreshold = ~~(endpoints.length / 2) + 1;
  const lookupPromises = endpoints.map((x) => post(x, generateJsonRPCObject(JRPC_METHODS.VERIFIER_LOOKUP, {
    verifier,
    verifier_id: verifierId.toString(),
    key_type: keyType,
    client_time: Math.floor(Date.now() / 1e3).toString()
  }), {}, {
    logTracingHeader: config.logRequestTracing
  }).catch((err) => log.error(`${JRPC_METHODS.GET_OR_SET_KEY} request failed`, err)));
  const result = await Some(lookupPromises, async (lookupResults) => {
    const lookupPubKeys = lookupResults.filter((x1) => {
      if (x1 && !x1.error) {
        return x1;
      }
      return false;
    });
    const errorResult = thresholdSame(lookupResults.map((x2) => x2 && x2.error), minThreshold);
    const keyResult = thresholdSame(lookupPubKeys.map((x3) => x3 && normalizeLookUpResult(x3.result)), minThreshold);
    const serverTimeOffsets = [];
    if (keyResult || errorResult) {
      const serverTimeOffset = keyResult ? calculateMedian(serverTimeOffsets) : 0;
      return Promise.resolve({
        keyResult,
        serverTimeOffset,
        errorResult
      });
    }
    return Promise.reject(new Error(`invalid lookup result: ${JSON.stringify(lookupResults)}
        )} for verifier: ${verifier}, verifierId: ${verifierId}`));
  });
  return result;
};
var commitmentRequest = async (params) => {
  const {
    idToken,
    endpoints,
    indexes,
    keyType,
    verifier,
    verifierParams,
    pubKeyX,
    pubKeyY,
    finalImportedShares,
    overrideExistingKey
  } = params;
  const tokenCommitment = keccak2562(Buffer.from(idToken, "utf8"));
  const threeFourthsThreshold = ~~(endpoints.length * 3 / 4) + 1;
  const halfThreshold = ~~(endpoints.length / 2) + 1;
  const promiseArr = [];
  for (let i = 0; i < endpoints.length; i += 1) {
    const p = () => post(endpoints[i], generateJsonRPCObject(JRPC_METHODS.COMMITMENT_REQUEST, {
      messageprefix: "mug00",
      keytype: keyType,
      tokencommitment: tokenCommitment.slice(2),
      temppubx: pubKeyX,
      temppuby: pubKeyY,
      verifieridentifier: verifier,
      verifier_id: verifierParams.verifier_id,
      extended_verifier_id: verifierParams.extended_verifier_id,
      is_import_key_flow: true
    }), {}, {
      logTracingHeader: config.logRequestTracing
    });
    const r = retryCommitment(p, 4);
    promiseArr.push(r);
  }
  return new Promise((resolve, reject) => {
    Some(promiseArr, (resultArr) => {
      const completedRequests = resultArr.filter((x) => {
        if (!x || typeof x !== "object") {
          return false;
        }
        if (x.error) {
          return false;
        }
        return true;
      });
      if (finalImportedShares.length > 0) {
        if (overrideExistingKey && completedRequests.length === endpoints.length) {
          const requiredNodeResult = completedRequests.find((resp) => {
            if (resp) {
              return true;
            }
            return false;
          });
          if (requiredNodeResult) {
            return Promise.resolve(resultArr);
          }
        } else if (!overrideExistingKey && completedRequests.length >= threeFourthsThreshold) {
          const nodeSigs = [];
          for (let i = 0; i < completedRequests.length; i += 1) {
            const x = completedRequests[i];
            if (!x || typeof x !== "object" || x.error) {
              continue;
            }
            if (x) nodeSigs.push(x.result);
          }
          const existingPubKey = thresholdSame(nodeSigs.map((x) => x && x.pub_key_x), halfThreshold);
          const proxyEndpointNum = getProxyCoordinatorEndpointIndex(endpoints, verifier, verifierParams.verifier_id);
          const requiredNodeIndex = indexes[proxyEndpointNum].toString(10);
          if (existingPubKey || !existingPubKey && completedRequests.length === endpoints.length) {
            const requiredNodeResult = completedRequests.find((resp) => {
              var _resp$result;
              if (resp && ((_resp$result = resp.result) === null || _resp$result === void 0 ? void 0 : _resp$result.nodeindex) === requiredNodeIndex) {
                return true;
              }
              return false;
            });
            if (requiredNodeResult) {
              return Promise.resolve(resultArr);
            }
          }
        }
      } else if (completedRequests.length >= threeFourthsThreshold) {
        const requiredNodeResult = completedRequests.find((resp) => {
          if (resp) {
            return true;
          }
          return false;
        });
        if (requiredNodeResult) {
          return Promise.resolve(resultArr);
        }
      }
      return Promise.reject(new Error(`invalid commitment results ${JSON.stringify(resultArr)}`));
    }).then((resultArr) => {
      return resolve(resultArr);
    }).catch(reject);
  });
};
async function retrieveOrImportShare(params) {
  const {
    legacyMetadataHost,
    enableOneKey,
    ecCurve,
    keyType,
    allowHost,
    network,
    clientId,
    endpoints,
    nodePubkeys,
    indexes,
    verifier,
    verifierParams,
    idToken,
    overrideExistingKey,
    newImportedShares,
    extraParams,
    useDkg = true,
    serverTimeOffset,
    checkCommitment = true
  } = params;
  await get(allowHost, {
    headers: {
      verifier,
      verifierid: verifierParams.verifier_id,
      network,
      clientid: clientId,
      enablegating: "true"
    }
  }, {
    useAPIKey: true
  });
  const sessionAuthKey = generatePrivate();
  const pubKey = getPublic(sessionAuthKey).toString("hex");
  const sessionPubX = pubKey.slice(2, 66);
  const sessionPubY = pubKey.slice(66);
  let finalImportedShares = [];
  const halfThreshold = ~~(endpoints.length / 2) + 1;
  if ((newImportedShares === null || newImportedShares === void 0 ? void 0 : newImportedShares.length) > 0) {
    if (newImportedShares.length !== endpoints.length) {
      throw new Error("Invalid imported shares length");
    }
    finalImportedShares = newImportedShares;
  } else if (!useDkg) {
    const bufferKey = keyType === KEY_TYPE.SECP256K1 ? generatePrivateKey(ecCurve, Buffer) : await getRandomBytes(32);
    const generatedShares = await generateShares(ecCurve, keyType, serverTimeOffset, indexes, nodePubkeys, Buffer.from(bufferKey));
    finalImportedShares = [...finalImportedShares, ...generatedShares];
  }
  let commitmentRequestResult = [];
  let isExistingKey;
  const nodeSigs = [];
  if (checkCommitment) {
    commitmentRequestResult = await commitmentRequest({
      idToken,
      endpoints,
      indexes,
      keyType,
      verifier,
      verifierParams,
      pubKeyX: sessionPubX,
      pubKeyY: sessionPubY,
      finalImportedShares,
      overrideExistingKey
    });
    for (let i = 0; i < commitmentRequestResult.length; i += 1) {
      const x = commitmentRequestResult[i];
      if (!x || typeof x !== "object" || x.error) {
        continue;
      }
      if (x) nodeSigs.push(x.result);
    }
    isExistingKey = !!thresholdSame(nodeSigs.map((x) => x && x.pub_key_x), halfThreshold);
  } else if (!checkCommitment && finalImportedShares.length > 0) {
    if (!overrideExistingKey) {
      var _keyLookupResult$erro, _keyLookupResult$keyR;
      const keyLookupResult = await VerifierLookupRequest({
        endpoints,
        verifier,
        verifierId: verifierParams.verifier_id,
        keyType
      });
      if (keyLookupResult.errorResult && !((_keyLookupResult$erro = keyLookupResult.errorResult) !== null && _keyLookupResult$erro !== void 0 && (_keyLookupResult$erro = _keyLookupResult$erro.data) !== null && _keyLookupResult$erro !== void 0 && _keyLookupResult$erro.includes("Verifier + VerifierID has not yet been assigned"))) {
        throw new Error(`node results do not match at first lookup ${JSON.stringify(keyLookupResult.keyResult || {})}, ${JSON.stringify(keyLookupResult.errorResult || {})}`);
      }
      if (((_keyLookupResult$keyR = keyLookupResult.keyResult) === null || _keyLookupResult$keyR === void 0 || (_keyLookupResult$keyR = _keyLookupResult$keyR.keys) === null || _keyLookupResult$keyR === void 0 ? void 0 : _keyLookupResult$keyR.length) > 0) {
        isExistingKey = !!keyLookupResult.keyResult.keys[0];
      }
    }
  }
  const promiseArrRequest = [];
  const canImportedShares = overrideExistingKey || !useDkg && !isExistingKey;
  if (canImportedShares) {
    const proxyEndpointNum = getProxyCoordinatorEndpointIndex(endpoints, verifier, verifierParams.verifier_id);
    const items = [];
    for (let i = 0; i < endpoints.length; i += 1) {
      const importedShare = finalImportedShares[i];
      if (!importedShare) {
        throw new Error(`invalid imported share at index ${i}`);
      }
      items.push(_objectSpread2(_objectSpread2({}, verifierParams), {}, {
        idtoken: idToken,
        nodesignatures: nodeSigs,
        verifieridentifier: verifier,
        pub_key_x: importedShare.oauth_pub_key_x,
        pub_key_y: importedShare.oauth_pub_key_y,
        signing_pub_key_x: importedShare.signing_pub_key_x,
        signing_pub_key_y: importedShare.signing_pub_key_y,
        encrypted_share: importedShare.encrypted_share,
        encrypted_share_metadata: importedShare.encrypted_share_metadata,
        node_index: importedShare.node_index,
        key_type: importedShare.key_type,
        nonce_data: importedShare.nonce_data,
        nonce_signature: importedShare.nonce_signature,
        sss_endpoint: endpoints[i]
      }, extraParams));
    }
    const p = post(endpoints[proxyEndpointNum], generateJsonRPCObject(JRPC_METHODS.IMPORT_SHARES, {
      encrypted: "yes",
      use_temp: true,
      verifieridentifier: verifier,
      temppubx: nodeSigs.length === 0 && !checkCommitment ? sessionPubX : "",
      // send session pub key x only if node signatures are not available (Ie. in non commitment flow)
      temppuby: nodeSigs.length === 0 && !checkCommitment ? sessionPubY : "",
      // send session pub key y only if node signatures are not available (Ie. in non commitment flow)
      item: items,
      key_type: keyType,
      one_key_flow: true
    }), {}, {
      logTracingHeader: config.logRequestTracing
    }).catch((err) => log.error("share req", err));
    promiseArrRequest.push(p);
  } else {
    for (let i = 0; i < endpoints.length; i += 1) {
      const p = post(endpoints[i], generateJsonRPCObject(JRPC_METHODS.GET_SHARE_OR_KEY_ASSIGN, {
        encrypted: "yes",
        use_temp: true,
        key_type: keyType,
        distributed_metadata: true,
        verifieridentifier: verifier,
        temppubx: nodeSigs.length === 0 && !checkCommitment ? sessionPubX : "",
        // send session pub key x only if node signatures are not available (Ie. in non commitment flow)
        temppuby: nodeSigs.length === 0 && !checkCommitment ? sessionPubY : "",
        // send session pub key y only if node signatures are not available (Ie. in non commitment flow)
        item: [_objectSpread2(_objectSpread2({}, verifierParams), {}, {
          idtoken: idToken,
          key_type: keyType,
          nodesignatures: nodeSigs,
          verifieridentifier: verifier
        }, extraParams)],
        client_time: Math.floor(Date.now() / 1e3).toString(),
        one_key_flow: true
      }), {}, {
        logTracingHeader: config.logRequestTracing
      });
      promiseArrRequest.push(p);
    }
  }
  return Some(promiseArrRequest, async (shareResponseResult, sharedState) => {
    let thresholdNonceData;
    let shareResponses = [];
    if (shareResponseResult.length === 1 && shareResponseResult[0] && Array.isArray(shareResponseResult[0].result)) {
      const importedSharesResult = shareResponseResult[0];
      shareResponseResult[0].result.forEach((res) => {
        shareResponses.push({
          id: importedSharesResult.id,
          jsonrpc: "2.0",
          result: res,
          error: importedSharesResult.error
        });
      });
    } else {
      shareResponses = shareResponseResult;
    }
    const completedRequests = shareResponses.filter((x) => {
      if (!x || typeof x !== "object") {
        return false;
      }
      if (x.error) {
        return false;
      }
      return true;
    });
    const pubkeys = shareResponses.map((x) => {
      if (x && x.result && x.result.keys[0].public_key) {
        return x.result.keys[0].public_key;
      }
      return void 0;
    });
    const thresholdPublicKey = thresholdSame(pubkeys, halfThreshold);
    if (!thresholdPublicKey) {
      throw new Error("invalid result from nodes, threshold number of public key results are not matching");
    }
    shareResponses.forEach((x) => {
      const requiredShareResponse = x && x.result && x.result.keys[0].public_key && x.result.keys[0];
      if (requiredShareResponse && !thresholdNonceData && !verifierParams.extended_verifier_id) {
        var _requiredShareRespons;
        const currentPubKey = requiredShareResponse.public_key;
        const pubNonce = (_requiredShareRespons = requiredShareResponse.nonce_data) === null || _requiredShareRespons === void 0 || (_requiredShareRespons = _requiredShareRespons.pubNonce) === null || _requiredShareRespons === void 0 ? void 0 : _requiredShareRespons.x;
        if (pubNonce && currentPubKey.X === thresholdPublicKey.X) {
          thresholdNonceData = requiredShareResponse.nonce_data;
        }
      }
    });
    const thresholdReqCount = canImportedShares ? endpoints.length : halfThreshold;
    if (completedRequests.length >= thresholdReqCount && thresholdPublicKey) {
      const sharePromises = [];
      const sessionTokenSigPromises = [];
      const sessionTokenPromises = [];
      const nodeIndexes = [];
      const sessionTokenData = [];
      const isNewKeyResponses = [];
      const serverTimeOffsetResponses = [];
      for (let i = 0; i < completedRequests.length; i += 1) {
        var _currentShareResponse;
        const currentShareResponse = completedRequests[i];
        const {
          session_tokens: sessionTokens,
          session_token_metadata: sessionTokenMetadata,
          session_token_sigs: sessionTokenSigs,
          session_token_sig_metadata: sessionTokenSigMetadata,
          keys,
          is_new_key: isNewKey2,
          server_time_offset: serverTimeOffsetResponse
        } = currentShareResponse.result;
        isNewKeyResponses.push({
          isNewKey: isNewKey2,
          publicKey: ((_currentShareResponse = currentShareResponse.result) === null || _currentShareResponse === void 0 || (_currentShareResponse = _currentShareResponse.keys[0]) === null || _currentShareResponse === void 0 || (_currentShareResponse = _currentShareResponse.public_key) === null || _currentShareResponse === void 0 ? void 0 : _currentShareResponse.X) || ""
        });
        serverTimeOffsetResponses.push(serverTimeOffsetResponse || "0");
        if ((sessionTokenSigs === null || sessionTokenSigs === void 0 ? void 0 : sessionTokenSigs.length) > 0) {
          var _sessionTokenSigMetad;
          if (sessionTokenSigMetadata && (_sessionTokenSigMetad = sessionTokenSigMetadata[0]) !== null && _sessionTokenSigMetad !== void 0 && _sessionTokenSigMetad.ephemPublicKey) {
            sessionTokenSigPromises.push(decryptNodeData(sessionTokenSigMetadata[0], sessionTokenSigs[0], sessionAuthKey).catch((err) => log.error("session sig decryption", err)));
          } else {
            sessionTokenSigPromises.push(Promise.resolve(Buffer.from(sessionTokenSigs[0], "hex")));
          }
        } else {
          sessionTokenSigPromises.push(Promise.resolve(void 0));
        }
        if ((sessionTokens === null || sessionTokens === void 0 ? void 0 : sessionTokens.length) > 0) {
          var _sessionTokenMetadata;
          if (sessionTokenMetadata && (_sessionTokenMetadata = sessionTokenMetadata[0]) !== null && _sessionTokenMetadata !== void 0 && _sessionTokenMetadata.ephemPublicKey) {
            sessionTokenPromises.push(decryptNodeData(sessionTokenMetadata[0], sessionTokens[0], sessionAuthKey).catch((err) => log.error("session token sig decryption", err)));
          } else {
            sessionTokenPromises.push(Promise.resolve(Buffer.from(sessionTokens[0], "base64")));
          }
        } else {
          sessionTokenPromises.push(Promise.resolve(void 0));
        }
        if ((keys === null || keys === void 0 ? void 0 : keys.length) > 0) {
          const latestKey = currentShareResponse.result.keys[0];
          nodeIndexes.push(new import_bn8.default(latestKey.node_index));
          if (latestKey.share_metadata) {
            sharePromises.push(decryptNodeDataWithPadding(latestKey.share_metadata, Buffer.from(latestKey.share, "base64").toString("binary"), sessionAuthKey).catch((err) => log.error("share decryption", err)));
          }
        } else {
          nodeIndexes.push(void 0);
          sharePromises.push(Promise.resolve(void 0));
        }
      }
      const allPromises = await Promise.all(sharePromises.concat(sessionTokenSigPromises).concat(sessionTokenPromises));
      const sharesResolved = allPromises.slice(0, sharePromises.length);
      const sessionSigsResolved = allPromises.slice(sharePromises.length, sharePromises.length + sessionTokenSigPromises.length);
      const sessionTokensResolved = allPromises.slice(sharePromises.length + sessionTokenSigPromises.length, allPromises.length);
      const validSigs = sessionSigsResolved.filter((sig) => {
        if (sig) {
          return true;
        }
        return false;
      });
      if (!verifierParams.extended_verifier_id && validSigs.length < halfThreshold) {
        throw new Error(`Insufficient number of signatures from nodes, required: ${halfThreshold}, found: ${validSigs.length}`);
      }
      const validTokens = sessionTokensResolved.filter((token) => {
        if (token) {
          return true;
        }
        return false;
      });
      if (!verifierParams.extended_verifier_id && validTokens.length < halfThreshold) {
        throw new Error(`Insufficient number of session tokens from nodes, required: ${halfThreshold}, found: ${validTokens.length}`);
      }
      sessionTokensResolved.forEach((x, index) => {
        if (!x || !sessionSigsResolved[index]) sessionTokenData.push(void 0);
        else sessionTokenData.push({
          token: x.toString("base64"),
          signature: sessionSigsResolved[index].toString("hex"),
          node_pubx: completedRequests[index].result.node_pubx,
          node_puby: completedRequests[index].result.node_puby
        });
      });
      if (sharedState.resolved) return void 0;
      const decryptedShares = sharesResolved.reduce((acc, curr, index) => {
        if (curr) {
          acc.push({
            index: nodeIndexes[index],
            value: new import_bn8.default(curr)
          });
        }
        return acc;
      }, []);
      const allCombis = kCombinations(decryptedShares.length, halfThreshold);
      let privateKey = null;
      for (let j = 0; j < allCombis.length; j += 1) {
        const currentCombi = allCombis[j];
        const currentCombiShares = decryptedShares.filter((_, index) => currentCombi.includes(index));
        const shares = currentCombiShares.map((x) => x.value);
        const indices = currentCombiShares.map((x) => x.index);
        const derivedPrivateKey = lagrangeInterpolation(ecCurve, shares, indices);
        if (!derivedPrivateKey) continue;
        const decryptedPubKey = derivePubKey(ecCurve, derivedPrivateKey);
        const decryptedPubKeyX = decryptedPubKey.getX();
        const decryptedPubKeyY = decryptedPubKey.getY();
        if (decryptedPubKeyX.cmp(new import_bn8.default(thresholdPublicKey.X, 16)) === 0 && decryptedPubKeyY.cmp(new import_bn8.default(thresholdPublicKey.Y, 16)) === 0) {
          privateKey = derivedPrivateKey;
          break;
        }
      }
      if (privateKey === void 0 || privateKey === null) {
        throw new Error("could not derive private key");
      }
      let isNewKey = false;
      isNewKeyResponses.forEach((x) => {
        if (x.isNewKey === "true" && x.publicKey.toLowerCase() === thresholdPublicKey.X.toLowerCase()) {
          isNewKey = true;
        }
      });
      const serverOffsetTimes = serverTimeOffsetResponses.map((timestamp) => Number.parseInt(timestamp, 10));
      return {
        privateKey,
        sessionTokenData,
        thresholdNonceData,
        nodeIndexes,
        thresholdPubKey: thresholdPublicKey,
        isNewKey,
        serverTimeOffsetResponse: serverTimeOffset || calculateMedian(serverOffsetTimes)
      };
    }
    if (completedRequests.length < thresholdReqCount) {
      throw new Error(`Waiting for results from more nodes, pending: ${thresholdReqCount - completedRequests.length}`);
    }
    throw new Error(`Invalid results, threshold pub key: ${thresholdPublicKey}, nonce data found: ${!!thresholdNonceData}, extended verifierId: ${verifierParams.extended_verifier_id}`);
  }).then(async (res) => {
    var _nonceResult;
    const {
      privateKey,
      thresholdPubKey,
      sessionTokenData,
      nodeIndexes,
      thresholdNonceData,
      isNewKey,
      serverTimeOffsetResponse
    } = res;
    let nonceResult = thresholdNonceData;
    if (!privateKey) throw new Error("Invalid private key returned");
    const oAuthKey = privateKey;
    const oAuthPubKey = derivePubKey(ecCurve, oAuthKey);
    const oAuthPubkeyX = oAuthPubKey.getX().toString("hex", 64);
    const oAuthPubkeyY = oAuthPubKey.getY().toString("hex", 64);
    if (!nonceResult && !verifierParams.extended_verifier_id && !LEGACY_NETWORKS_ROUTE_MAP[network]) {
      const metadataNonceResult = await getOrSetSapphireMetadataNonce(network, thresholdPubKey.X, thresholdPubKey.Y, serverTimeOffset, oAuthKey);
      if (metadataNonceResult && !thresholdNonceData) {
        nonceResult = metadataNonceResult;
      } else {
        throw new Error(`invalid metadata result from nodes, nonce metadata is empty for verifier: ${verifier} and verifierId: ${verifierParams.verifier_id}`);
      }
    }
    let metadataNonce = new import_bn8.default((_nonceResult = nonceResult) !== null && _nonceResult !== void 0 && _nonceResult.nonce ? nonceResult.nonce.padStart(64, "0") : "0", "hex");
    let finalPubKey;
    let pubNonce;
    let typeOfUser = "v1";
    if (verifierParams.extended_verifier_id) {
      typeOfUser = "v2";
      finalPubKey = ecCurve.keyFromPublic({
        x: oAuthPubkeyX,
        y: oAuthPubkeyY
      }).getPublic();
    } else if (LEGACY_NETWORKS_ROUTE_MAP[network]) {
      if (enableOneKey) {
        nonceResult = await getOrSetNonce(legacyMetadataHost, ecCurve, serverTimeOffsetResponse, oAuthPubkeyX, oAuthPubkeyY, oAuthKey, !isNewKey);
        metadataNonce = new import_bn8.default(nonceResult.nonce || "0", 16);
        typeOfUser = nonceResult.typeOfUser;
        if (typeOfUser === "v2") {
          pubNonce = {
            X: nonceResult.pubNonce.x,
            Y: nonceResult.pubNonce.y
          };
          finalPubKey = ecCurve.keyFromPublic({
            x: oAuthPubkeyX,
            y: oAuthPubkeyY
          }).getPublic().add(ecCurve.keyFromPublic({
            x: nonceResult.pubNonce.x,
            y: nonceResult.pubNonce.y
          }).getPublic());
        } else {
          typeOfUser = "v1";
          metadataNonce = await getMetadata(legacyMetadataHost, {
            pub_key_X: oAuthPubkeyX,
            pub_key_Y: oAuthPubkeyY
          });
          const privateKeyWithNonce = oAuthKey.add(metadataNonce).umod(ecCurve.n);
          finalPubKey = ecCurve.keyFromPrivate(privateKeyWithNonce.toString(16, 64), "hex").getPublic();
        }
      } else {
        typeOfUser = "v1";
        metadataNonce = await getMetadata(legacyMetadataHost, {
          pub_key_X: oAuthPubkeyX,
          pub_key_Y: oAuthPubkeyY
        });
        const privateKeyWithNonce = oAuthKey.add(metadataNonce).umod(ecCurve.n);
        finalPubKey = ecCurve.keyFromPrivate(privateKeyWithNonce.toString(16, 64), "hex").getPublic();
      }
    } else {
      typeOfUser = "v2";
      finalPubKey = ecCurve.keyFromPublic({
        x: oAuthPubkeyX,
        y: oAuthPubkeyY
      }).getPublic().add(ecCurve.keyFromPublic({
        x: nonceResult.pubNonce.x,
        y: nonceResult.pubNonce.y
      }).getPublic());
      pubNonce = {
        X: nonceResult.pubNonce.x,
        Y: nonceResult.pubNonce.y
      };
    }
    if (!finalPubKey) {
      throw new Error("Invalid public key, this might be a bug, please report this to web3auth team");
    }
    let finalPrivKey = "";
    let isUpgraded = false;
    const oAuthKeyAddress = generateAddressFromPrivKey(keyType, oAuthKey);
    const finalWalletAddress = generateAddressFromPubKey(keyType, finalPubKey.getX(), finalPubKey.getY());
    let keyWithNonce = "";
    if (typeOfUser === "v1") {
      isUpgraded = null;
    } else if (typeOfUser === "v2") {
      isUpgraded = metadataNonce.eq(new import_bn8.default("0"));
    }
    if (typeOfUser === "v1" || typeOfUser === "v2" && metadataNonce.gt(new import_bn8.default(0))) {
      const privateKeyWithNonce = oAuthKey.add(metadataNonce).umod(ecCurve.n);
      keyWithNonce = privateKeyWithNonce.toString("hex", 64);
    }
    if (keyType === KEY_TYPE.SECP256K1) {
      finalPrivKey = keyWithNonce;
    } else if (keyType === KEY_TYPE.ED25519) {
      if (keyWithNonce && !nonceResult.seed) {
        throw new Error("Invalid data, seed data is missing for ed25519 key, Please report this bug");
      } else if (keyWithNonce && nonceResult.seed) {
        const decryptedSeed = await decryptSeedData(nonceResult.seed, new import_bn8.default(keyWithNonce, "hex"));
        finalPrivKey = decryptedSeed.toString("hex");
      }
    } else {
      throw new Error(`Invalid keyType: ${keyType}`);
    }
    let postboxKey = oAuthKey;
    let postboxPubX = oAuthPubkeyX;
    let postboxPubY = oAuthPubkeyY;
    if (keyType === KEY_TYPE.ED25519) {
      const {
        scalar,
        point
      } = getSecpKeyFromEd25519(privateKey);
      postboxKey = scalar;
      postboxPubX = point.getX().toString(16, 64);
      postboxPubY = point.getY().toString(16, 64);
      if (thresholdPubKey.SignerX.padStart(64, "0") !== postboxPubX || thresholdPubKey.SignerY.padStart(64, "0") !== postboxPubY) {
        throw new Error("Invalid postbox key");
      }
    }
    return {
      finalKeyData: {
        walletAddress: finalWalletAddress,
        X: finalPubKey.getX().toString(16, 64),
        // this is final pub x user before and after updating to 2/n
        Y: finalPubKey.getY().toString(16, 64),
        // this is final pub y user before and after updating to 2/n
        privKey: finalPrivKey
      },
      oAuthKeyData: {
        walletAddress: oAuthKeyAddress,
        X: oAuthPubkeyX,
        Y: oAuthPubkeyY,
        privKey: oAuthKey.toString("hex", 64)
      },
      postboxKeyData: {
        privKey: postboxKey.toString("hex", 64),
        X: postboxPubX,
        Y: postboxPubY
      },
      sessionData: {
        sessionTokenData,
        sessionAuthKey: sessionAuthKey.toString("hex").padStart(64, "0")
      },
      metadata: {
        pubNonce,
        nonce: metadataNonce,
        typeOfUser,
        upgraded: isUpgraded,
        serverTimeOffset: serverTimeOffsetResponse
      },
      nodesData: {
        nodeIndexes: nodeIndexes.map((x) => x.toNumber())
      }
    };
  });
}

// node_modules/@toruslabs/torus.js/dist/lib.esm/torus.js
var Torus = class _Torus {
  constructor({
    enableOneKey = false,
    clientId,
    network,
    serverTimeOffset = 0,
    allowHost,
    legacyMetadataHost,
    keyType = KEY_TYPE.SECP256K1
  }) {
    _defineProperty(this, "allowHost", void 0);
    _defineProperty(this, "serverTimeOffset", void 0);
    _defineProperty(this, "network", void 0);
    _defineProperty(this, "clientId", void 0);
    _defineProperty(this, "ec", void 0);
    _defineProperty(this, "enableOneKey", void 0);
    _defineProperty(this, "legacyMetadataHost", void 0);
    _defineProperty(this, "keyType", KEY_TYPE.SECP256K1);
    if (!clientId) throw new Error("Please provide a valid clientId in constructor");
    if (!network) throw new Error("Please provide a valid network in constructor");
    if (keyType === KEY_TYPE.ED25519 && LEGACY_NETWORKS_ROUTE_MAP[network]) {
      throw new Error(`keyType: ${keyType} is not supported by ${network} network`);
    }
    this.keyType = keyType;
    this.ec = new import_elliptic4.ec(this.keyType);
    this.serverTimeOffset = serverTimeOffset || 0;
    this.network = network;
    this.clientId = clientId;
    this.allowHost = allowHost || `${SIGNER_MAP[network]}/api/allow`;
    this.enableOneKey = enableOneKey;
    this.legacyMetadataHost = legacyMetadataHost || METADATA_MAP[network];
  }
  static enableLogging(v = true) {
    if (v) {
      log.enableAll();
      config.logRequestTracing = true;
    } else log.disableAll();
  }
  static setAPIKey(apiKey) {
    setAPIKey(apiKey);
  }
  static setEmbedHost(embedHost) {
    setEmbedHost(embedHost);
  }
  static setSessionTime(sessionTime) {
    _Torus.sessionTime = sessionTime;
  }
  static isGetOrSetNonceError(err) {
    return err instanceof GetOrSetNonceError;
  }
  static getPostboxKey(torusKey) {
    if (torusKey.metadata.typeOfUser === "v1") {
      return torusKey.finalKeyData.privKey || torusKey.postboxKeyData.privKey;
    }
    return torusKey.postboxKeyData.privKey;
  }
  async retrieveShares(params) {
    const {
      verifier,
      verifierParams,
      idToken,
      nodePubkeys,
      indexes,
      endpoints,
      useDkg,
      extraParams = {},
      checkCommitment = true
    } = params;
    if (nodePubkeys.length === 0) {
      throw new Error("nodePubkeys param is required");
    }
    if (nodePubkeys.length !== indexes.length) {
      throw new Error("nodePubkeys length must be same as indexes length");
    }
    if (nodePubkeys.length !== endpoints.length) {
      throw new Error("nodePubkeys length must be same as endpoints length");
    }
    let shouldUseDkg;
    if (typeof useDkg === "boolean") {
      if (useDkg === false && LEGACY_NETWORKS_ROUTE_MAP[this.network]) {
        throw new Error(`useDkg cannot be false for legacy network; ${this.network}`);
      }
      shouldUseDkg = this.keyType === KEY_TYPE.ED25519 ? false : useDkg;
    } else if (this.keyType === KEY_TYPE.ED25519) {
      shouldUseDkg = false;
    } else {
      shouldUseDkg = true;
    }
    if (!shouldUseDkg && nodePubkeys.length === 0) {
      throw new Error("nodePubkeys param is required");
    }
    if (!extraParams.session_token_exp_second) {
      extraParams.session_token_exp_second = _Torus.sessionTime;
    }
    return retrieveOrImportShare({
      legacyMetadataHost: this.legacyMetadataHost,
      serverTimeOffset: this.serverTimeOffset,
      enableOneKey: this.enableOneKey,
      ecCurve: this.ec,
      keyType: this.keyType,
      allowHost: this.allowHost,
      network: this.network,
      clientId: this.clientId,
      endpoints,
      indexes,
      verifier,
      verifierParams,
      idToken,
      useDkg: shouldUseDkg,
      newImportedShares: [],
      overrideExistingKey: false,
      nodePubkeys,
      extraParams,
      checkCommitment
    });
  }
  async getPublicAddress(endpoints, torusNodePubs, {
    verifier,
    verifierId,
    extendedVerifierId
  }) {
    log.info(torusNodePubs, {
      verifier,
      verifierId,
      extendedVerifierId
    });
    return this.getNewPublicAddress(endpoints, {
      verifier,
      verifierId,
      extendedVerifierId
    }, this.enableOneKey);
  }
  async importPrivateKey(params) {
    const {
      nodeIndexes,
      newPrivateKey,
      verifier,
      verifierParams,
      idToken,
      nodePubkeys,
      endpoints,
      extraParams = {},
      checkCommitment = true
    } = params;
    if (LEGACY_NETWORKS_ROUTE_MAP[this.network]) {
      throw new Error(`importPrivateKey is not supported by legacy network; ${this.network}`);
    }
    if (endpoints.length !== nodeIndexes.length) {
      throw new Error(`length of endpoints array must be same as length of nodeIndexes array`);
    }
    if (!extraParams.session_token_exp_second) {
      extraParams.session_token_exp_second = _Torus.sessionTime;
    }
    let privKeyBuffer;
    if (this.keyType === KEY_TYPE.SECP256K1) {
      privKeyBuffer = Buffer.from(newPrivateKey.padStart(64, "0"), "hex");
      if (privKeyBuffer.length !== 32) {
        throw new Error("Invalid private key length for given secp256k1 key");
      }
    }
    if (this.keyType === KEY_TYPE.ED25519) {
      privKeyBuffer = Buffer.from(newPrivateKey.padStart(64, "0"), "hex");
      if (privKeyBuffer.length !== 32) {
        throw new Error("Invalid private key length for given ed25519 key");
      }
    }
    const sharesData = await generateShares(this.ec, this.keyType, this.serverTimeOffset, nodeIndexes, nodePubkeys, privKeyBuffer);
    if (this.keyType === KEY_TYPE.ED25519) {
      const ed25519Key = getEd25519ExtendedPublicKey(privKeyBuffer);
      const ed25519PubKey = encodeEd25519Point(ed25519Key.point);
      const encodedPubKey = encodeEd25519Point(sharesData[0].final_user_point);
      const importedPubKey = Buffer.from(ed25519PubKey).toString("hex");
      const derivedPubKey = encodedPubKey.toString("hex");
      if (importedPubKey !== derivedPubKey) {
        throw new Error("invalid shares data for ed25519 key, public key is not matching after generating shares");
      }
    }
    return retrieveOrImportShare({
      legacyMetadataHost: this.legacyMetadataHost,
      serverTimeOffset: this.serverTimeOffset,
      enableOneKey: this.enableOneKey,
      ecCurve: this.ec,
      keyType: this.keyType,
      allowHost: this.allowHost,
      network: this.network,
      clientId: this.clientId,
      endpoints,
      indexes: nodeIndexes,
      verifier,
      verifierParams,
      idToken,
      useDkg: false,
      overrideExistingKey: true,
      newImportedShares: sharesData,
      nodePubkeys,
      extraParams,
      checkCommitment
    });
  }
  /**
   * Note: use this function only for openlogin tkey account lookups.
   * this is a legacy function, use getPublicAddress instead for new networks
   */
  async getUserTypeAndAddress(endpoints, {
    verifier,
    verifierId,
    extendedVerifierId
  }) {
    return this.getNewPublicAddress(endpoints, {
      verifier,
      verifierId,
      extendedVerifierId
    }, true);
  }
  async getNewPublicAddress(endpoints, {
    verifier,
    verifierId,
    extendedVerifierId
  }, enableOneKey) {
    const keyAssignResult = await GetPubKeyOrKeyAssign({
      endpoints,
      network: this.network,
      verifier,
      verifierId,
      keyType: this.keyType,
      extendedVerifierId
    });
    const {
      errorResult,
      keyResult,
      nodeIndexes = [],
      serverTimeOffset
    } = keyAssignResult;
    const finalServerTimeOffset = this.serverTimeOffset || serverTimeOffset;
    const {
      nonceResult
    } = keyAssignResult;
    if (errorResult && JSON.stringify(errorResult).toLowerCase().includes("verifier not supported")) {
      throw new Error(`Verifier not supported. Check if you: 

      1. Are on the right network (Torus testnet/mainnet) 

      2. Have setup a verifier on dashboard.web3auth.io?`);
    }
    if (errorResult) {
      throw new Error(`node results do not match at first lookup ${JSON.stringify(keyResult || {})}, ${JSON.stringify(errorResult || {})}`);
    }
    if (!(keyResult !== null && keyResult !== void 0 && keyResult.keys)) {
      throw new Error(`node results do not match at final lookup ${JSON.stringify(keyResult || {})}, ${JSON.stringify(errorResult || {})}`);
    }
    if (!nonceResult && !extendedVerifierId && !LEGACY_NETWORKS_ROUTE_MAP[this.network]) {
      throw new GetOrSetNonceError("metadata nonce is missing in share response");
    }
    const {
      pub_key_X: X,
      pub_key_Y: Y
    } = keyResult.keys[0];
    let pubNonce;
    const nonce = new import_bn9.default((nonceResult === null || nonceResult === void 0 ? void 0 : nonceResult.nonce) || "0", 16);
    let oAuthPubKey;
    let finalPubKey;
    if (extendedVerifierId) {
      finalPubKey = this.ec.keyFromPublic({
        x: X,
        y: Y
      }).getPublic();
      oAuthPubKey = finalPubKey;
    } else if (LEGACY_NETWORKS_ROUTE_MAP[this.network]) {
      return this.formatLegacyPublicKeyData({
        isNewKey: keyResult.is_new_key,
        enableOneKey,
        finalKeyResult: {
          keys: keyResult.keys
        },
        serverTimeOffset: finalServerTimeOffset
      });
    } else {
      const v2NonceResult = nonceResult;
      oAuthPubKey = this.ec.keyFromPublic({
        x: X,
        y: Y
      }).getPublic();
      finalPubKey = this.ec.keyFromPublic({
        x: X,
        y: Y
      }).getPublic().add(this.ec.keyFromPublic({
        x: v2NonceResult.pubNonce.x,
        y: v2NonceResult.pubNonce.y
      }).getPublic());
      pubNonce = {
        X: v2NonceResult.pubNonce.x,
        Y: v2NonceResult.pubNonce.y
      };
    }
    if (!oAuthPubKey) {
      throw new Error("Unable to derive oAuthPubKey");
    }
    const oAuthX = oAuthPubKey.getX().toString(16, 64);
    const oAuthY = oAuthPubKey.getY().toString(16, 64);
    const oAuthAddress = generateAddressFromPubKey(this.keyType, oAuthPubKey.getX(), oAuthPubKey.getY());
    if (!finalPubKey) {
      throw new Error("Unable to derive finalPubKey");
    }
    const finalX = finalPubKey ? finalPubKey.getX().toString(16, 64) : "";
    const finalY = finalPubKey ? finalPubKey.getY().toString(16, 64) : "";
    const finalAddress = finalPubKey ? generateAddressFromPubKey(this.keyType, finalPubKey.getX(), finalPubKey.getY()) : "";
    return {
      oAuthKeyData: {
        walletAddress: oAuthAddress,
        X: oAuthX,
        Y: oAuthY
      },
      finalKeyData: {
        walletAddress: finalAddress,
        X: finalX,
        Y: finalY
      },
      metadata: {
        pubNonce,
        nonce,
        upgraded: (nonceResult === null || nonceResult === void 0 ? void 0 : nonceResult.upgraded) || false,
        typeOfUser: "v2",
        serverTimeOffset: finalServerTimeOffset
      },
      nodesData: {
        nodeIndexes
      }
    };
  }
  async formatLegacyPublicKeyData(params) {
    var _nonceResult;
    const {
      finalKeyResult,
      enableOneKey,
      isNewKey,
      serverTimeOffset
    } = params;
    const {
      pub_key_X: X,
      pub_key_Y: Y
    } = finalKeyResult.keys[0];
    let nonceResult;
    let nonce;
    let finalPubKey;
    let typeOfUser;
    let pubNonce;
    const oAuthPubKey = this.ec.keyFromPublic({
      x: X,
      y: Y
    }).getPublic();
    const finalServerTimeOffset = this.serverTimeOffset || serverTimeOffset;
    if (enableOneKey) {
      try {
        nonceResult = await getOrSetNonce(this.legacyMetadataHost, this.ec, finalServerTimeOffset, X, Y, void 0, !isNewKey);
        nonce = new import_bn9.default(nonceResult.nonce || "0", 16);
        typeOfUser = nonceResult.typeOfUser;
      } catch {
        throw new GetOrSetNonceError();
      }
      if (nonceResult.typeOfUser === "v1") {
        nonce = await getMetadata(this.legacyMetadataHost, {
          pub_key_X: X,
          pub_key_Y: Y
        });
        finalPubKey = this.ec.keyFromPublic({
          x: X,
          y: Y
        }).getPublic().add(this.ec.keyFromPrivate(nonce.toString(16, 64), "hex").getPublic());
      } else if (nonceResult.typeOfUser === "v2") {
        finalPubKey = this.ec.keyFromPublic({
          x: X,
          y: Y
        }).getPublic().add(this.ec.keyFromPublic({
          x: nonceResult.pubNonce.x,
          y: nonceResult.pubNonce.y
        }).getPublic());
        pubNonce = {
          X: nonceResult.pubNonce.x,
          Y: nonceResult.pubNonce.y
        };
      } else {
        throw new Error("getOrSetNonce should always return typeOfUser.");
      }
    } else {
      typeOfUser = "v1";
      nonce = await getMetadata(this.legacyMetadataHost, {
        pub_key_X: X,
        pub_key_Y: Y
      });
      finalPubKey = this.ec.keyFromPublic({
        x: X,
        y: Y
      }).getPublic().add(this.ec.keyFromPrivate(nonce.toString(16, 64), "hex").getPublic());
    }
    if (!oAuthPubKey) {
      throw new Error("Unable to derive oAuthPubKey");
    }
    const oAuthX = oAuthPubKey.getX().toString(16, 64);
    const oAuthY = oAuthPubKey.getY().toString(16, 64);
    const oAuthAddress = generateAddressFromPubKey(this.keyType, oAuthPubKey.getX(), oAuthPubKey.getY());
    if (typeOfUser === "v2" && !finalPubKey) {
      throw new Error("Unable to derive finalPubKey");
    }
    const finalX = finalPubKey ? finalPubKey.getX().toString(16, 64) : "";
    const finalY = finalPubKey ? finalPubKey.getY().toString(16, 64) : "";
    const finalAddress = finalPubKey ? generateAddressFromPubKey(this.keyType, finalPubKey.getX(), finalPubKey.getY()) : "";
    return {
      oAuthKeyData: {
        walletAddress: oAuthAddress,
        X: oAuthX,
        Y: oAuthY
      },
      finalKeyData: {
        walletAddress: finalAddress,
        X: finalX,
        Y: finalY
      },
      metadata: {
        pubNonce,
        nonce,
        upgraded: ((_nonceResult = nonceResult) === null || _nonceResult === void 0 ? void 0 : _nonceResult.upgraded) || false,
        typeOfUser,
        serverTimeOffset: finalServerTimeOffset
      },
      nodesData: {
        nodeIndexes: []
      }
    };
  }
};
_defineProperty(Torus, "sessionTime", 86400);

// node_modules/@toruslabs/torus.js/dist/lib.esm/helpers/tssPubKeyUtils.js
var import_loglevel6 = __toESM(require_loglevel());
var GetOrSetTssDKGPubKey = async (params) => {
  const {
    endpoints,
    verifier,
    verifierId,
    tssVerifierId,
    keyType = KEY_TYPE.SECP256K1
  } = params;
  const minThreshold = ~~(endpoints.length / 2) + 1;
  const lookupPromises = endpoints.map((x) => post(x, generateJsonRPCObject(JRPC_METHODS.GET_OR_SET_KEY, {
    distributed_metadata: true,
    verifier,
    verifier_id: verifierId,
    extended_verifier_id: tssVerifierId,
    one_key_flow: true,
    key_type: keyType,
    fetch_node_index: true,
    client_time: Math.floor(Date.now() / 1e3).toString()
  }), {}, {
    logTracingHeader: false
  }).catch((err) => import_loglevel6.default.error(`${JRPC_METHODS.GET_OR_SET_KEY} request failed`, err)));
  const nodeIndexes = [];
  const result = await Some(lookupPromises, async (lookupResults) => {
    const lookupPubKeys = lookupResults.filter((x1) => {
      if (x1 && !x1.error) {
        return x1;
      }
      return false;
    });
    const errorResult = thresholdSame(lookupResults.map((x2) => x2 && x2.error), minThreshold);
    const keyResult = thresholdSame(lookupPubKeys.map((x3) => x3 && normalizeKeysResult(x3.result)), minThreshold);
    if (keyResult || errorResult) {
      if (keyResult) {
        lookupResults.forEach((x1) => {
          if (x1 && x1.result) {
            const currentNodePubKey = x1.result.keys[0].pub_key_X.toLowerCase();
            const thresholdPubKey = keyResult.keys[0].pub_key_X.toLowerCase();
            if (currentNodePubKey === thresholdPubKey) {
              const nodeIndex = Number.parseInt(x1.result.node_index);
              if (nodeIndex) nodeIndexes.push(nodeIndex);
            }
          }
        });
      }
      return Promise.resolve({
        keyResult,
        nodeIndexes,
        errorResult
      });
    }
    return Promise.reject(new Error(`invalid public key result: ${JSON.stringify(lookupResults)} for tssVerifierId: ${tssVerifierId} `));
  });
  if (result.errorResult) {
    throw new Error(`invalid public key result,errorResult: ${JSON.stringify(result.errorResult)}`);
  }
  const key = result.keyResult.keys[0];
  return {
    key: {
      pubKeyX: key.pub_key_X,
      pubKeyY: key.pub_key_Y,
      address: key.address,
      createdAt: key.created_at
    },
    nodeIndexes: result.nodeIndexes,
    isNewKey: result.keyResult.is_new_key
  };
};

export {
  JRPC_METHODS,
  SAPPHIRE_METADATA_URL,
  SAPPHIRE_DEVNET_METADATA_URL,
  Point,
  Share,
  Polynomial,
  GetOrSetNonceError,
  keccak2562 as keccak256,
  generatePrivateKey,
  getKeyCurve,
  normalizeKeysResult,
  normalizeLookUpResult,
  kCombinations,
  thresholdSame,
  encParamsBufToHex,
  encParamsHexToBuf,
  getProxyCoordinatorEndpointIndex,
  calculateMedian,
  waitFor,
  retryCommitment,
  lagrangeInterpolatePolynomial,
  lagrangeInterpolation,
  generateRandomPolynomial,
  getSecpKeyFromEd25519,
  convertMetadataToNonce,
  decryptNodeData,
  decryptNodeDataWithPadding,
  generateMetadataParams,
  getMetadata,
  generateNonceMetadataParams,
  getOrSetNonce,
  getNonce,
  decryptSeedData,
  getOrSetSapphireMetadataNonce,
  stripHexPrefix,
  toChecksumAddress,
  getEd25519ExtendedPublicKey,
  encodeEd25519Point,
  generateEd25519KeyData,
  generateSecp256k1KeyData,
  generateAddressFromPrivKey,
  generateAddressFromPubKey,
  getPostboxKeyFrom1OutOf1,
  derivePubKey,
  getEncryptionEC,
  generateShares,
  GetPubKeyOrKeyAssign,
  VerifierLookupRequest,
  retrieveOrImportShare,
  Torus,
  GetOrSetTssDKGPubKey
};
//# sourceMappingURL=chunk-LQPOXDXK.js.map
