import {
  CustomAuth$1,
  KEY_NOT_FOUND,
  KeyType,
  ONE_KEY_DELETE_NONCE,
  Point$1,
  Polynomial$1,
  PublicPolynomial$1,
  PublicShare$1,
  SHARE_DELETED,
  Share$1,
  ShareStore$1,
  TkeyError,
  decrypt,
  encrypt,
  generatePrivateExcludingIndexes,
  getPubKeyECC,
  getPubKeyPoint,
  prettyPrintError,
  secp256k1,
  stripHexPrefix,
  toPrivKeyEC,
  toPrivKeyECC
} from "./chunk-CW4ZZO2K.js";
import {
  Torus,
  getEd25519ExtendedPublicKey,
  getSecpKeyFromEd25519,
  keccak256 as keccak2562
} from "./chunk-LQPOXDXK.js";
import {
  getRandomBytes
} from "./chunk-H6CUK76M.js";
import {
  _defineProperty,
  _objectSpread2,
  post,
  require_elliptic,
  require_json_stable_stringify,
  require_loglevel
} from "./chunk-NYBMST6M.js";
import {
  keccak256
} from "./chunk-O35336FG.js";
import {
  require_bn
} from "./chunk-J3UDRN3X.js";
import {
  __toESM
} from "./chunk-OL46QLBJ.js";

// node_modules/@tkey/service-provider-base/dist/lib.esm/ServiceProviderBase.js
var import_bn = __toESM(require_bn());
var ServiceProviderBase = class _ServiceProviderBase {
  constructor({
    enableLogging = false,
    postboxKey
  }) {
    _defineProperty(this, "enableLogging", void 0);
    _defineProperty(this, "postboxKey", void 0);
    _defineProperty(this, "serviceProviderName", void 0);
    _defineProperty(this, "migratableKey", null);
    this.enableLogging = enableLogging;
    this.postboxKey = new import_bn.default(postboxKey, "hex");
    this.serviceProviderName = "ServiceProviderBase";
  }
  static fromJSON(value) {
    const {
      enableLogging,
      postboxKey,
      serviceProviderName
    } = value;
    if (serviceProviderName !== "ServiceProviderBase") return void 0;
    return new _ServiceProviderBase({
      enableLogging,
      postboxKey
    });
  }
  async encrypt(msg) {
    const publicKey = this.retrievePubKey("ecc");
    return encrypt(publicKey, msg);
  }
  async decrypt(msg) {
    return decrypt(toPrivKeyECC(this.postboxKey), msg);
  }
  retrievePubKeyPoint() {
    return toPrivKeyEC(this.postboxKey).getPublic();
  }
  retrievePubKey(type) {
    if (type === "ecc") {
      return getPubKeyECC(this.postboxKey);
    }
    throw new Error("Unsupported pub key type");
  }
  sign(msg) {
    const tmp = new import_bn.default(msg, "hex");
    const sig = toPrivKeyEC(this.postboxKey).sign(tmp.toString("hex"));
    return Buffer.from(sig.r.toString(16, 64) + sig.s.toString(16, 64) + new import_bn.default(0).toString(16, 2), "hex").toString("base64");
  }
  toJSON() {
    return {
      enableLogging: this.enableLogging,
      postboxKey: this.postboxKey.toString("hex"),
      serviceProviderName: this.serviceProviderName
    };
  }
};
var ServiceProviderBase$1 = ServiceProviderBase;

// node_modules/@tkey/service-provider-torus/dist/lib.esm/TorusServiceProvider.js
var import_bn2 = __toESM(require_bn());
var TorusServiceProvider = class _TorusServiceProvider extends ServiceProviderBase$1 {
  constructor({
    enableLogging = false,
    postboxKey,
    customAuthArgs
  }) {
    super({
      enableLogging,
      postboxKey
    });
    _defineProperty(this, "customAuthInstance", void 0);
    _defineProperty(this, "singleLoginKey", void 0);
    _defineProperty(this, "torusKey", void 0);
    _defineProperty(this, "migratableKey", null);
    _defineProperty(this, "customAuthArgs", void 0);
    this.customAuthArgs = customAuthArgs;
    this.customAuthInstance = new CustomAuth$1(customAuthArgs);
    this.serviceProviderName = "TorusServiceProvider";
  }
  static fromJSON(value) {
    const {
      enableLogging,
      postboxKey,
      customAuthArgs,
      serviceProviderName
    } = value;
    if (serviceProviderName !== "TorusServiceProvider") return void 0;
    return new _TorusServiceProvider({
      enableLogging,
      postboxKey,
      customAuthArgs
    });
  }
  async init(params) {
    return this.customAuthInstance.init(params);
  }
  /**
   * Trigger login flow. Returns `null` in redirect mode.
   */
  async triggerLogin(params) {
    const obj = await this.customAuthInstance.triggerLogin(params);
    if (obj) {
      const localPrivKey = Torus.getPostboxKey(obj);
      this.torusKey = obj;
      if (!obj.metadata.upgraded) {
        const {
          finalKeyData,
          oAuthKeyData
        } = obj;
        const privKey = finalKeyData.privKey || oAuthKeyData.privKey;
        this.migratableKey = new import_bn2.default(privKey, "hex");
      }
      this.postboxKey = new import_bn2.default(localPrivKey, "hex");
    }
    return obj;
  }
  /**
   * Trigger login flow. Returns `null` in redirect mode.
   */
  async triggerAggregateLogin(params) {
    const obj = await this.customAuthInstance.triggerAggregateLogin(params);
    if (obj) {
      const localPrivKey = Torus.getPostboxKey(obj);
      this.torusKey = obj;
      if (!obj.metadata.upgraded) {
        const {
          finalKeyData,
          oAuthKeyData
        } = obj;
        const privKey = finalKeyData.privKey || oAuthKeyData.privKey;
        this.migratableKey = new import_bn2.default(privKey, "hex");
      }
      this.postboxKey = new import_bn2.default(localPrivKey, "hex");
    }
    return obj;
  }
  toJSON() {
    return _objectSpread2(_objectSpread2({}, super.toJSON()), {}, {
      serviceProviderName: this.serviceProviderName,
      customAuthArgs: this.customAuthArgs
    });
  }
};
var TorusServiceProvider$1 = TorusServiceProvider;

// node_modules/@tkey/tss/dist/lib.esm/util.js
var import_bn3 = __toESM(require_bn());
var kCombinations = (s, k) => {
  let set = s;
  if (typeof set === "number") {
    set = Array.from({
      length: set
    }, (_, i) => i);
  }
  if (k > set.length || k <= 0) {
    return [];
  }
  if (k === set.length) {
    return [set];
  }
  if (k === 1) {
    return set.reduce((acc, cur) => [...acc, [cur]], []);
  }
  const combs = [];
  let tailCombs = [];
  for (let i = 0; i <= set.length - k + 1; i += 1) {
    tailCombs = kCombinations(set.slice(i + 1), k - 1);
    for (let j = 0; j < tailCombs.length; j += 1) {
      combs.push([set[i], ...tailCombs[j]]);
    }
  }
  return combs;
};
function generateSalt(ec5) {
  return ec5.genKeyPair().getPrivate().toString("hex", 64);
}
function getLagrangeCoeffs(ecCurve, _allIndexes, _myIndex, _target = 0) {
  const allIndexes = _allIndexes.map((i) => new import_bn3.default(i));
  const myIndex = new import_bn3.default(_myIndex);
  const target = new import_bn3.default(_target);
  let upper = new import_bn3.default(1);
  let lower = new import_bn3.default(1);
  for (let j = 0; j < allIndexes.length; j += 1) {
    if (myIndex.cmp(allIndexes[j]) !== 0) {
      let tempUpper = target.sub(allIndexes[j]);
      tempUpper = tempUpper.umod(ecCurve.curve.n);
      upper = upper.mul(tempUpper);
      upper = upper.umod(ecCurve.curve.n);
      let tempLower = myIndex.sub(allIndexes[j]);
      tempLower = tempLower.umod(ecCurve.curve.n);
      lower = lower.mul(tempLower).umod(ecCurve.curve.n);
    }
  }
  return upper.mul(lower.invm(ecCurve.curve.n)).umod(ecCurve.curve.n);
}
function lagrangeInterpolation(ecCurve, shares, nodeIndex) {
  if (shares.length !== nodeIndex.length) {
    return null;
  }
  let secret = new import_bn3.default(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new import_bn3.default(1);
    let lower = new import_bn3.default(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(ecCurve.curve.n);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(ecCurve.curve.n);
        lower = lower.mul(temp).umod(ecCurve.curve.n);
      }
    }
    let delta = upper.mul(lower.invm(ecCurve.curve.n)).umod(ecCurve.curve.n);
    delta = delta.mul(shares[i]).umod(ecCurve.curve.n);
    secret = secret.add(delta);
  }
  return secret.umod(ecCurve.curve.n);
}
function pointToHex(p) {
  return {
    x: p.x.toString(16, 64),
    y: p.y.toString(16, 64)
  };
}
function getPubKeyPoint2(s, ec5) {
  const p = ec5.g.mul(s);
  return Point$1.fromElliptic(p);
}
var DELIMITERS = {
  Delimiter1: "",
  Delimiter2: "",
  Delimiter3: "",
  Delimiter4: ""
};
function getExtendedVerifierId(verifierId, tssTag, tssNonce) {
  return `${verifierId}${DELIMITERS.Delimiter2}${tssTag}${DELIMITERS.Delimiter3}${tssNonce}`;
}
function getEd25519SeedStoreDomainKey(tssTag) {
  return tssTag ? `ed25519Seed/${tssTag}` : "ed25519Seed";
}

// node_modules/@tkey/tss/dist/lib.esm/provider.js
var TSSTorusServiceProvider = class extends TorusServiceProvider$1 {
  constructor(...args) {
    super(...args);
    _defineProperty(this, "verifierName", void 0);
    _defineProperty(this, "verifierId", void 0);
  }
  async getRSSNodeDetails() {
    if (!this.verifierId) throw new Error("no verifierId, not logged in");
    if (!this.verifierName) throw new Error("no verifierName, not logged in");
    const {
      torusNodeRSSEndpoints: tssNodeEndpoints,
      torusNodePub: torusPubKeys
    } = await this.customAuthInstance.nodeDetailManager.getNodeDetails({
      verifier: this.verifierName,
      verifierId: this.verifierId
    });
    return {
      serverEndpoints: tssNodeEndpoints,
      serverPubKeys: torusPubKeys.map((key) => {
        return {
          x: key.X,
          y: key.Y
        };
      }),
      serverThreshold: Math.ceil(tssNodeEndpoints.length / 2)
    };
  }
  async getTSSPubKey(tssTag, tssNonce) {
    if (!this.verifierName || !this.verifierId) throw new Error("verifier userinfo not found, not logged in yet");
    const nodeDetails = await this.customAuthInstance.nodeDetailManager.getNodeDetails({
      verifier: this.verifierName,
      verifierId: this.verifierId
    });
    const tssServerPub = await this.customAuthInstance.torus.getPublicAddress(nodeDetails.torusNodeSSSEndpoints, nodeDetails.torusNodePub, {
      verifier: this.verifierName,
      verifierId: this.verifierId,
      extendedVerifierId: getExtendedVerifierId(this.verifierId, tssTag, tssNonce)
    });
    return {
      pubKey: new Point$1(tssServerPub.finalKeyData.X, tssServerPub.finalKeyData.Y),
      nodeIndexes: tssServerPub.nodesData.nodeIndexes || []
    };
  }
  getVerifierNameVerifierId() {
    return `${this.verifierName}${this.verifierId}`;
  }
  async triggerLogin(params) {
    const obj = await super.triggerLogin(params);
    if (obj) {
      const {
        verifier,
        verifierId
      } = obj.userInfo;
      this.verifierName = verifier;
      this.verifierId = verifierId;
    }
    return obj;
  }
  async triggerAggregateLogin(params) {
    const obj = await super.triggerAggregateLogin(params);
    if (obj) {
      const {
        verifier,
        verifierId
      } = obj.userInfo[0];
      this.verifierName = verifier;
      this.verifierId = verifierId;
    }
    return obj;
  }
};

// node_modules/@tkey/core/dist/lib.esm/authMetadata.js
var import_json_stable_stringify2 = __toESM(require_json_stable_stringify());

// node_modules/@tkey/core/dist/lib.esm/errors.js
var CoreError = class _CoreError extends TkeyError {
  constructor(code, message) {
    super(code, message);
    Object.defineProperty(this, "name", {
      value: "CoreError"
    });
  }
  static fromCode(code, extraMessage = "") {
    return new _CoreError(code, `${_CoreError.messages[code]} ${extraMessage}`);
  }
  static default(extraMessage = "") {
    return new _CoreError(1e3, `${_CoreError.messages[1e3]} ${extraMessage}`);
  }
  // Custom methods
  // Metadata
  static metadataUndefined(extraMessage = "") {
    return _CoreError.fromCode(1101, extraMessage);
  }
  static delete1OutOf1OnlyManualSync(extraMessage = "") {
    return _CoreError.fromCode(1601, extraMessage);
  }
  static metadataGetFailed(extraMessage = "") {
    return _CoreError.fromCode(1102, extraMessage);
  }
  static metadataPostFailed(extraMessage = "") {
    return _CoreError.fromCode(1103, extraMessage);
  }
  // TkeyData
  static tkeyStoreInvalid(extraMessage = "") {
    return _CoreError.fromCode(1201, extraMessage);
  }
  static tkeyEncryptionFailed(extraMessage = "") {
    return _CoreError.fromCode(1202, extraMessage);
  }
  static tkeyDecryptionFailed(extraMessage = "") {
    return _CoreError.fromCode(1203, extraMessage);
  }
  // Shares
  static privateKeyUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1301, extraMessage);
  }
  static unableToReconstruct(extraMessage = "") {
    return _CoreError.fromCode(1302, extraMessage);
  }
  static incorrectReconstruction(extraMessage = "") {
    return _CoreError.fromCode(1303, extraMessage);
  }
  static encryptedShareStoreUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1306, extraMessage);
  }
  // Metadata locks
  static acquireLockFailed(extraMessage = "") {
    return _CoreError.fromCode(1401, extraMessage);
  }
  static releaseLockFailed(extraMessage = "") {
    return _CoreError.fromCode(1402, extraMessage);
  }
  // Authmetadata
  static privKeyUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1501, extraMessage);
  }
  static metadataPubKeyUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1502, extraMessage);
  }
  static authMetadataGetUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1503, extraMessage);
  }
  static authMetadataSetUnavailable(extraMessage = "") {
    return _CoreError.fromCode(1504, extraMessage);
  }
};
_defineProperty(CoreError, "messages", {
  1e3: "Custom",
  // Misc
  1001: "Unable to delete service provider share",
  1002: "Wrong share index",
  1003: "Unable to updateSDK",
  // metadata
  1101: "metadata not found, SDK likely not initialized",
  1102: "getMetadata errored",
  1103: "setMetadata errored",
  1104: "previouslyFetchedCloudMetadata provided in initialization is outdated",
  1105: "previouslyFetchedCloudMetadata.nonce should never be higher than the latestShareDetails, please contact support",
  // tkeystore
  1201: "Invalid tkeyStore",
  1202: "Encryption failed",
  1203: "Decryption failed",
  // shares
  1301: "Private key not available. Please reconstruct key first",
  1302: "Unable to reconstruct",
  1303: "reconstructed key is not pub key",
  1304: "Share found in unexpected polynomial",
  1305: "Input is not supported",
  1306: "no encrypted share store for share exists",
  1307: "Share doesn't exist",
  1308: "Share was deleted",
  // lock
  1401: "Unable to acquire lock",
  1402: "Unable to release lock",
  // auth metadata
  1501: "privkey unavailable",
  1502: "metadata pubkey unavailable",
  1503: "getAuthMetadata errored",
  1504: "setAuthMetadata errored",
  1601: "delete1OutOf1 requires manualSync=true"
});
var CoreError$1 = CoreError;

// node_modules/@tkey/core/dist/lib.esm/metadata.js
var import_bn5 = __toESM(require_bn());
var import_json_stable_stringify = __toESM(require_json_stable_stringify());

// node_modules/@tkey/core/dist/lib.esm/lagrangeInterpolatePolynomial.js
var import_bn4 = __toESM(require_bn());
function generatePrivateBN() {
  return secp256k1.genKeyPair().getPrivate();
}
var generateEmptyBNArray = (length) => Array.from({
  length
}, () => new import_bn4.default(0));
var denominator = (i, innerPoints) => {
  let result = new import_bn4.default(1);
  const xi = innerPoints[i].x;
  for (let j = innerPoints.length - 1; j >= 0; j -= 1) {
    if (i !== j) {
      let tmp = new import_bn4.default(xi);
      tmp = tmp.sub(innerPoints[j].x);
      tmp = tmp.umod(secp256k1.curve.n);
      result = result.mul(tmp);
      result = result.umod(secp256k1.curve.n);
    }
  }
  return result;
};
var interpolationPoly = (i, innerPoints) => {
  let coefficients = generateEmptyBNArray(innerPoints.length);
  const d = denominator(i, innerPoints);
  if (d.cmp(new import_bn4.default(0)) === 0) {
    throw CoreError$1.default("Denominator for interpolationPoly is 0");
  }
  coefficients[0] = d.invm(secp256k1.curve.n);
  for (let k = 0; k < innerPoints.length; k += 1) {
    const newCoefficients = generateEmptyBNArray(innerPoints.length);
    if (k !== i) {
      let j;
      if (k < i) {
        j = k + 1;
      } else {
        j = k;
      }
      j -= 1;
      for (; j >= 0; j -= 1) {
        newCoefficients[j + 1] = newCoefficients[j + 1].add(coefficients[j]);
        newCoefficients[j + 1] = newCoefficients[j + 1].umod(secp256k1.curve.n);
        let tmp = new import_bn4.default(innerPoints[k].x);
        tmp = tmp.mul(coefficients[j]);
        tmp = tmp.umod(secp256k1.curve.n);
        newCoefficients[j] = newCoefficients[j].sub(tmp);
        newCoefficients[j] = newCoefficients[j].umod(secp256k1.curve.n);
      }
      coefficients = newCoefficients;
    }
  }
  return coefficients;
};
var pointSort = (innerPoints) => {
  const pointArrClone = [...innerPoints];
  pointArrClone.sort((a, b) => a.x.cmp(b.x));
  return pointArrClone;
};
var lagrange = (unsortedPoints) => {
  const sortedPoints = pointSort(unsortedPoints);
  const polynomial = generateEmptyBNArray(sortedPoints.length);
  for (let i = 0; i < sortedPoints.length; i += 1) {
    const coefficients = interpolationPoly(i, sortedPoints);
    for (let k = 0; k < sortedPoints.length; k += 1) {
      let tmp = new import_bn4.default(sortedPoints[i].y);
      tmp = tmp.mul(coefficients[k]);
      polynomial[k] = polynomial[k].add(tmp);
      polynomial[k] = polynomial[k].umod(secp256k1.curve.n);
    }
  }
  return new Polynomial$1(polynomial);
};
function lagrangeInterpolatePolynomial(points) {
  return lagrange(points);
}
function lagrangeInterpolation2(shares, nodeIndex) {
  if (shares.length !== nodeIndex.length) {
    throw CoreError$1.default("shares not equal to nodeIndex length in lagrangeInterpolation");
  }
  let secret = new import_bn4.default(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new import_bn4.default(1);
    let lower = new import_bn4.default(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(secp256k1.curve.n);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(secp256k1.curve.n);
        lower = lower.mul(temp).umod(secp256k1.curve.n);
      }
    }
    let delta = upper.mul(lower.invm(secp256k1.curve.n)).umod(secp256k1.curve.n);
    delta = delta.mul(shares[i]).umod(secp256k1.curve.n);
    secret = secret.add(delta);
  }
  return secret.umod(secp256k1.curve.n);
}
function generateRandomPolynomial(degree, secret, deterministicShares) {
  let actualS = secret;
  if (!secret) {
    actualS = generatePrivateExcludingIndexes([new import_bn4.default(0)]);
  }
  if (!deterministicShares) {
    const poly = [actualS];
    for (let i = 0; i < degree; i += 1) {
      const share = generatePrivateExcludingIndexes(poly);
      poly.push(share);
    }
    return new Polynomial$1(poly);
  }
  if (!Array.isArray(deterministicShares)) {
    throw CoreError$1.default("deterministic shares in generateRandomPolynomial should be an array");
  }
  if (deterministicShares.length > degree) {
    throw CoreError$1.default("deterministicShares in generateRandomPolynomial should be less or equal than degree to ensure an element of randomness");
  }
  const points = {};
  deterministicShares.forEach((share) => {
    points[share.shareIndex.toString("hex")] = new Point$1(share.shareIndex, share.share);
  });
  for (let i = 0; i < degree - deterministicShares.length; i += 1) {
    let shareIndex = generatePrivateExcludingIndexes([new import_bn4.default(0)]);
    while (points[shareIndex.toString("hex")] !== void 0) {
      shareIndex = generatePrivateExcludingIndexes([new import_bn4.default(0)]);
    }
    points[shareIndex.toString("hex")] = new Point$1(shareIndex, generatePrivateBN());
  }
  points["0"] = new Point$1(new import_bn4.default(0), actualS);
  return lagrangeInterpolatePolynomial(Object.values(points));
}
function polyCommitmentEval(polyCommitments, index) {
  const basePtPolyCommitments = [];
  for (let i = 0; i < polyCommitments.length; i += 1) {
    const key = secp256k1.keyFromPublic({
      x: polyCommitments[i].x.toString("hex"),
      y: polyCommitments[i].y.toString("hex")
    }, "");
    basePtPolyCommitments.push(key.getPublic());
  }
  let shareCommitment = basePtPolyCommitments[0];
  for (let i = 1; i < basePtPolyCommitments.length; i += 1) {
    const factor = index.pow(new import_bn4.default(i)).umod(secp256k1.n);
    const e = basePtPolyCommitments[i].mul(factor);
    shareCommitment = shareCommitment.add(e);
  }
  return new Point$1(shareCommitment.getX(), shareCommitment.getY());
}

// node_modules/@tkey/core/dist/lib.esm/metadata.js
var Metadata = class _Metadata {
  constructor(input) {
    _defineProperty(this, "pubKey", void 0);
    _defineProperty(this, "publicPolynomials", void 0);
    _defineProperty(this, "publicShares", void 0);
    _defineProperty(this, "polyIDList", void 0);
    _defineProperty(this, "generalStore", void 0);
    _defineProperty(this, "tkeyStore", void 0);
    _defineProperty(this, "scopedStore", void 0);
    _defineProperty(this, "nonce", void 0);
    _defineProperty(this, "tssKeyTypes", void 0);
    _defineProperty(this, "tssNonces", void 0);
    _defineProperty(this, "tssPolyCommits", void 0);
    _defineProperty(this, "factorPubs", void 0);
    _defineProperty(this, "factorEncs", void 0);
    this.publicPolynomials = {};
    this.publicShares = {};
    this.generalStore = {};
    this.tkeyStore = {};
    this.scopedStore = {};
    this.pubKey = input;
    this.polyIDList = [];
    this.nonce = 0;
    this.tssKeyTypes = {};
    this.tssPolyCommits = {};
    this.tssNonces = {};
    this.factorPubs = {};
    this.factorEncs = {};
  }
  static fromJSON(value) {
    const {
      pubKey,
      polyIDList,
      generalStore,
      tkeyStore,
      scopedStore,
      nonce,
      tssKeyTypes,
      tssPolyCommits,
      tssNonces,
      factorPubs,
      factorEncs
    } = value;
    const point = Point$1.fromSEC1(secp256k1, pubKey);
    const metadata = new _Metadata(point);
    const unserializedPolyIDList = [];
    if (generalStore) metadata.generalStore = generalStore;
    if (tkeyStore) metadata.tkeyStore = tkeyStore;
    if (scopedStore) metadata.scopedStore = scopedStore;
    if (nonce) metadata.nonce = nonce;
    if (tssKeyTypes) {
      metadata.tssKeyTypes = {};
      for (const key in tssKeyTypes) {
        metadata.tssKeyTypes[key] = tssKeyTypes[key];
      }
    }
    if (tssPolyCommits) {
      metadata.tssPolyCommits = {};
      for (const key in tssPolyCommits) {
        metadata.tssPolyCommits[key] = tssPolyCommits[key].map((obj) => new Point$1(obj.x, obj.y));
      }
    }
    if (tssNonces) {
      metadata.tssNonces = {};
      for (const key in tssNonces) {
        metadata.tssNonces[key] = tssNonces[key];
      }
    }
    if (factorPubs) {
      metadata.factorPubs = {};
      for (const key in factorPubs) {
        metadata.factorPubs[key] = factorPubs[key].map((obj) => new Point$1(obj.x, obj.y));
      }
    }
    if (factorEncs) metadata.factorEncs = factorEncs;
    for (let i = 0; i < polyIDList.length; i += 1) {
      const serializedPolyID = polyIDList[i];
      const arrPolyID = serializedPolyID.split("|");
      const zeroIndex = arrPolyID.findIndex((v) => v === "0x0");
      const firstHalf = arrPolyID.slice(0, zeroIndex);
      const secondHalf = arrPolyID.slice(zeroIndex + 1, arrPolyID.length);
      const pubPolyID = firstHalf.join("|");
      const pointCommitments = [];
      firstHalf.forEach((compressedCommitment) => {
        pointCommitments.push(Point$1.fromCompressedPub(compressedCommitment));
      });
      const publicPolynomial = new PublicPolynomial$1(pointCommitments);
      metadata.publicPolynomials[pubPolyID] = publicPolynomial;
      unserializedPolyIDList.push([pubPolyID, secondHalf]);
    }
    metadata.polyIDList = unserializedPolyIDList;
    return metadata;
  }
  getShareIndexesForPolynomial(polyID) {
    const matchingPolyIDs = this.polyIDList.filter((tuple) => tuple[0] === polyID);
    if (matchingPolyIDs.length < 1) {
      throw CoreError$1.default("there is no matching polyID");
    } else if (matchingPolyIDs.length > 1) {
      throw CoreError$1.default("there is more than one matching polyID");
    }
    return matchingPolyIDs[0][1];
  }
  getLatestPublicPolynomial() {
    return this.publicPolynomials[this.polyIDList[this.polyIDList.length - 1][0]];
  }
  addPublicShare(polynomialID, publicShare) {
    if (!(polynomialID in this.publicShares)) {
      this.publicShares[polynomialID] = {};
    }
    this.publicShares[polynomialID][publicShare.shareIndex.toString("hex")] = publicShare;
  }
  setGeneralStoreDomain(key, obj) {
    this.generalStore[key] = obj;
  }
  getGeneralStoreDomain(key) {
    return this.generalStore[key];
  }
  deleteGeneralStoreDomain(key) {
    delete this.generalStore[key];
  }
  setTkeyStoreDomain(key, arr) {
    this.tkeyStore[key] = arr;
  }
  getTkeyStoreDomain(key) {
    return this.tkeyStore[key];
  }
  // appends shares and public polynomial to metadata.
  // should represent a generation of share or edit of threshold
  addFromPolynomialAndShares(polynomial, shares) {
    const publicPolynomial = polynomial.getPublicPolynomial();
    const polyID = publicPolynomial.getPolynomialID();
    this.publicPolynomials[polyID] = publicPolynomial;
    const shareIndexArr = [];
    if (Array.isArray(shares)) {
      for (let i = 0; i < shares.length; i += 1) {
        this.addPublicShare(publicPolynomial.getPolynomialID(), shares[i].getPublicShare());
        shareIndexArr.push(shares[i].shareIndex.toString("hex"));
      }
    } else {
      for (const k in shares) {
        if (Object.prototype.hasOwnProperty.call(shares, k)) {
          this.addPublicShare(publicPolynomial.getPolynomialID(), shares[k].getPublicShare());
          shareIndexArr.push(shares[k].shareIndex.toString("hex"));
        }
      }
    }
    this.polyIDList.push([polyID, shareIndexArr]);
  }
  setScopedStore(domain, data) {
    this.scopedStore[domain] = data;
  }
  async getEncryptedShare(shareStore) {
    const pubShare = shareStore.share.getPublicShare();
    const encryptedShareStore = this.scopedStore.encryptedShares;
    if (!encryptedShareStore) {
      throw CoreError$1.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const encryptedShare = encryptedShareStore[pubShare.shareCommitment.x.toString("hex")];
    if (!encryptedShare) {
      throw CoreError$1.encryptedShareStoreUnavailable(`${shareStore}`);
    }
    const rawDecrypted = await decrypt(toPrivKeyECC(shareStore.share.share), encryptedShare);
    return ShareStore$1.fromJSON(JSON.parse(rawDecrypted.toString()));
  }
  getShareDescription() {
    return this.getGeneralStoreDomain("shareDescriptions");
  }
  addShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions") || {};
    if (currentSD[shareIndex]) {
      currentSD[shareIndex].push(description);
    } else {
      currentSD[shareIndex] = [description];
    }
    this.setGeneralStoreDomain("shareDescriptions", currentSD);
  }
  deleteShareDescription(shareIndex, description) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(description);
    if (index > -1) {
      currentSD[shareIndex].splice(index, 1);
    } else {
      throw CoreError$1.default(`No share description found for the given shareIndex: ${shareIndex} 
        and description: ${description}`);
    }
  }
  updateShareDescription(shareIndex, oldDescription, newDescription) {
    const currentSD = this.getGeneralStoreDomain("shareDescriptions");
    const index = currentSD[shareIndex].indexOf(oldDescription);
    if (index > -1) {
      currentSD[shareIndex][index] = newDescription;
    } else {
      throw CoreError$1.default(`No share description found for the given shareIndex:
        ${shareIndex} and description: ${oldDescription}`);
    }
  }
  shareToShareStore(share) {
    const pubkey = getPubKeyPoint(share);
    for (let i = this.polyIDList.length - 1; i >= 0; i -= 1) {
      const el = this.polyIDList[i][0];
      for (let t = 0; t < this.polyIDList[i][1].length; t += 1) {
        const shareIndex = this.polyIDList[i][1][t];
        let pubShare;
        if (this.publicShares[el]) {
          if (this.publicShares[el][shareIndex]) {
            pubShare = this.publicShares[el][shareIndex];
          }
        }
        if (!pubShare) {
          pubShare = new PublicShare$1(shareIndex, polyCommitmentEval(this.publicPolynomials[el].polynomialCommitments, new import_bn5.default(shareIndex, "hex")));
        }
        if (pubShare.shareCommitment.x.eq(pubkey.x) && pubShare.shareCommitment.y.eq(pubkey.y)) {
          const tempShare = new Share$1(pubShare.shareIndex, share);
          return new ShareStore$1(tempShare, el);
        }
      }
    }
    {
      throw CoreError$1.fromCode(1307);
    }
  }
  clone() {
    return _Metadata.fromJSON(JSON.parse((0, import_json_stable_stringify.default)(this)));
  }
  toJSON() {
    const serializedPolyIDList = [];
    for (let i = 0; i < this.polyIDList.length; i += 1) {
      const polyID = this.polyIDList[i][0];
      const shareIndexes = this.polyIDList[i][1];
      const sortedShareIndexes = shareIndexes.sort((a, b) => new import_bn5.default(a, "hex").cmp(new import_bn5.default(b, "hex")));
      const serializedPolyID = polyID.split(`|`).concat("0x0").concat(...sortedShareIndexes).join("|");
      serializedPolyIDList.push(serializedPolyID);
    }
    return _objectSpread2(_objectSpread2(_objectSpread2(_objectSpread2(_objectSpread2({
      pubKey: this.pubKey.toSEC1(secp256k1, true).toString("hex"),
      polyIDList: serializedPolyIDList,
      scopedStore: this.scopedStore,
      generalStore: this.generalStore,
      tkeyStore: this.tkeyStore,
      nonce: this.nonce
    }, this.tssKeyTypes && {
      tssKeyTypes: this.tssKeyTypes
    }), this.tssNonces && {
      tssNonces: this.tssNonces
    }), this.tssPolyCommits && {
      tssPolyCommits: this.tssPolyCommits
    }), this.factorPubs && {
      factorPubs: this.factorPubs
    }), this.factorEncs && {
      factorEncs: this.factorEncs
    });
  }
  /**
   * Updates the TSS metadata for the given tag.
   */
  updateTSSData(tssData) {
    const {
      tssKeyType,
      tssTag,
      tssNonce,
      tssPolyCommits,
      factorPubs,
      factorEncs
    } = tssData;
    if (tssKeyType) this.tssKeyTypes[tssTag] = tssKeyType;
    if (tssNonce !== void 0) this.tssNonces[tssTag] = tssNonce;
    if (tssPolyCommits) this.tssPolyCommits[tssTag] = tssPolyCommits;
    if (factorPubs) this.factorPubs[tssTag] = factorPubs;
    if (factorEncs) this.factorEncs[tssTag] = factorEncs;
  }
};
var Metadata$1 = Metadata;

// node_modules/@tkey/core/dist/lib.esm/authMetadata.js
var AuthMetadata = class _AuthMetadata {
  constructor(metadata, privKey) {
    _defineProperty(this, "metadata", void 0);
    _defineProperty(this, "privKey", void 0);
    this.metadata = metadata;
    this.privKey = privKey;
  }
  static fromJSON(value) {
    const {
      data,
      sig
    } = value;
    if (!data) throw CoreError$1.metadataUndefined();
    const m = Metadata$1.fromJSON(data);
    if (!m.pubKey) throw CoreError$1.metadataPubKeyUnavailable();
    const keyPair = secp256k1.keyFromPublic(m.pubKey.toSEC1(secp256k1));
    if (!keyPair.verify(stripHexPrefix(keccak2562(Buffer.from((0, import_json_stable_stringify2.default)(data), "utf8"))), sig)) {
      throw CoreError$1.default("Signature not valid for returning metadata");
    }
    return new _AuthMetadata(m);
  }
  toJSON() {
    const data = this.metadata;
    if (!this.privKey) throw CoreError$1.privKeyUnavailable();
    const k = toPrivKeyEC(this.privKey);
    const sig = k.sign(stripHexPrefix(keccak2562(Buffer.from((0, import_json_stable_stringify2.default)(data), "utf8"))));
    return {
      data,
      sig: sig.toDER("hex")
    };
  }
};
var AuthMetadata$1 = AuthMetadata;

// node_modules/@tkey/core/dist/lib.esm/core.js
var import_bn6 = __toESM(require_bn());
var import_json_stable_stringify3 = __toESM(require_json_stable_stringify());
var ed25519SeedConst = "ed25519Seed";
var ThresholdKey = class _ThresholdKey {
  constructor(args) {
    _defineProperty(this, "modules", void 0);
    _defineProperty(this, "enableLogging", void 0);
    _defineProperty(this, "serviceProvider", void 0);
    _defineProperty(this, "storageLayer", void 0);
    _defineProperty(this, "shares", void 0);
    _defineProperty(this, "lastFetchedCloudMetadata", void 0);
    _defineProperty(this, "metadata", void 0);
    _defineProperty(this, "manualSync", void 0);
    _defineProperty(this, "_localMetadataTransitions", void 0);
    _defineProperty(this, "_refreshMiddleware", void 0);
    _defineProperty(this, "_reconstructKeyMiddleware", void 0);
    _defineProperty(this, "_shareSerializationMiddleware", void 0);
    _defineProperty(this, "storeDeviceShare", void 0);
    _defineProperty(this, "haveWriteMetadataLock", void 0);
    _defineProperty(this, "serverTimeOffset", 0);
    _defineProperty(this, "privKey", void 0);
    _defineProperty(this, "_ed25519Seed", void 0);
    const {
      enableLogging = false,
      modules = {},
      serviceProvider,
      storageLayer,
      manualSync = false,
      serverTimeOffset
    } = args || {};
    this.enableLogging = enableLogging;
    this.serviceProvider = serviceProvider;
    this.storageLayer = storageLayer;
    this.modules = modules;
    this.shares = {};
    this.privKey = void 0;
    this.manualSync = manualSync;
    this._refreshMiddleware = {};
    this._reconstructKeyMiddleware = {};
    this._shareSerializationMiddleware = void 0;
    this.storeDeviceShare = void 0;
    this._localMetadataTransitions = [[], []];
    this.setModuleReferences();
    this.haveWriteMetadataLock = "";
    this.serverTimeOffset = serverTimeOffset;
  }
  get secp256k1Key() {
    if (typeof this.privKey !== "undefined") {
      return this.privKey;
    }
    return null;
  }
  get ed25519Key() {
    if (typeof this._ed25519Seed !== "undefined") {
      return this._ed25519Seed;
    }
    return null;
  }
  set secp256k1Key(privKey) {
    this.privKey = privKey;
  }
  set ed25519Key(seed) {
    this._ed25519Seed = seed;
  }
  static async fromJSON(value, args) {
    const {
      enableLogging,
      privKey,
      metadata,
      shares,
      _localMetadataTransitions,
      manualSync,
      lastFetchedCloudMetadata,
      serverTimeOffset
    } = value;
    const {
      storageLayer,
      serviceProvider,
      modules
    } = args;
    const tb = new _ThresholdKey({
      enableLogging,
      storageLayer,
      serviceProvider,
      modules,
      manualSync,
      serverTimeOffset
    });
    if (privKey) tb.privKey = new import_bn6.default(privKey, "hex");
    for (const key in shares) {
      if (Object.prototype.hasOwnProperty.call(shares, key)) {
        const shareStoreMapElement = shares[key];
        for (const shareElementKey in shareStoreMapElement) {
          if (Object.prototype.hasOwnProperty.call(shareStoreMapElement, shareElementKey)) {
            const shareStore = shareStoreMapElement[shareElementKey];
            shareStoreMapElement[shareElementKey] = ShareStore$1.fromJSON(shareStore);
          }
        }
      }
    }
    tb.shares = shares;
    const AuthMetadataKeys = Object.keys(JSON.parse((0, import_json_stable_stringify3.default)(new AuthMetadata$1(new Metadata$1(new Point$1("0", "0")), new import_bn6.default("0", "hex")))));
    const ShareStoreKeys = Object.keys(JSON.parse((0, import_json_stable_stringify3.default)(new ShareStore$1(new Share$1("0", "0"), ""))));
    const sampleMessageMetadata = {
      message: "Sample message",
      dateAdded: Date.now()
    };
    const MessageMetadataKeys = Object.keys(sampleMessageMetadata);
    const localTransitionShares = [];
    const localTransitionData = [];
    _localMetadataTransitions[0].forEach((x, index) => {
      if (x) {
        localTransitionShares.push(new import_bn6.default(x, "hex"));
      } else {
        localTransitionShares.push(void 0);
      }
      const keys = Object.keys(_localMetadataTransitions[1][index]);
      if (keys.length === AuthMetadataKeys.length && keys.every((val) => AuthMetadataKeys.includes(val))) {
        const tempAuth = AuthMetadata$1.fromJSON(_localMetadataTransitions[1][index]);
        tempAuth.privKey = privKey;
        localTransitionData.push(tempAuth);
      } else if (keys.length === ShareStoreKeys.length && keys.every((val) => ShareStoreKeys.includes(val))) {
        localTransitionData.push(ShareStore$1.fromJSON(_localMetadataTransitions[1][index]));
      } else if (keys.length === MessageMetadataKeys.length && keys.every((val) => MessageMetadataKeys.includes(val))) {
        localTransitionData.push(_localMetadataTransitions[1][index]);
      } else {
        throw CoreError$1.default("fromJSON failed. Could not deserialise _localMetadataTransitions");
      }
    });
    if (metadata || lastFetchedCloudMetadata) {
      let tempMetadata;
      let tempCloud;
      let shareToUseForSerialization;
      if (tb.serviceProvider.postboxKey.toString("hex") === "0") {
        const latestPolyIDOnCloud = Metadata$1.fromJSON(lastFetchedCloudMetadata).getLatestPublicPolynomial().getPolynomialID();
        const shareIndexesExistInSDK = Object.keys(shares[latestPolyIDOnCloud]);
        const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
        if (shareIndexesExistInSDK.length >= 1) {
          shareToUseForSerialization = shares[latestPolyIDOnCloud][randomIndex];
        }
      }
      if (metadata) tempMetadata = Metadata$1.fromJSON(metadata);
      if (lastFetchedCloudMetadata) tempCloud = Metadata$1.fromJSON(lastFetchedCloudMetadata);
      await tb.initialize({
        neverInitializeNewKey: true,
        transitionMetadata: tempMetadata,
        previouslyFetchedCloudMetadata: tempCloud,
        previousLocalMetadataTransitions: [localTransitionShares, localTransitionData],
        withShare: shareToUseForSerialization
      });
    } else {
      await tb.initialize({
        neverInitializeNewKey: true
      });
    }
    return tb;
  }
  getStorageLayer() {
    return this.storageLayer;
  }
  getMetadata() {
    if (typeof this.metadata !== "undefined") {
      return this.metadata;
    }
    throw CoreError$1.metadataUndefined();
  }
  async initialize(params) {
    const p = params || {};
    if (p.delete1OutOf1 && !this.manualSync) throw CoreError$1.delete1OutOf1OnlyManualSync();
    const {
      withShare,
      importKey,
      importEd25519Seed,
      neverInitializeNewKey,
      transitionMetadata,
      previouslyFetchedCloudMetadata,
      previousLocalMetadataTransitions
    } = p;
    const previousLocalMetadataTransitionsExists = previousLocalMetadataTransitions && previousLocalMetadataTransitions[0].length > 0 && previousLocalMetadataTransitions[1].length > 0;
    const reinitializing = transitionMetadata && previousLocalMetadataTransitionsExists;
    const reinitializingWithNewKeyAssign = reinitializing && previouslyFetchedCloudMetadata === void 0;
    let shareStore;
    if (withShare instanceof ShareStore$1) {
      shareStore = withShare;
    } else if (typeof withShare === "object") {
      shareStore = ShareStore$1.fromJSON(withShare);
    } else if (!withShare) {
      const spIncludeLocalMetadataTransitions = reinitializingWithNewKeyAssign;
      const spLocalMetadataTransitions = reinitializingWithNewKeyAssign ? previousLocalMetadataTransitions : void 0;
      const rawServiceProviderShare = await this.getGenericMetadataWithTransitionStates({
        serviceProvider: this.serviceProvider,
        includeLocalMetadataTransitions: spIncludeLocalMetadataTransitions,
        _localMetadataTransitions: spLocalMetadataTransitions,
        fromJSONConstructor: {
          fromJSON(val) {
            return val;
          }
        }
      });
      const noKeyFound = rawServiceProviderShare;
      if (noKeyFound.message === KEY_NOT_FOUND) {
        if (neverInitializeNewKey) {
          throw CoreError$1.default("key has not been generated yet");
        }
        if (this.serviceProvider.migratableKey && !(importKey || importEd25519Seed)) {
          const tempStateManualSync = this.manualSync;
          this.manualSync = true;
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: this.serviceProvider.migratableKey,
            delete1OutOf1: true
          });
          if (!tempStateManualSync) await this.syncLocalMetadataTransitions();
          this.manualSync = tempStateManualSync;
        } else {
          await this._initializeNewKey({
            initializeModules: true,
            importedKey: importKey,
            delete1OutOf1: p.delete1OutOf1,
            importEd25519Seed
          });
        }
        return this.getKeyDetails();
      }
      shareStore = ShareStore$1.fromJSON(rawServiceProviderShare);
    } else {
      throw CoreError$1.default("Input is not supported");
    }
    let currentMetadata;
    let latestCloudMetadata;
    let latestShareDetails;
    try {
      latestShareDetails = await this.catchupToLatestShare({
        shareStore
      });
    } catch (error) {
      const err = error;
      const noMetadataExistsForShare = err.code === 1503;
      if (!noMetadataExistsForShare || !reinitializing) {
        throw err;
      }
    }
    if (reinitializing && !reinitializingWithNewKeyAssign) {
      if (previouslyFetchedCloudMetadata.nonce < latestShareDetails.shareMetadata.nonce) {
        throw CoreError$1.fromCode(1104);
      } else if (previouslyFetchedCloudMetadata.nonce > latestShareDetails.shareMetadata.nonce) {
        throw CoreError$1.fromCode(1105);
      }
      latestCloudMetadata = previouslyFetchedCloudMetadata;
    } else {
      latestCloudMetadata = latestShareDetails ? latestShareDetails.shareMetadata.clone() : void 0;
    }
    if (reinitializing) {
      currentMetadata = transitionMetadata;
      this._localMetadataTransitions = previousLocalMetadataTransitions;
    } else {
      currentMetadata = latestShareDetails.shareMetadata;
    }
    this.lastFetchedCloudMetadata = latestCloudMetadata;
    this.metadata = currentMetadata;
    const latestShare = latestShareDetails ? latestShareDetails.latestShare : shareStore;
    this.inputShareStore(latestShare);
    if (importEd25519Seed && this.getEd25519PublicKey()) {
      throw CoreError$1.default("Ed25119 key already exists");
    }
    await this.initializeModules();
    return this.getKeyDetails();
  }
  /**
   * catchupToLatestShare recursively loops fetches metadata of the provided share and checks if there is an encrypted share for it.
   * @param shareStore - share to start of with
   * @param polyID - if specified, polyID to refresh to if it exists
   */
  async catchupToLatestShare(params) {
    const {
      shareStore,
      polyID,
      includeLocalMetadataTransitions
    } = params;
    let shareMetadata;
    try {
      shareMetadata = await this.getAuthMetadata({
        privKey: shareStore.share.share,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      const prettyError = await prettyPrintError(err);
      throw CoreError$1.authMetadataGetUnavailable(`, ${prettyError.message}`);
    }
    try {
      if (polyID) {
        if (shareStore.polynomialID === polyID) {
          return {
            latestShare: shareStore,
            shareMetadata
          };
        }
      }
      const nextShare = await shareMetadata.getEncryptedShare(shareStore);
      return await this.catchupToLatestShare({
        shareStore: nextShare,
        polyID,
        includeLocalMetadataTransitions
      });
    } catch (error) {
      const err = error;
      if (err && err.code === 1308) {
        throw err;
      }
      return {
        latestShare: shareStore,
        shareMetadata
      };
    }
  }
  async reconstructKey(_reconstructKeyMiddleware = true) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const requiredThreshold = pubPoly.getThreshold();
    const pubPolyID = pubPoly.getPolynomialID();
    let sharesLeft = requiredThreshold;
    const fullShareList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const shareIndexesRequired = {};
    for (let i = 0; i < fullShareList.length; i += 1) {
      shareIndexesRequired[fullShareList[i]] = true;
    }
    const sharesToInput = [];
    for (let z = this.metadata.polyIDList.length - 1; z >= 0 && sharesLeft > 0; z -= 1) {
      const sharesForPoly = this.shares[this.metadata.polyIDList[z][0]];
      if (sharesForPoly) {
        const shareIndexesForPoly = Object.keys(sharesForPoly);
        for (let k = 0; k < shareIndexesForPoly.length && sharesLeft > 0; k += 1) {
          if (shareIndexesForPoly[k] in shareIndexesRequired) {
            const currentShareForPoly = sharesForPoly[shareIndexesForPoly[k]];
            if (currentShareForPoly.polynomialID === pubPolyID) {
              sharesToInput.push(currentShareForPoly);
            } else {
              const latestShareRes = await this.catchupToLatestShare({
                shareStore: currentShareForPoly,
                polyID: pubPolyID,
                includeLocalMetadataTransitions: true
              });
              if (latestShareRes.latestShare.polynomialID === pubPolyID) {
                sharesToInput.push(latestShareRes.latestShare);
              } else {
                throw new CoreError$1(1304, "Share found in unexpected polynomial");
              }
            }
            delete shareIndexesRequired[shareIndexesForPoly[k]];
            sharesLeft -= 1;
          }
        }
      }
    }
    sharesToInput.forEach((share) => {
      this.inputShareStore(share);
    });
    if (sharesLeft > 0) {
      throw CoreError$1.unableToReconstruct(` require ${requiredThreshold} but have ${requiredThreshold - sharesLeft}`);
    }
    const polyShares = Object.keys(this.shares[pubPolyID]);
    const shareArr = [];
    const shareIndexArr = [];
    for (let i = 0; i < requiredThreshold; i += 1) {
      shareArr.push(this.shares[pubPolyID][polyShares[i]].share.share);
      shareIndexArr.push(this.shares[pubPolyID][polyShares[i]].share.shareIndex);
    }
    const privKey = lagrangeInterpolation2(shareArr, shareIndexArr);
    const reconstructedPubKey = getPubKeyPoint(privKey);
    if (this.metadata.pubKey.x.cmp(reconstructedPubKey.x) !== 0) {
      throw CoreError$1.incorrectReconstruction();
    }
    this.secp256k1Key = privKey;
    const returnObject = {
      allKeys: [privKey]
    };
    if (_reconstructKeyMiddleware && Object.keys(this._reconstructKeyMiddleware).length > 0) {
      await Promise.all(Object.keys(this._reconstructKeyMiddleware).map(async (x) => {
        if (Object.prototype.hasOwnProperty.call(this._reconstructKeyMiddleware, x)) {
          const extraKeys = await this._reconstructKeyMiddleware[x]();
          returnObject[x] = extraKeys;
          returnObject.allKeys.push(...extraKeys);
        }
      }));
    }
    if (this.getEd25519PublicKey()) {
      const seed = await this.retrieveEd25519Seed();
      if (!seed) {
        throw CoreError$1.default("Ed25519 seed not found");
      }
      this._ed25519Seed = seed;
    }
    return _objectSpread2({
      secp256k1Key: privKey,
      ed25519Seed: this._ed25519Seed
    }, returnObject);
  }
  reconstructLatestPoly() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares to reconstruct poly");
    }
    if (new Set(sharesForExistingPoly).size !== sharesForExistingPoly.length) {
      throw CoreError$1.default("share indexes should be unique");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point$1(new import_bn6.default(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    return lagrangeInterpolatePolynomial(pointsArr);
  }
  async deleteShare(shareIndex) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const shareIndexToDelete = new import_bn6.default(shareIndex, "hex");
    const shareToDelete = this.outputShareStore(shareIndexToDelete);
    if (shareIndexToDelete.cmp(new import_bn6.default("1", "hex")) === 0) {
      throw new CoreError$1(1001, "Unable to delete service provider share");
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const newShareIndexes = [];
    existingShareIndexes.forEach((el) => {
      const bn = new import_bn6.default(el, "hex");
      if (bn.cmp(shareIndexToDelete) !== 0) {
        newShareIndexes.push(bn.toString("hex"));
      }
    });
    if (existingShareIndexes.length === newShareIndexes.length) {
      throw CoreError$1.default("Share index does not exist in latest polynomial");
    } else if (newShareIndexes.length < pubPoly.getThreshold()) {
      throw CoreError$1.default(`Minimum ${pubPoly.getThreshold()} shares are required for tkey. Unable to delete share`);
    }
    const results = await this._refreshShares(pubPoly.getThreshold(), [...newShareIndexes], previousPolyID);
    const newShareStores = results.shareStores;
    await this.addLocalMetadataTransitions({
      input: [{
        message: SHARE_DELETED,
        dateAdded: Date.now()
      }],
      privKey: [shareToDelete.share.share]
    });
    return {
      newShareStores
    };
  }
  async generateNewShare() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.secp256k1Key) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const existingShareIndexesBN = existingShareIndexes.map((el) => new import_bn6.default(el, "hex"));
    const newShareIndex = new import_bn6.default(generatePrivateExcludingIndexes(existingShareIndexesBN));
    const results = await this._refreshShares(pubPoly.getThreshold(), [...existingShareIndexes, newShareIndex.toString("hex")], previousPolyID);
    const newShareStores = results.shareStores;
    return {
      newShareStores,
      newShareIndex
    };
  }
  getEd25519PublicKey() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    return result === null || result === void 0 ? void 0 : result.publicKey;
  }
  async retrieveEd25519Seed() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const result = this.metadata.getGeneralStoreDomain(ed25519SeedConst);
    const seed = await this.decrypt(result.message);
    this._ed25519Seed = seed;
    return seed;
  }
  async addLocalMetadataTransitions(params) {
    const {
      privKey,
      input
    } = params;
    this._localMetadataTransitions[0] = [...this._localMetadataTransitions[0], ...privKey];
    this._localMetadataTransitions[1] = [...this._localMetadataTransitions[1], ...input];
    if (!this.manualSync) await this.syncLocalMetadataTransitions();
  }
  async syncLocalMetadataTransitions() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!(Array.isArray(this._localMetadataTransitions[0]) && this._localMetadataTransitions[0].length > 0)) return;
    let acquiredLock = false;
    if (this.lastFetchedCloudMetadata) {
      await this.acquireWriteMetadataLock();
      acquiredLock = true;
    }
    try {
      await this.storageLayer.setMetadataStream({
        input: this._localMetadataTransitions[1],
        privKey: this._localMetadataTransitions[0],
        serviceProvider: this.serviceProvider
      });
      this._localMetadataTransitions = [[], []];
      this.lastFetchedCloudMetadata = this.metadata.clone();
    } catch (error) {
      const prettyError = await prettyPrintError(error);
      throw CoreError$1.metadataPostFailed(prettyError.message);
    } finally {
      if (acquiredLock) await this.releaseWriteMetadataLock();
    }
  }
  async readMetadata(privKey) {
    return this.storageLayer.getMetadata({
      privKey
    });
  }
  // Returns a new instance of metadata with a clean state. All the previous state will be reset.
  async updateSDK(params) {
    const tb = new _ThresholdKey({
      enableLogging: this.enableLogging,
      modules: this.modules,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer,
      manualSync: this.manualSync
    });
    try {
      await tb.initialize({
        neverInitializeNewKey: true,
        withShare: params && params.withShare
      });
    } catch (err) {
      throw CoreError$1.fromCode(1103, `${err.message}`);
    }
    const allPolyIDList = tb.metadata.polyIDList;
    let lastValidPolyID;
    Object.keys(this.shares).forEach((x) => {
      if (allPolyIDList.find((id) => id[0] === x)) {
        lastValidPolyID = x;
      } else {
        delete this.shares[x];
      }
    });
    const shareStoresForLastValidPolyID = Object.keys(this.shares[lastValidPolyID]).map((x) => tb.inputShareStoreSafe(this.outputShareStore(x, lastValidPolyID)));
    await Promise.all(shareStoresForLastValidPolyID);
    return tb;
  }
  // NOTE: This API will be DEPRECATED in the future in favour of inputShareStoreSafe()
  inputShareStore(shareStore) {
    let ss;
    if (shareStore instanceof ShareStore$1) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = ShareStore$1.fromJSON(shareStore);
    } else {
      throw CoreError$1.default("can only add type ShareStore into shares");
    }
    if (!(ss.polynomialID in this.shares)) {
      this.shares[ss.polynomialID] = {};
    }
    this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
  }
  // inputs a share ensuring that the share is the latest share AND metadata is updated to its latest state
  async inputShareStoreSafe(shareStore, autoUpdateMetadata = false) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let ss;
    if (shareStore instanceof ShareStore$1) {
      ss = shareStore;
    } else if (typeof shareStore === "object") {
      ss = ShareStore$1.fromJSON(shareStore);
    } else {
      throw CoreError$1.default("can only add type ShareStore into shares");
    }
    const polynomialId = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    if (ss.polynomialID !== polynomialId) {
      const latestShareRes = await this.catchupToLatestShare({
        shareStore: ss,
        includeLocalMetadataTransitions: true
      });
      if (!latestShareRes.shareMetadata.polyIDList.find((tuple) => tuple[0] === polynomialId)) {
        throw CoreError$1.fromCode(1307);
      }
      if (polynomialId !== latestShareRes.latestShare.polynomialID) {
        if (!autoUpdateMetadata) throw CoreError$1.default(`TKey SDK metadata seems to be outdated because shareIndex: ${latestShareRes.latestShare.share.shareIndex.toString("hex")} has a more recent metadata. Please call updateSDK first`);
        else this.metadata = latestShareRes.shareMetadata;
      }
      if (!(latestShareRes.latestShare.polynomialID in this.shares)) {
        this.shares[latestShareRes.latestShare.polynomialID] = {};
      }
      this.shares[latestShareRes.latestShare.polynomialID][latestShareRes.latestShare.share.shareIndex.toString("hex")] = latestShareRes.latestShare;
    } else {
      if (!(ss.polynomialID in this.shares)) {
        this.shares[ss.polynomialID] = {};
      }
      this.shares[ss.polynomialID][ss.share.shareIndex.toString("hex")] = ss;
    }
  }
  outputShareStore(shareIndex, polyID) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let shareIndexParsed;
    if (typeof shareIndex === "number") {
      shareIndexParsed = new import_bn6.default(shareIndex);
    } else if (import_bn6.default.isBN(shareIndex)) {
      shareIndexParsed = shareIndex;
    } else if (typeof shareIndex === "string") {
      shareIndexParsed = new import_bn6.default(shareIndex, "hex");
    }
    let polyIDToSearch;
    if (polyID) {
      polyIDToSearch = polyID;
    } else {
      polyIDToSearch = this.metadata.getLatestPublicPolynomial().getPolynomialID();
    }
    if (!this.metadata.getShareIndexesForPolynomial(polyIDToSearch).includes(shareIndexParsed.toString("hex"))) {
      throw new CoreError$1(1002, "no such share index created");
    }
    const shareFromStore = this.shares[polyIDToSearch][shareIndexParsed.toString("hex")];
    if (shareFromStore) return shareFromStore;
    const poly = this.reconstructLatestPoly();
    const shareMap = poly.generateShares([shareIndexParsed]);
    return new ShareStore$1(shareMap[shareIndexParsed.toString("hex")], polyIDToSearch);
  }
  getCurrentShareIndexes() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const latestPolynomial = this.metadata.getLatestPublicPolynomial();
    const latestPolynomialId = latestPolynomial.getPolynomialID();
    const currentShareIndexes = Object.keys(this.shares[latestPolynomialId]);
    return currentShareIndexes;
  }
  getKeyDetails() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const poly = this.metadata.getLatestPublicPolynomial();
    const previousPolyID = poly.getPolynomialID();
    const requiredShares = poly.getThreshold() - Object.keys(this.shares[previousPolyID]).length;
    let shareDescriptions = this.metadata.getShareDescription();
    if (shareDescriptions) {
      const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
      shareDescriptions = Object.keys(shareDescriptions).reduce((acc, index) => {
        if (existingShareIndexes.indexOf(index) >= 0) acc[index] = shareDescriptions[index];
        return acc;
      }, {});
    }
    return {
      pubKey: this.metadata.pubKey,
      ed25519PublicKey: this.getEd25519PublicKey(),
      requiredShares,
      threshold: poly.getThreshold(),
      totalShares: this.metadata.getShareIndexesForPolynomial(previousPolyID).length,
      shareDescriptions
    };
  }
  // Auth functions
  generateAuthMetadata(params) {
    const {
      input
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new AuthMetadata$1(input[i], this.privKey));
    }
    return authMetadatas;
  }
  setAuthMetadata(params) {
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadata = new AuthMetadata$1(input, this.privKey);
    return this.storageLayer.setMetadata({
      input: authMetadata,
      serviceProvider,
      privKey
    });
  }
  async setAuthMetadataBulk(params) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    const {
      input,
      serviceProvider,
      privKey
    } = params;
    const authMetadatas = [];
    for (let i = 0; i < input.length; i += 1) {
      authMetadatas.push(new AuthMetadata$1(input[i], this.privKey));
    }
    await this.addLocalMetadataTransitions({
      input: authMetadatas,
      serviceProvider,
      privKey
    });
  }
  async getAuthMetadata(params) {
    const raw = await this.getGenericMetadataWithTransitionStates(_objectSpread2(_objectSpread2({}, params), {}, {
      fromJSONConstructor: AuthMetadata$1
    }));
    const authMetadata = raw;
    return authMetadata.metadata;
  }
  // fetches the latest metadata potentially searching in local transition states first
  async getGenericMetadataWithTransitionStates(params) {
    if (!(params.serviceProvider && params.serviceProvider.postboxKey.toString("hex") !== "0" || params.privKey)) {
      throw CoreError$1.default("require either serviceProvider or priv key in getGenericMetadataWithTransitionStates");
    }
    if (params.includeLocalMetadataTransitions) {
      const transitions = params._localMetadataTransitions ? params._localMetadataTransitions : this._localMetadataTransitions;
      let index = null;
      for (let i = transitions[0].length - 1; i >= 0; i -= 1) {
        const x = transitions[0][i];
        if (params.privKey && x && x.cmp(params.privKey) === 0) index = i;
        else if (params.serviceProvider && !x) index = i;
        if (index !== null) break;
      }
      if (index !== null) {
        return transitions[1][index];
      }
    }
    let raw;
    try {
      raw = await this.storageLayer.getMetadata(params);
    } catch (err) {
      const prettyError = await prettyPrintError(err);
      throw CoreError$1.metadataGetFailed(prettyError.message);
    }
    if (raw.message === SHARE_DELETED) {
      throw CoreError$1.fromCode(1308);
    }
    return params.fromJSONConstructor.fromJSON(raw);
  }
  // Lock functions
  async acquireWriteMetadataLock() {
    if (this.haveWriteMetadataLock) return this.metadata.nonce;
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    let randomShareStore;
    const latestPolyIDOnCloud = this.lastFetchedCloudMetadata.getLatestPublicPolynomial().getPolynomialID();
    const shareIndexesExistInSDK = Object.keys(this.shares[latestPolyIDOnCloud]);
    const randomIndex = shareIndexesExistInSDK[Math.floor(Math.random() * (shareIndexesExistInSDK.length - 1))];
    if (shareIndexesExistInSDK.length >= 1) {
      randomShareStore = this.shares[latestPolyIDOnCloud][randomIndex];
    } else {
      randomShareStore = this.outputShareStore(randomIndex, latestPolyIDOnCloud);
    }
    const latestRes = await this.catchupToLatestShare({
      shareStore: randomShareStore
    });
    const latestMetadata = latestRes.shareMetadata;
    if (latestMetadata.nonce > this.lastFetchedCloudMetadata.nonce) {
      throw CoreError$1.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
           being lower than last written metadata nonce (${latestMetadata.nonce}). perhaps update metadata SDK (create new tKey and init)`);
    } else if (latestMetadata.nonce < this.lastFetchedCloudMetadata.nonce) {
      throw CoreError$1.acquireLockFailed(`unable to acquire write access for metadata due to 
      lastFetchedCloudMetadata (${this.lastFetchedCloudMetadata.nonce})
      being higher than last written metadata nonce (${latestMetadata.nonce}). this should never happen as it 
      should only ever be updated by getting metadata)`);
    }
    const res = await this.storageLayer.acquireWriteLock({
      privKey: this.privKey
    });
    if (res.status !== 1) throw CoreError$1.acquireLockFailed(`lock cannot be acquired from storage layer status code: ${res.status}`);
    this.haveWriteMetadataLock = res.id;
    return this.metadata.nonce;
  }
  async releaseWriteMetadataLock() {
    if (!this.haveWriteMetadataLock) throw CoreError$1.releaseLockFailed("releaseWriteMetadataLock - don't have metadata lock to release");
    const res = await this.storageLayer.releaseWriteLock({
      privKey: this.privKey,
      id: this.haveWriteMetadataLock
    });
    if (res.status !== 1) throw CoreError$1.releaseLockFailed(`lock cannot be released from storage layer status code: ${res.status}`);
    this.haveWriteMetadataLock = "";
  }
  // Module functions
  async _syncShareMetadata(adjustScopedStore) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const shareArray = this.getAllShareStoresForLatestPolynomial().map((x) => x.share.share);
    await this.syncMultipleShareMetadata(shareArray, adjustScopedStore);
  }
  async syncMultipleShareMetadata(shares, adjustScopedStore) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.nonce += 1;
    const newMetadataPromise = shares.map(async (share) => {
      const newMetadata2 = this.metadata.clone();
      let specificShareMetadata;
      try {
        specificShareMetadata = await this.getAuthMetadata({
          privKey: share,
          includeLocalMetadataTransitions: true
        });
      } catch (err) {
        const prettyError = await prettyPrintError(err);
        throw CoreError$1.authMetadataGetUnavailable(prettyError.message);
      }
      let scopedStoreToBeSet;
      if (adjustScopedStore) {
        scopedStoreToBeSet = adjustScopedStore(specificShareMetadata.scopedStore);
      } else {
        scopedStoreToBeSet = specificShareMetadata.scopedStore;
      }
      newMetadata2.scopedStore = scopedStoreToBeSet;
      return newMetadata2;
    });
    const newMetadata = await Promise.all(newMetadataPromise);
    return this.setAuthMetadataBulk({
      input: newMetadata,
      privKey: shares
    });
  }
  _addRefreshMiddleware(moduleName, middleware) {
    this._refreshMiddleware[moduleName] = middleware;
  }
  _addReconstructKeyMiddleware(moduleName, middleware) {
    this._reconstructKeyMiddleware[moduleName] = middleware;
  }
  _addShareSerializationMiddleware(serialize, deserialize) {
    this._shareSerializationMiddleware = {
      serialize,
      deserialize
    };
  }
  _setDeviceStorage(storeDeviceStorage) {
    if (this.storeDeviceShare) {
      throw CoreError$1.default("storeDeviceShare already set");
    }
    this.storeDeviceShare = storeDeviceStorage;
  }
  async addShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.addShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async deleteShareDescription(shareIndex, description, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.deleteShareDescription(shareIndex, description);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async updateShareDescription(shareIndex, oldDescription, newDescription, updateMetadata) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    this.metadata.updateShareDescription(shareIndex, oldDescription, newDescription);
    if (updateMetadata) {
      await this._syncShareMetadata();
    }
  }
  async encrypt(data) {
    if (!this.privKey) throw CoreError$1.privateKeyUnavailable();
    return encrypt(getPubKeyECC(this.privKey), data);
  }
  async decrypt(encryptedMessage) {
    if (!this.privKey) throw CoreError$1.privateKeyUnavailable();
    return decrypt(toPrivKeyECC(this.privKey), encryptedMessage);
  }
  async _setTKeyStoreItem(moduleName, data) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async (x) => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const encryptedData = await this.encrypt(Buffer.from((0, import_json_stable_stringify3.default)(data)));
    const duplicateItemIndex = decryptedItems.findIndex((x) => x.id === data.id);
    if (duplicateItemIndex > -1) {
      rawTkeyStoreItems[duplicateItemIndex] = encryptedData;
    } else {
      rawTkeyStoreItems.push(encryptedData);
    }
    this.metadata.setTkeyStoreDomain(moduleName, rawTkeyStoreItems);
    await this._syncShareMetadata();
  }
  async _deleteTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async (x) => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const finalItems = decryptedItems.filter((x) => x.id !== id);
    this.metadata.setTkeyStoreDomain(moduleName, finalItems);
    await this._syncShareMetadata();
  }
  async getTKeyStore(moduleName) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async (x) => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    return decryptedItems;
  }
  async getTKeyStoreItem(moduleName, id) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const rawTkeyStoreItems = this.metadata.getTkeyStoreDomain(moduleName) || [];
    const decryptedItems = await Promise.all(rawTkeyStoreItems.map(async (x) => {
      const decryptedItem = await this.decrypt(x);
      return JSON.parse(decryptedItem.toString());
    }));
    const item = decryptedItems.find((x) => x.id === id);
    return item;
  }
  // Import export shares
  async outputShare(shareIndex, type) {
    const {
      share
    } = this.outputShareStore(shareIndex).share;
    if (!type) return share;
    return this._shareSerializationMiddleware.serialize(share, type);
  }
  async inputShare(share, type) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    let shareStore;
    if (!type) shareStore = this.metadata.shareToShareStore(share);
    else {
      const deserialized = await this._shareSerializationMiddleware.deserialize(share, type);
      shareStore = this.metadata.shareToShareStore(deserialized);
    }
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const fullShareIndexesList = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    if (!fullShareIndexesList.includes(shareStore.share.shareIndex.toString("hex"))) {
      throw CoreError$1.default("Latest poly doesn't include this share");
    }
    await this.inputShareStoreSafe(shareStore);
  }
  toJSON() {
    return {
      shares: this.shares,
      enableLogging: this.enableLogging,
      privKey: this.privKey ? this.privKey.toString("hex") : void 0,
      metadata: this.metadata,
      lastFetchedCloudMetadata: this.lastFetchedCloudMetadata,
      _localMetadataTransitions: this._localMetadataTransitions,
      manualSync: this.manualSync,
      serviceProvider: this.serviceProvider,
      storageLayer: this.storageLayer
    };
  }
  getAllShareStoresForLatestPolynomial() {
    const pubPoly = this.metadata.getLatestPublicPolynomial();
    const pubPolyID = pubPoly.getPolynomialID();
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(pubPolyID);
    const threshold = pubPoly.getThreshold();
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[pubPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point$1(new import_bn6.default(sharesForExistingPoly[i], "hex"), this.shares[pubPolyID][sharesForExistingPoly[i]].share.share));
    }
    const currentPoly = lagrangeInterpolatePolynomial(pointsArr);
    const allExistingShares = currentPoly.generateShares(existingShareIndexes);
    const shareArray = existingShareIndexes.map((shareIndex) => {
      return this.metadata.shareToShareStore(allExistingShares[shareIndex].share);
    });
    return shareArray;
  }
  /// Destructive method. All data will be wiped!
  async CRITICAL_deleteTkey() {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (this._localMetadataTransitions[0].length > 0 || this._localMetadataTransitions[1].length > 0) {
      throw CoreError$1.default("Please sync all local state before calling this function");
    }
    const shareArray = this.getAllShareStoresForLatestPolynomial();
    await this.addLocalMetadataTransitions({
      input: [...Array(shareArray.length).fill({
        message: SHARE_DELETED,
        dateAdded: Date.now()
      }), {
        message: KEY_NOT_FOUND
      }],
      privKey: [...shareArray.map((x) => x.share.share), void 0]
    });
    await this.syncLocalMetadataTransitions();
    this.privKey = void 0;
    this.metadata = void 0;
    this.shares = {};
    this.lastFetchedCloudMetadata = void 0;
  }
  getApi() {
    return {
      getMetadata: this.getMetadata.bind(this),
      getStorageLayer: this.getStorageLayer.bind(this),
      initialize: this.initialize.bind(this),
      catchupToLatestShare: this.catchupToLatestShare.bind(this),
      _syncShareMetadata: this._syncShareMetadata.bind(this),
      _addRefreshMiddleware: this._addRefreshMiddleware.bind(this),
      _addReconstructKeyMiddleware: this._addReconstructKeyMiddleware.bind(this),
      _addShareSerializationMiddleware: this._addShareSerializationMiddleware.bind(this),
      addShareDescription: this.addShareDescription.bind(this),
      generateNewShare: this.generateNewShare.bind(this),
      inputShareStore: this.inputShareStore.bind(this),
      inputShareStoreSafe: this.inputShareStoreSafe.bind(this),
      outputShareStore: this.outputShareStore.bind(this),
      inputShare: this.inputShare.bind(this),
      outputShare: this.outputShare.bind(this),
      _setDeviceStorage: this._setDeviceStorage.bind(this),
      encrypt: this.encrypt.bind(this),
      decrypt: this.decrypt.bind(this),
      getTKeyStore: this.getTKeyStore.bind(this),
      getTKeyStoreItem: this.getTKeyStoreItem.bind(this),
      _setTKeyStoreItem: this._setTKeyStoreItem.bind(this),
      _deleteTKeyStoreItem: this._deleteTKeyStoreItem.bind(this),
      deleteShare: this.deleteShare.bind(this)
    };
  }
  setModuleReferences() {
    Object.keys(this.modules).map((x) => this.modules[x].setModuleReferences(this.getApi()));
  }
  async initializeModules() {
    return Promise.all(Object.keys(this.modules).map((x) => this.modules[x].initialize()));
  }
  async _refreshShares(threshold, newShareIndexes, previousPolyID) {
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (threshold > newShareIndexes.length) {
      throw CoreError$1.default(`threshold should not be greater than share indexes. ${threshold} > ${newShareIndexes.length}`);
    }
    this.metadata.nonce += 1;
    const poly = generateRandomPolynomial(threshold - 1, this.privKey);
    const shares = poly.generateShares(newShareIndexes);
    const existingShareIndexes = this.metadata.getShareIndexesForPolynomial(previousPolyID);
    const pointsArr = [];
    const sharesForExistingPoly = Object.keys(this.shares[previousPolyID]);
    if (sharesForExistingPoly.length < threshold) {
      throw CoreError$1.unableToReconstruct("not enough shares for polynomial reconstruction");
    }
    for (let i = 0; i < threshold; i += 1) {
      pointsArr.push(new Point$1(new import_bn6.default(sharesForExistingPoly[i], "hex"), this.shares[previousPolyID][sharesForExistingPoly[i]].share.share));
    }
    const oldPoly = lagrangeInterpolatePolynomial(pointsArr);
    const shareIndexesNeedingEncryption = [];
    for (let index = 0; index < existingShareIndexes.length; index += 1) {
      const shareIndexHex = existingShareIndexes[index];
      if (newShareIndexes.includes(shareIndexHex)) {
        shareIndexesNeedingEncryption.push(shareIndexHex);
      }
    }
    this.metadata.addFromPolynomialAndShares(poly, shares);
    const oldShareStores = {};
    const newShareStores = {};
    const polyID = poly.getPolynomialID();
    newShareIndexes.forEach((shareIndexHex) => {
      newShareStores[shareIndexHex] = new ShareStore$1(shares[shareIndexHex], polyID);
    });
    const m = this.metadata.clone();
    const newScopedStore = {};
    const sharesToPush = await Promise.all(shareIndexesNeedingEncryption.map(async (shareIndex) => {
      const oldShare = oldPoly.polyEval(new import_bn6.default(shareIndex, "hex"));
      const encryptedShare = await encrypt(getPubKeyECC(oldShare), Buffer.from(JSON.stringify(newShareStores[shareIndex])));
      newScopedStore[getPubKeyPoint(oldShare).x.toString("hex")] = encryptedShare;
      oldShareStores[shareIndex] = new ShareStore$1(new Share$1(shareIndex, oldShare), previousPolyID);
      return oldShare;
    }));
    m.setScopedStore("encryptedShares", newScopedStore);
    const metadataToPush = Array(sharesToPush.length).fill(m);
    for (const moduleName in this._refreshMiddleware) {
      if (Object.prototype.hasOwnProperty.call(this._refreshMiddleware, moduleName)) {
        const adjustedGeneralStore = this._refreshMiddleware[moduleName](this.metadata.getGeneralStoreDomain(moduleName), oldShareStores, newShareStores);
        if (!adjustedGeneralStore) this.metadata.deleteGeneralStoreDomain(moduleName);
        else this.metadata.setGeneralStoreDomain(moduleName, adjustedGeneralStore);
      }
    }
    const newShareMetadataToPush = [];
    const newShareStoreSharesToPush = newShareIndexes.map((shareIndex) => {
      const me = this.metadata.clone();
      newShareMetadataToPush.push(me);
      return newShareStores[shareIndex].share.share;
    });
    const AuthMetadatas = this.generateAuthMetadata({
      input: [...metadataToPush, ...newShareMetadataToPush]
    });
    await this.addLocalMetadataTransitions({
      input: [...AuthMetadatas, newShareStores["1"]],
      privKey: [...sharesToPush, ...newShareStoreSharesToPush, void 0]
    });
    for (let index = 0; index < newShareIndexes.length; index += 1) {
      const shareIndex = newShareIndexes[index];
      this.inputShareStore(newShareStores[shareIndex]);
    }
    return {
      shareStores: newShareStores
    };
  }
  async _initializeNewKey({
    determinedShare,
    initializeModules,
    importedKey,
    importEd25519Seed,
    delete1OutOf1
  } = {}) {
    if (!importedKey) {
      const tmpPriv = generatePrivateBN();
      this.secp256k1Key = tmpPriv;
    } else {
      this.secp256k1Key = importedKey;
    }
    const shareIndexForDeviceStorage = generatePrivateExcludingIndexes([new import_bn6.default(1), new import_bn6.default(0)]);
    const shareIndexes = [new import_bn6.default(1), shareIndexForDeviceStorage];
    let poly;
    if (determinedShare) {
      const shareIndexForDeterminedShare = generatePrivateExcludingIndexes([new import_bn6.default(1), new import_bn6.default(0)]);
      poly = generateRandomPolynomial(1, this.privKey, [new Share$1(shareIndexForDeterminedShare, determinedShare)]);
      shareIndexes.push(shareIndexForDeterminedShare);
    } else {
      poly = generateRandomPolynomial(1, this.privKey);
    }
    const shares = poly.generateShares(shareIndexes);
    const metadata = new Metadata$1(getPubKeyPoint(this.privKey));
    metadata.addFromPolynomialAndShares(poly, shares);
    const serviceProviderShare = shares[shareIndexes[0].toString("hex")];
    const shareStore = new ShareStore$1(serviceProviderShare, poly.getPolynomialID());
    this.metadata = metadata;
    await this.setupEd25519Seed(importEd25519Seed);
    if (initializeModules) {
      await this.initializeModules();
    }
    const metadataToPush = [];
    const sharesToPush = shareIndexes.map((shareIndex) => {
      metadataToPush.push(this.metadata);
      return shares[shareIndex.toString("hex")].share;
    });
    const authMetadatas = this.generateAuthMetadata({
      input: metadataToPush
    });
    await this.addLocalMetadataTransitions({
      input: [...authMetadatas, shareStore],
      privKey: [...sharesToPush, void 0]
    });
    if (delete1OutOf1) {
      await this.addLocalMetadataTransitions({
        input: [{
          message: ONE_KEY_DELETE_NONCE
        }],
        privKey: [this.serviceProvider.postboxKey]
      });
    }
    for (let index = 0; index < shareIndexes.length; index += 1) {
      const shareIndex = shareIndexes[index];
      this.inputShareStore(new ShareStore$1(shares[shareIndex.toString("hex")], poly.getPolynomialID()));
    }
    if (this.storeDeviceShare) {
      await this.storeDeviceShare(new ShareStore$1(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()));
    }
    const result = {
      secp256k1Key: this.privKey,
      deviceShare: new ShareStore$1(shares[shareIndexes[1].toString("hex")], poly.getPolynomialID()),
      userShare: void 0
    };
    if (determinedShare) {
      result.userShare = new ShareStore$1(shares[shareIndexes[2].toString("hex")], poly.getPolynomialID());
    }
    return result;
  }
  async importEd25519Seed(seed) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    if (this.getEd25519PublicKey()) {
      throw CoreError$1.default("Ed25519 key already exists");
    }
    const keyPair = getEd25519ExtendedPublicKey(seed);
    this.metadata.setGeneralStoreDomain(ed25519SeedConst, {
      message: await this.encrypt(seed),
      publicKey: keyPair.point.encode("hex", false)
    });
    this._ed25519Seed = seed;
  }
  async setupEd25519Seed(seed) {
    if (!this.privKey) {
      throw CoreError$1.privateKeyUnavailable();
    }
    let seedToUse = seed;
    if (!seed) {
      const newEd25519Seed = await getRandomBytes(32);
      seedToUse = Buffer.from(newEd25519Seed);
    }
    await this.importEd25519Seed(seedToUse);
  }
};
var ThresholdKey$1 = ThresholdKey;

// node_modules/@toruslabs/rss-client/dist/lib.esm/rss.js
var import_bn8 = __toESM(require_bn());
var import_elliptic3 = __toESM(require_elliptic());
var import_loglevel = __toESM(require_loglevel());

// node_modules/@toruslabs/rss-client/node_modules/@toruslabs/eccrypto/dist/lib.esm/index.js
var import_elliptic = __toESM(require_elliptic());
var ec = new import_elliptic.ec("secp256k1");
var browserCrypto = globalThis.crypto || globalThis.msCrypto || {};
var subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;
var EC_GROUP_ORDER = Buffer.from("fffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141", "hex");
var ZERO32 = Buffer.alloc(32, 0);
function assert(condition, message) {
  if (!condition) {
    throw new Error(message || "Assertion failed");
  }
}
function isScalar(x) {
  return Buffer.isBuffer(x) && x.length === 32;
}
function isValidPrivateKey(privateKey) {
  if (!isScalar(privateKey)) {
    return false;
  }
  return privateKey.compare(ZERO32) > 0 && // > 0
  privateKey.compare(EC_GROUP_ORDER) < 0;
}
function equalConstTime(b1, b2) {
  if (b1.length !== b2.length) {
    return false;
  }
  let res = 0;
  for (let i = 0; i < b1.length; i++) {
    res |= b1[i] ^ b2[i];
  }
  return res === 0;
}
function randomBytes(size) {
  if (typeof browserCrypto.getRandomValues === "undefined") {
    return Buffer.from(browserCrypto.randomBytes(size));
  }
  const arr = new Uint8Array(size);
  browserCrypto.getRandomValues(arr);
  return Buffer.from(arr);
}
async function sha512(msg) {
  if (!browserCrypto.createHash) {
    const hash2 = await subtle.digest("SHA-512", msg);
    const result2 = new Uint8Array(hash2);
    return result2;
  }
  const hash = browserCrypto.createHash("sha512");
  const result = hash.update(msg).digest();
  return new Uint8Array(result);
}
function getAes(op) {
  return async function(iv, key, data) {
    if (subtle && subtle[op] && subtle.importKey) {
      const importAlgorithm = {
        name: "AES-CBC"
      };
      const cryptoKey = await subtle.importKey("raw", key, importAlgorithm, false, [op]);
      const encAlgorithm = {
        name: "AES-CBC",
        iv
      };
      const result = await subtle[op](encAlgorithm, cryptoKey, data);
      return Buffer.from(new Uint8Array(result));
    } else if (op === "encrypt" && browserCrypto.createCipheriv) {
      const cipher = browserCrypto.createCipheriv("aes-256-cbc", key, iv);
      const firstChunk = cipher.update(data);
      const secondChunk = cipher.final();
      return Buffer.concat([firstChunk, secondChunk]);
    } else if (op === "decrypt" && browserCrypto.createDecipheriv) {
      const decipher = browserCrypto.createDecipheriv("aes-256-cbc", key, iv);
      const firstChunk = decipher.update(data);
      const secondChunk = decipher.final();
      return Buffer.concat([firstChunk, secondChunk]);
    }
    throw new Error(`Unsupported operation: ${op}`);
  };
}
var aesCbcEncrypt = getAes("encrypt");
var aesCbcDecrypt = getAes("decrypt");
async function hmacSha256Sign(key, msg) {
  if (!browserCrypto.createHmac) {
    const importAlgorithm = {
      name: "HMAC",
      hash: {
        name: "SHA-256"
      }
    };
    const cryptoKey = await subtle.importKey("raw", new Uint8Array(key), importAlgorithm, false, ["sign", "verify"]);
    const sig = await subtle.sign("HMAC", cryptoKey, msg);
    const result2 = Buffer.from(new Uint8Array(sig));
    return result2;
  }
  const hmac = browserCrypto.createHmac("sha256", Buffer.from(key));
  hmac.update(msg);
  const result = hmac.digest();
  return result;
}
async function hmacSha256Verify(key, msg, sig) {
  const expectedSig = await hmacSha256Sign(key, msg);
  return equalConstTime(expectedSig, sig);
}
var getPublic = function(privateKey) {
  assert(privateKey.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKey), "Bad private key");
  return Buffer.from(ec.keyFromPrivate(privateKey).getPublic("array"));
};
var derive = async function(privateKeyA, publicKeyB) {
  assert(Buffer.isBuffer(privateKeyA), "Bad private key");
  assert(Buffer.isBuffer(publicKeyB), "Bad public key");
  assert(privateKeyA.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKeyA), "Bad private key");
  assert(publicKeyB.length === 65 || publicKeyB.length === 33, "Bad public key");
  if (publicKeyB.length === 65) {
    assert(publicKeyB[0] === 4, "Bad public key");
  }
  if (publicKeyB.length === 33) {
    assert(publicKeyB[0] === 2 || publicKeyB[0] === 3, "Bad public key");
  }
  const keyA = ec.keyFromPrivate(privateKeyA);
  const keyB = ec.keyFromPublic(publicKeyB);
  const Px = keyA.derive(keyB.getPublic());
  return Buffer.from(Px.toArray());
};
var deriveUnpadded = derive;
var derivePadded = async function(privateKeyA, publicKeyB) {
  assert(Buffer.isBuffer(privateKeyA), "Bad private key");
  assert(Buffer.isBuffer(publicKeyB), "Bad public key");
  assert(privateKeyA.length === 32, "Bad private key");
  assert(isValidPrivateKey(privateKeyA), "Bad private key");
  assert(publicKeyB.length === 65 || publicKeyB.length === 33, "Bad public key");
  if (publicKeyB.length === 65) {
    assert(publicKeyB[0] === 4, "Bad public key");
  }
  if (publicKeyB.length === 33) {
    assert(publicKeyB[0] === 2 || publicKeyB[0] === 3, "Bad public key");
  }
  const keyA = ec.keyFromPrivate(privateKeyA);
  const keyB = ec.keyFromPublic(publicKeyB);
  const Px = keyA.derive(keyB.getPublic());
  return Buffer.from(Px.toString(16, 64), "hex");
};
var encrypt2 = async function(publicKeyTo, msg, opts) {
  opts = opts || {};
  let ephemPrivateKey = opts.ephemPrivateKey || randomBytes(32);
  while (!isValidPrivateKey(ephemPrivateKey)) {
    ephemPrivateKey = opts.ephemPrivateKey || randomBytes(32);
  }
  const ephemPublicKey = getPublic(ephemPrivateKey);
  const Px = await deriveUnpadded(ephemPrivateKey, publicKeyTo);
  const hash = await sha512(Px);
  const iv = opts.iv || randomBytes(16);
  const encryptionKey = hash.slice(0, 32);
  const macKey = hash.slice(32);
  const data = await aesCbcEncrypt(iv, Buffer.from(encryptionKey), msg);
  const ciphertext = data;
  const dataToMac = Buffer.concat([iv, ephemPublicKey, ciphertext]);
  const mac = await hmacSha256Sign(Buffer.from(macKey), dataToMac);
  return {
    iv,
    ephemPublicKey,
    ciphertext,
    mac
  };
};
var decrypt2 = async function(privateKey, opts, _padding) {
  const padding = _padding !== null && _padding !== void 0 ? _padding : false;
  const deriveLocal = padding ? derivePadded : deriveUnpadded;
  const Px = await deriveLocal(privateKey, opts.ephemPublicKey);
  const hash = await sha512(Px);
  const encryptionKey = hash.slice(0, 32);
  const macKey = hash.slice(32);
  const dataToMac = Buffer.concat([opts.iv, opts.ephemPublicKey, opts.ciphertext]);
  const macGood = await hmacSha256Verify(Buffer.from(macKey), dataToMac, opts.mac);
  if (!macGood && padding === false) {
    return decrypt2(privateKey, opts, true);
  } else if (!macGood && padding === true) {
    throw new Error("bad MAC after trying padded");
  }
  const msg = await aesCbcDecrypt(opts.iv, Buffer.from(encryptionKey), opts.ciphertext);
  return Buffer.from(new Uint8Array(msg));
};

// node_modules/@toruslabs/rss-client/dist/lib.esm/utils.js
var import_bn7 = __toESM(require_bn());
var import_elliptic2 = __toESM(require_elliptic());
var ecCurveSecp256k1 = new import_elliptic2.ec("secp256k1");
function randomSelection(arr, num) {
  if (num > arr.length) throw new Error("trying to select more elements than available");
  const selected = [];
  const slice = arr.slice();
  while (selected.length < num) {
    selected.push(slice.splice(Math.floor(Math.random() * slice.length), 1)[0]);
  }
  return selected;
}
function ecPoint(ecCurve, p) {
  if (p.x === null && p.y === null) {
    return ecCurve.curve.g.add(ecCurve.curve.g.neg());
  }
  return ecCurve.keyFromPublic({
    x: p.x.padStart(64, "0"),
    y: p.y.padStart(64, "0")
  }).getPublic();
}
function hexPoint(p) {
  if (p.isInfinity()) {
    return {
      x: null,
      y: null
    };
  }
  return {
    x: p.getX().toString(16, 64),
    y: p.getY().toString(16, 64)
  };
}
async function encrypt3(publicKey, msg) {
  const encryptedDetails = await encrypt2(publicKey, msg);
  return {
    ciphertext: encryptedDetails.ciphertext.toString("hex"),
    ephemPublicKey: encryptedDetails.ephemPublicKey.toString("hex"),
    iv: encryptedDetails.iv.toString("hex"),
    mac: encryptedDetails.mac.toString("hex")
  };
}
async function decrypt3(privKey, msg) {
  const bufferEncDetails = {
    ciphertext: Buffer.from(msg.ciphertext, "hex"),
    ephemPublicKey: Buffer.from(msg.ephemPublicKey, "hex"),
    iv: Buffer.from(msg.iv, "hex"),
    mac: Buffer.from(msg.mac, "hex")
  };
  return decrypt2(privKey, bufferEncDetails);
}
function generatePolynomial(degree, yIntercept, randomElement) {
  const res = [];
  let i = 0;
  if (yIntercept !== void 0) {
    res.push(yIntercept);
    i++;
  }
  for (; i <= degree; i++) {
    res.push(randomElement());
  }
  return res;
}
function getShare(polynomial, index, modulus) {
  let res = new import_bn7.default(0);
  for (let i = 0; i < polynomial.length; i++) {
    const term = polynomial[i].mul(new import_bn7.default(index).pow(new import_bn7.default(i)));
    res = res.add(term.umod(modulus));
  }
  return res.umod(modulus);
}
function dotProduct(arr1, arr2, modulus) {
  if (arr1.length !== arr2.length) {
    throw new Error("arrays of different lengths");
  }
  let sum = new import_bn7.default(0);
  for (let i = 0; i < arr1.length; i++) {
    sum = sum.add(arr1[i].mul(arr2[i]));
    if (modulus) {
      sum = sum.umod(modulus);
    }
  }
  return sum;
}
function getLagrangeCoeff(_allIndexes, _myIndex, _target, modulus) {
  const allIndexes = _allIndexes.map((i) => new import_bn7.default(i));
  const myIndex = new import_bn7.default(_myIndex);
  const target = new import_bn7.default(_target);
  let upper = new import_bn7.default(1);
  let lower = new import_bn7.default(1);
  for (let j = 0; j < allIndexes.length; j += 1) {
    if (myIndex.cmp(allIndexes[j]) !== 0) {
      let tempUpper = target.sub(allIndexes[j]);
      tempUpper = tempUpper.umod(modulus);
      upper = upper.mul(tempUpper);
      upper = upper.umod(modulus);
      let tempLower = myIndex.sub(allIndexes[j]);
      tempLower = tempLower.umod(modulus);
      lower = lower.mul(tempLower).umod(modulus);
    }
  }
  return upper.mul(lower.invm(modulus)).umod(modulus);
}

// node_modules/@toruslabs/rss-client/dist/lib.esm/rss.js
function postEndpoint(endpoint, path, data, options_, customOptions) {
  if (typeof endpoint === "string") {
    return post(`${endpoint}${path}`, data, options_, customOptions);
  }
  return endpoint.post(path, data);
}
var RSSClient = class {
  constructor(opts) {
    _defineProperty(this, "tssPubKey", void 0);
    _defineProperty(this, "tempPrivKey", void 0);
    _defineProperty(this, "tempPubKey", void 0);
    _defineProperty(this, "serverEndpoints", void 0);
    _defineProperty(this, "serverThreshold", void 0);
    _defineProperty(this, "serverPubKeys", void 0);
    _defineProperty(this, "ecCurve", void 0);
    _defineProperty(this, "keyType", void 0);
    if (opts.keyType !== "secp256k1" && opts.keyType !== "ed25519") throw new Error("Invalid keyType, only secp256k1 or ed25519 is supported");
    this.keyType = opts.keyType;
    this.ecCurve = new import_elliptic3.ec(this.keyType);
    this.tssPubKey = ecPoint(this.ecCurve, opts.tssPubKey);
    this.serverEndpoints = opts.serverEndpoints;
    this.serverThreshold = opts.serverThreshold;
    this.serverPubKeys = opts.serverPubKeys;
    if (opts.tempKey) {
      this.tempPrivKey = opts.tempKey;
      this.tempPubKey = ecCurveSecp256k1.g.mul(opts.tempKey);
    } else {
      const kp = ecCurveSecp256k1.genKeyPair();
      this.tempPrivKey = kp.getPrivate();
      this.tempPubKey = kp.getPublic();
    }
  }
  async import(opts) {
    const {
      importKey,
      newLabel,
      sigs,
      dkgNewPub,
      targetIndexes,
      selectedServers,
      factorPubs
    } = opts;
    if (factorPubs.length !== targetIndexes.length) throw new Error("inconsistent factorPubs and targetIndexes lengths");
    const serversInfo = {
      pubkeys: this.serverPubKeys,
      selected: selectedServers,
      threshold: this.serverThreshold
    };
    const rssRound1Proms = selectedServers.map((ind) => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "new",
        server_index: ind,
        new_servers_info: serversInfo,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: newLabel,
          // TODO: undesigned
          sigs
        },
        key_type: this.keyType
      });
    });
    const _finalLagrangeCoeffs = targetIndexes.map((target) => getLagrangeCoeff([0, 1], 0, target, this.ecCurve.n).umod(this.ecCurve.n));
    const _masterPolys = [];
    const _masterPolyCommits = [];
    const _serverPolys = [];
    const _serverPolyCommits = [];
    const generateRandomScalar = () => this.ecCurve.genKeyPair().getPrivate();
    for (let i = 0; i < _finalLagrangeCoeffs.length; i++) {
      const _lc = _finalLagrangeCoeffs[i];
      const _m = generatePolynomial(1, _lc.mul(importKey).umod(this.ecCurve.n), generateRandomScalar);
      _masterPolys.push(_m);
      _masterPolyCommits.push(_m.map((coeff) => {
        const _gCoeff = this.ecCurve.g.mul(coeff);
        return hexPoint(_gCoeff);
      }));
      const _s = generatePolynomial(serversInfo.threshold - 1, getShare(_m, 1, this.ecCurve.n), generateRandomScalar);
      _serverPolys.push(_s);
      _serverPolyCommits.push(_s.map((coeff) => hexPoint(this.ecCurve.g.mul(coeff))));
    }
    const _serverEncs = [];
    const _userEncs = [];
    for (let i = 0; i < _masterPolys.length; i++) {
      _serverEncs.push([]);
    }
    for (let i = 0; i < targetIndexes.length; i++) {
      const _masterPoly = _masterPolys[i];
      _userEncs.push(await encrypt3(Buffer.from(`04${hexPoint(this.tempPubKey).x.padStart(64, "0")}${hexPoint(this.tempPubKey).y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_masterPoly, 99, this.ecCurve.n).toString(16, 64), "hex")));
      const _serverPoly = _serverPolys[i];
      const _serverEnc = _serverEncs[i];
      for (let j = 0; j < serversInfo.pubkeys.length; j++) {
        const _pub = serversInfo.pubkeys[j];
        _serverEnc.push(await encrypt3(Buffer.from(`04${_pub.x.padStart(64, "0")}${_pub.y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_serverPoly, j + 1, this.ecCurve.n).toString(16, 64), "hex")));
      }
    }
    const _data = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      _data.push({
        master_poly_commits: _masterPolyCommits[i],
        server_poly_commits: _serverPolyCommits[i],
        target_encryptions: {
          user_enc: _userEncs[i],
          server_encs: _serverEncs[i]
        }
      });
    }
    rssRound1Proms.push(new Promise((resolve) => {
      resolve({
        target_index: targetIndexes,
        data: _data
      });
    }));
    const rssRound1Responses = await Promise.all(rssRound1Proms);
    const sums = targetIndexes.map((_, i) => {
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (masterPolyCommits.length !== 2) throw new Error("incorrect number of coeffs for master poly commits");
        if (serverPolyCommits.length !== this.serverThreshold) throw new Error("incorrect number of coeffs for server poly commits");
      }
      let sumMasterPolyCommits = [];
      let sumServerPolyCommits = [];
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (sumMasterPolyCommits.length === 0 && sumServerPolyCommits.length === 0) {
          sumMasterPolyCommits = masterPolyCommits.map((p) => ecPoint(this.ecCurve, p));
          sumServerPolyCommits = serverPolyCommits.map((p) => ecPoint(this.ecCurve, p));
          continue;
        }
        sumMasterPolyCommits = sumMasterPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, masterPolyCommits[k]).add(summedCommit);
        });
        sumServerPolyCommits = sumServerPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, serverPolyCommits[k]).add(summedCommit);
        });
      }
      return {
        mc: sumMasterPolyCommits,
        sc: sumServerPolyCommits
      };
    });
    targetIndexes.map((target, i) => {
      const {
        mc,
        sc
      } = sums[i];
      const temp1 = ecPoint(this.ecCurve, dkgNewPub).mul(getLagrangeCoeff([1, target], 1, 0, this.ecCurve.n));
      const temp2 = mc[0].mul(getLagrangeCoeff([1, target], target, 0, this.ecCurve.n));
      const _tssPubKey = temp1.add(temp2);
      if (!_tssPubKey.eq(this.tssPubKey)) throw new Error("master poly commits inconsistent with tssPubKey");
      if (!mc[0].add(mc[1]).eq(sc[0])) throw new Error("server poly commits inconsistent with master poly commits");
      return null;
    });
    const privKeyBuffer = Buffer.from(this.tempPrivKey.toString(16, 64), "hex");
    const userShares = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      const userEncs = rssRound1Responses.map((r) => r.data[i].target_encryptions.user_enc);
      const userDecs = await Promise.all(userEncs.map((encMsg) => decrypt3(privKeyBuffer, encMsg)));
      const userShare = userDecs.map((userDec) => new import_bn8.default(userDec)).reduce((acc, d) => acc.add(d).umod(this.ecCurve.n), new import_bn8.default(0));
      const {
        mc
      } = sums[i];
      const gU = this.ecCurve.g.mul(userShare);
      const _gU = mc[0].add(mc[1].mul(new import_bn8.default(99)));
      if (!gU.eq(_gU)) throw new Error("decrypted user shares inconsistent with poly commits");
      userShares.push(userShare);
    }
    const userFactorEncs = await Promise.all(userShares.map((userShare, i) => {
      const pub = factorPubs[i];
      return encrypt3(Buffer.from(`04${pub.x.padStart(64, "0")}${pub.y.padStart(64, "0")}`, "hex"), Buffer.from(userShare.toString(16, 64), "hex"));
    }));
    const serverEncs = targetIndexes.map((_, i) => {
      const serverEncsReceived = rssRound1Responses.map((r) => r.data[i].target_encryptions.server_encs);
      const serverEncsToSend = [];
      for (let j = 0; j < this.serverEndpoints.length; j++) {
        const serverEnc = [];
        for (let k = 0; k < this.serverThreshold + 1; k++) {
          serverEnc.push(serverEncsReceived[k][j]);
        }
        serverEncsToSend.push(serverEnc);
      }
      return serverEncsToSend;
    });
    const serverIndexes = this.serverEndpoints.map((_, i) => i + 1);
    const serverFactorEncs = await Promise.all(serverIndexes.map((ind) => {
      const data = [];
      targetIndexes.map((_, i) => {
        const {
          mc,
          sc
        } = sums[i];
        const round2RequestData = {
          master_commits: mc.map(hexPoint),
          server_commits: sc.map(hexPoint),
          server_encs: serverEncs[i][ind - 1],
          factor_pubkeys: [factorPubs[i]]
          // TODO: must we do it like this?
        };
        data.push(round2RequestData);
        return null;
      });
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_2", {
        round_name: "rss_round_2",
        server_index: ind,
        target_index: targetIndexes,
        data,
        key_type: this.keyType
      }).catch((e) => import_loglevel.default.error(e));
    }));
    if (serverFactorEncs.filter((s) => s).length < this.serverThreshold) throw new Error("not enough servers responded");
    const factorEncs = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      factorEncs.push({
        targetIndex: targetIndexes[i],
        factorPub: factorPubs[i],
        serverFactorEncs: serverFactorEncs.map((s) => s && s.data[i].encs[0]),
        userFactorEnc: userFactorEncs[i]
      });
    }
    return factorEncs;
  }
  async refresh(opts) {
    const {
      targetIndexes,
      inputIndex,
      selectedServers,
      oldLabel,
      newLabel,
      sigs,
      dkgNewPub,
      inputShare,
      factorPubs
    } = opts;
    if (factorPubs.length !== targetIndexes.length) throw new Error("inconsistent factorPubs and targetIndexes lengths");
    const serversInfo = {
      pubkeys: this.serverPubKeys,
      selected: selectedServers,
      threshold: this.serverThreshold
    };
    const rssRound1Proms = selectedServers.map((ind) => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "old",
        server_index: ind,
        old_servers_info: serversInfo,
        new_servers_info: serversInfo,
        old_user_share_index: inputIndex,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: oldLabel,
          sigs
        },
        key_type: this.keyType
      });
    }).concat(selectedServers.map((ind) => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "new",
        server_index: ind,
        old_servers_info: serversInfo,
        new_servers_info: serversInfo,
        old_user_share_index: inputIndex,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: newLabel,
          // TODO: undesigned
          sigs
        },
        key_type: this.keyType
      });
    }));
    const _L = getLagrangeCoeff([1, inputIndex], inputIndex, 0, this.ecCurve.n);
    const _finalLagrangeCoeffs = targetIndexes.map((target) => _L.mul(getLagrangeCoeff([0, 1], 0, target, this.ecCurve.n)).umod(this.ecCurve.n));
    const _masterPolys = [];
    const _masterPolyCommits = [];
    const _serverPolys = [];
    const _serverPolyCommits = [];
    const generateRandomScalar = () => this.ecCurve.genKeyPair().getPrivate();
    for (let i = 0; i < _finalLagrangeCoeffs.length; i++) {
      const _lc = _finalLagrangeCoeffs[i];
      const _m = generatePolynomial(1, _lc.mul(inputShare).umod(this.ecCurve.n), generateRandomScalar);
      _masterPolys.push(_m);
      _masterPolyCommits.push(_m.map((coeff) => {
        const _gCoeff = this.ecCurve.g.mul(coeff);
        return hexPoint(_gCoeff);
      }));
      const _s = generatePolynomial(serversInfo.threshold - 1, getShare(_m, 1, this.ecCurve.n), generateRandomScalar);
      _serverPolys.push(_s);
      _serverPolyCommits.push(_s.map((coeff) => hexPoint(this.ecCurve.g.mul(coeff))));
    }
    const _serverEncs = [];
    const _userEncs = [];
    for (let i = 0; i < _masterPolys.length; i++) {
      _serverEncs.push([]);
    }
    for (let i = 0; i < targetIndexes.length; i++) {
      const _masterPoly = _masterPolys[i];
      _userEncs.push(await encrypt3(Buffer.from(`04${hexPoint(this.tempPubKey).x.padStart(64, "0")}${hexPoint(this.tempPubKey).y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_masterPoly, 99, this.ecCurve.n).toString(16, 64), "hex")));
      const _serverPoly = _serverPolys[i];
      const _serverEnc = _serverEncs[i];
      for (let j = 0; j < serversInfo.pubkeys.length; j++) {
        const _pub = serversInfo.pubkeys[j];
        _serverEnc.push(await encrypt3(Buffer.from(`04${_pub.x.padStart(64, "0")}${_pub.y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_serverPoly, j + 1, this.ecCurve.n).toString(16, 64), "hex")));
      }
    }
    const _data = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      _data.push({
        master_poly_commits: _masterPolyCommits[i],
        server_poly_commits: _serverPolyCommits[i],
        target_encryptions: {
          user_enc: _userEncs[i],
          server_encs: _serverEncs[i]
        }
      });
    }
    rssRound1Proms.push(new Promise((resolve) => {
      resolve({
        target_index: targetIndexes,
        data: _data
      });
    }));
    const rssRound1Responses = await Promise.all(rssRound1Proms);
    const sums = targetIndexes.map((_, i) => {
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (masterPolyCommits.length !== 2) throw new Error("incorrect number of coeffs for master poly commits");
        if (serverPolyCommits.length !== this.serverThreshold) throw new Error("incorrect number of coeffs for server poly commits");
      }
      let sumMasterPolyCommits = [];
      let sumServerPolyCommits = [];
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (sumMasterPolyCommits.length === 0 && sumServerPolyCommits.length === 0) {
          sumMasterPolyCommits = masterPolyCommits.map((p) => ecPoint(this.ecCurve, p));
          sumServerPolyCommits = serverPolyCommits.map((p) => ecPoint(this.ecCurve, p));
          continue;
        }
        sumMasterPolyCommits = sumMasterPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, masterPolyCommits[k]).add(summedCommit);
        });
        sumServerPolyCommits = sumServerPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, serverPolyCommits[k]).add(summedCommit);
        });
      }
      return {
        mc: sumMasterPolyCommits,
        sc: sumServerPolyCommits
      };
    });
    targetIndexes.map((target, i) => {
      const {
        mc,
        sc
      } = sums[i];
      const temp1 = ecPoint(this.ecCurve, dkgNewPub).mul(getLagrangeCoeff([1, target], 1, 0, this.ecCurve.n));
      const temp2 = mc[0].mul(getLagrangeCoeff([1, target], target, 0, this.ecCurve.n));
      const _tssPubKey = temp1.add(temp2);
      if (!_tssPubKey.eq(this.tssPubKey)) throw new Error("master poly commits inconsistent with tssPubKey");
      if (!mc[0].add(mc[1]).eq(sc[0])) throw new Error("server poly commits inconsistent with master poly commits");
      return null;
    });
    const privKeyBuffer = Buffer.from(this.tempPrivKey.toString(16, 64), "hex");
    const userShares = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      const userEncs = rssRound1Responses.map((r) => r.data[i].target_encryptions.user_enc);
      const userDecs = await Promise.all(userEncs.map((encMsg) => decrypt3(privKeyBuffer, encMsg)));
      const userShare = userDecs.map((userDec) => new import_bn8.default(userDec)).reduce((acc, d) => acc.add(d).umod(this.ecCurve.n), new import_bn8.default(0));
      const {
        mc
      } = sums[i];
      const gU = this.ecCurve.g.mul(userShare);
      const _gU = mc[0].add(mc[1].mul(new import_bn8.default(99)));
      if (!gU.eq(_gU)) throw new Error("decrypted user shares inconsistent with poly commits");
      userShares.push(userShare);
    }
    const userFactorEncs = await Promise.all(userShares.map((userShare, i) => {
      const pub = factorPubs[i];
      return encrypt3(Buffer.from(`04${pub.x.padStart(64, "0")}${pub.y.padStart(64, "0")}`, "hex"), Buffer.from(userShare.toString(16, 64), "hex"));
    }));
    const serverEncs = targetIndexes.map((_, i) => {
      const serverEncsReceived = rssRound1Responses.map((r) => r.data[i].target_encryptions.server_encs);
      const serverEncsToSend = [];
      for (let j = 0; j < this.serverEndpoints.length; j++) {
        const serverEnc = [];
        for (let k = 0; k < this.serverThreshold * 2 + 1; k++) {
          serverEnc.push(serverEncsReceived[k][j]);
        }
        serverEncsToSend.push(serverEnc);
      }
      return serverEncsToSend;
    });
    const serverIndexes = this.serverEndpoints.map((_, i) => i + 1);
    const serverFactorEncs = await Promise.all(serverIndexes.map((ind) => {
      const data = [];
      targetIndexes.map((_, i) => {
        const {
          mc,
          sc
        } = sums[i];
        const round2RequestData = {
          master_commits: mc.map(hexPoint),
          server_commits: sc.map(hexPoint),
          server_encs: serverEncs[i][ind - 1],
          factor_pubkeys: [factorPubs[i]]
          // TODO: must we do it like this?
        };
        data.push(round2RequestData);
        return null;
      });
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_2", {
        round_name: "rss_round_2",
        server_index: ind,
        target_index: targetIndexes,
        data,
        key_type: this.keyType
      }).catch((e) => import_loglevel.default.error(e));
    }));
    if (serverFactorEncs.filter((s) => s).length < this.serverThreshold) throw new Error("not enough servers responded");
    const factorEncs = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      factorEncs.push({
        targetIndex: targetIndexes[i],
        factorPub: factorPubs[i],
        serverFactorEncs: serverFactorEncs.map((s) => s && s.data[i].encs[0]),
        userFactorEnc: userFactorEncs[i]
      });
    }
    return factorEncs;
  }
};

// node_modules/@tkey/tss/dist/lib.esm/tss.js
var import_bn9 = __toESM(require_bn());
var import_elliptic4 = __toESM(require_elliptic());
var TSS_MODULE = "tssModule";
var TSS_TAG_DEFAULT = "default";
var FACTOR_KEY_TYPE = "secp256k1";
var factorKeyCurve = new import_elliptic4.ec(FACTOR_KEY_TYPE);
var LEGACY_KEY_TYPE = "secp256k1";
var TKeyTSS = class extends ThresholdKey$1 {
  /**
   * Constructs a new TKeyTSS instance using the given parameters.
   */
  constructor(args) {
    super(args);
    _defineProperty(this, "serviceProvider", null);
    _defineProperty(this, "_tssKeyType", void 0);
    _defineProperty(this, "_tssCurve", void 0);
    _defineProperty(this, "_tssTag", void 0);
    _defineProperty(this, "_accountSalt", void 0);
    const {
      serviceProvider,
      storageLayer,
      tssTag = "default",
      tssKeyType
    } = args;
    if (serviceProvider.customAuthArgs.keyType !== tssKeyType) {
      throw CoreError$1.default(`service provider keyType mismatch: ${serviceProvider.customAuthArgs.keyType} !== ${tssKeyType}`);
    }
    this.serviceProvider = serviceProvider;
    this.storageLayer = storageLayer;
    this._tssTag = tssTag;
    this._tssKeyType = tssKeyType;
    this._tssCurve = new import_elliptic4.ec(tssKeyType);
  }
  get tssTag() {
    return this._tssTag;
  }
  get tssKeyType() {
    return this._tssKeyType;
  }
  get tssCurve() {
    return this._tssCurve;
  }
  set tssTag(tag) {
    if ((this.metadata.tssKeyTypes[this.tssTag] || LEGACY_KEY_TYPE) !== this.tssKeyType) {
      throw CoreError$1.default(`tssKeyType mismatch: ${this.metadata.tssKeyTypes[this.tssTag]} !== ${this.tssKeyType}`);
    }
    this._tssTag = tag;
  }
  /**
   * Initializes this instance. If a TSS account does not exist, creates one
   * under the given factor key. `skipTssInit` skips TSS account creation and
   * can be used with `importTssKey` to just import an existing account instead.
   * @returns The key details of TKey core.
   */
  async initialize(params) {
    const keyDetails = await super.initialize(params);
    if (!this.metadata.tssPolyCommits[this.tssTag] && !(params !== null && params !== void 0 && params.skipTssInit || params !== null && params !== void 0 && params.neverInitializeNewKey)) {
      const {
        factorEncs,
        factorPubs,
        tssPolyCommits
      } = await this._initializeNewTSSKey(this.tssTag, params.deviceTSSShare, params.factorPub, params.deviceTSSIndex);
      this.metadata.updateTSSData({
        tssKeyType: this._tssKeyType,
        tssTag: this.tssTag,
        tssNonce: 0,
        tssPolyCommits,
        factorPubs,
        factorEncs
      });
      const accountSalt = generateSalt(this._tssCurve);
      await this._setTKeyStoreItem(TSS_MODULE, {
        id: "accountSalt",
        value: accountSalt
      });
      this._accountSalt = accountSalt;
    }
    if (this.metadata.tssPolyCommits[this.tssTag] && (this.metadata.tssKeyTypes[this.tssTag] || LEGACY_KEY_TYPE) !== this.tssKeyType) {
      throw CoreError$1.default(`tssKeyType mismatch: ${this.metadata.tssKeyTypes[this.tssTag]} !== ${this.tssKeyType}`);
    }
    return keyDetails;
  }
  /**
   * Returns the encrypted data associated with the given factor public key.
   */
  getFactorEncs(factorPub) {
    if (!this.metadata) throw CoreError$1.metadataUndefined();
    if (!this.metadata.factorEncs) throw CoreError$1.default("no factor encs mapping");
    if (!this.metadata.factorPubs) throw CoreError$1.default("no factor pubs mapping");
    const factorPubs = this.metadata.factorPubs[this.tssTag];
    if (!factorPubs) throw CoreError$1.default(`no factor pubs for this tssTag ${this.tssTag}`);
    if (factorPubs.filter((f) => f.x.cmp(factorPub.x) === 0 && f.y.cmp(factorPub.y) === 0).length === 0) throw CoreError$1.default(`factor pub ${factorPub} not found for tssTag ${this.tssTag}`);
    if (!this.metadata.factorEncs[this.tssTag]) throw CoreError$1.default(`no factor encs for tssTag ${this.tssTag}`);
    const factorPubID = factorPub.x.toString(16, 64);
    return this.metadata.factorEncs[this.tssTag][factorPubID];
  }
  /**
   * Returns the TSS share associated with the given factor private key.
   */
  async getTSSShare(factorKey, opts) {
    const factorPub = getPubKeyPoint2(factorKey, factorKeyCurve);
    const factorEncs = this.getFactorEncs(factorPub);
    const {
      userEnc,
      serverEncs,
      tssIndex,
      type
    } = factorEncs;
    const userDecryption = await decrypt(Buffer.from(factorKey.toString(16, 64), "hex"), userEnc);
    const serverDecryptions = await Promise.all(serverEncs.map((factorEnc) => {
      if (factorEnc === null) return null;
      return decrypt(Buffer.from(factorKey.toString(16, 64), "hex"), factorEnc);
    }));
    const tssShareBufs = [userDecryption].concat(serverDecryptions);
    const tssShareBNs = tssShareBufs.map((buf) => {
      if (buf === null) return null;
      return new import_bn9.default(buf);
    });
    const ec5 = this._tssCurve;
    const tssCommits = this.getTSSCommits().map((p) => {
      return ec5.keyFromPublic({
        x: p.x.toString(16, 64),
        y: p.y.toString(16, 64)
      }).getPublic();
    });
    const userDec = tssShareBNs[0];
    const accountIndex = (opts === null || opts === void 0 ? void 0 : opts.accountIndex) || 0;
    const coefficient = (opts === null || opts === void 0 ? void 0 : opts.coefficient) || new import_bn9.default(1);
    if (type === "direct") {
      const tssSharePub = ec5.g.mul(userDec);
      const tssCommitA0 = tssCommits[0];
      const tssCommitA1 = tssCommits[1];
      const _tssSharePub = tssCommitA0.add(tssCommitA1.mul(new import_bn9.default(tssIndex)));
      if (tssSharePub.eq(_tssSharePub)) {
        const adjustedShare = this.adjustTssShare(userDec, accountIndex, coefficient);
        return {
          tssIndex,
          tssShare: adjustedShare
        };
      }
      throw new Error("user decryption does not match tss commitments...");
    }
    const serverDecs = tssShareBNs.slice(1);
    const serverIndexes = new Array(serverDecs.length).fill(null).map((_, i) => i + 1);
    const threshold = (opts === null || opts === void 0 ? void 0 : opts.threshold) || Math.ceil(serverDecs.length / 2);
    const combis = kCombinations(serverDecs.length, threshold);
    for (let i = 0; i < combis.length; i++) {
      const combi = combis[i];
      const selectedServerDecs = serverDecs.filter((_, j) => combi.indexOf(j) > -1);
      if (selectedServerDecs.includes(null)) continue;
      const selectedServerIndexes = serverIndexes.filter((_, j) => combi.indexOf(j) > -1);
      const serverLagrangeCoeffs = selectedServerIndexes.map((x) => getLagrangeCoeffs(ec5, selectedServerIndexes, x));
      const serverInterpolated = dotProduct(serverLagrangeCoeffs, selectedServerDecs, ec5.n);
      const lagrangeCoeffs = [getLagrangeCoeffs(ec5, [1, 99], 1), getLagrangeCoeffs(ec5, [1, 99], 99)];
      const tssShare = dotProduct(lagrangeCoeffs, [serverInterpolated, userDec], ec5.n);
      const tssSharePub = ec5.g.mul(tssShare);
      const tssCommitA0 = tssCommits[0];
      const tssCommitA1 = tssCommits[1];
      let _tssSharePub = tssCommitA0;
      for (let j = 0; j < tssIndex; j++) {
        _tssSharePub = _tssSharePub.add(tssCommitA1);
      }
      if (tssSharePub.eq(_tssSharePub)) {
        const adjustedShare = this.adjustTssShare(tssShare, accountIndex, coefficient);
        return {
          tssIndex,
          tssShare: adjustedShare
        };
      }
    }
    throw new Error("could not find any combination of server decryptions that match tss commitments...");
  }
  /**
   * Returns the TSS public key and the curve points corresponding to secret key
   * shares, as stored in Metadata.
   */
  getTSSCommits() {
    if (!this.metadata) throw CoreError$1.metadataUndefined();
    const tssPolyCommits = this.metadata.tssPolyCommits[this.tssTag];
    if (!tssPolyCommits) throw CoreError$1.default(`tss poly commits not found for tssTag ${this.tssTag}`);
    if (tssPolyCommits.length === 0) throw CoreError$1.default("tss poly commits is empty");
    return tssPolyCommits;
  }
  /**
   * Returns the TSS public key.
   */
  getTSSPub(accountIndex) {
    const ec5 = this._tssCurve;
    const tssCommits = this.getTSSCommits();
    if (accountIndex && accountIndex > 0) {
      const nonce = this.computeAccountNonce(accountIndex);
      const noncePub = ec5.keyFromPrivate(nonce.toString("hex")).getPublic();
      const pubKeyPoint = tssCommits[0].toEllipticPoint(ec5);
      const devicePubKeyPoint = pubKeyPoint.add(noncePub);
      return Point$1.fromElliptic(devicePubKeyPoint);
    }
    return tssCommits[0];
  }
  /**
   * Returns the node details for RSS.
   */
  async _getRssNodeDetails() {
    const {
      serverEndpoints,
      serverPubKeys,
      serverThreshold
    } = await this.serviceProvider.getRSSNodeDetails();
    if (!Array.isArray(serverEndpoints) || serverEndpoints.length === 0) throw new Error("service provider tss server endpoints are missing");
    if (!Array.isArray(serverPubKeys) || serverPubKeys.length === 0) throw new Error("service provider pub keys are missing");
    return {
      serverEndpoints,
      serverPubKeys,
      serverThreshold: serverThreshold || Math.floor(serverEndpoints.length / 2) + 1
    };
  }
  /**
   * Imports an existing private key for threshold signing. A corresponding user
   * key share will be stored under the specified factor key.
   */
  async importTssKey(params, serverOpts) {
    const ec5 = this._tssCurve;
    if (!this.secp256k1Key) throw CoreError$1.privateKeyUnavailable();
    if (!this.metadata) {
      throw CoreError$1.metadataUndefined();
    }
    const {
      importKey,
      factorPub,
      newTSSIndex,
      tag
    } = params;
    const oldTag = this.tssTag;
    this._tssTag = tag;
    try {
      const {
        selectedServers = [],
        authSignatures = []
      } = serverOpts || {};
      if (!tag) throw CoreError$1.default(`invalid param, tag is required`);
      if (!factorPub) throw CoreError$1.default(`invalid param, newFactorPub is required`);
      if (!newTSSIndex) throw CoreError$1.default(`invalid param, newTSSIndex is required`);
      if (authSignatures.length === 0) throw CoreError$1.default(`invalid param, authSignatures is required`);
      const existingFactorPubs = this.metadata.factorPubs[tag];
      if ((existingFactorPubs === null || existingFactorPubs === void 0 ? void 0 : existingFactorPubs.length) > 0) {
        throw CoreError$1.default(`Duplicate account tag, please use a unique tag for importing key`);
      }
      const factorPubs = [factorPub];
      const importScalar = await (async () => {
        if (this._tssKeyType === KeyType.secp256k1) {
          return new import_bn9.default(importKey);
        } else if (this._tssKeyType === KeyType.ed25519) {
          const domainKey = getEd25519SeedStoreDomainKey(this.tssTag || TSS_TAG_DEFAULT);
          const result = this.metadata.getGeneralStoreDomain(domainKey);
          if (result) {
            throw new Error("Seed already exists");
          }
          const {
            scalar
          } = getEd25519ExtendedPublicKey(importKey);
          const encKey = Buffer.from(getSecpKeyFromEd25519(scalar).point.encodeCompressed("hex"), "hex");
          const msg = await encrypt(encKey, importKey);
          this.metadata.setGeneralStoreDomain(domainKey, {
            message: msg
          });
          return scalar;
        }
        throw new Error("Invalid key type");
      })();
      if (!importScalar || importScalar.eq(new import_bn9.default("0"))) {
        throw new Error("Invalid importedKey");
      }
      const tssIndexes = [newTSSIndex];
      const existingNonce = this.metadata.tssNonces[this.tssTag];
      const newTssNonce = existingNonce && existingNonce > 0 ? existingNonce + 1 : 0;
      const verifierAndVerifierID = this.serviceProvider.getVerifierNameVerifierId();
      const label = `${verifierAndVerifierID}${this.tssTag}${newTssNonce}`;
      const tssPubKey = hexPoint(ec5.g.mul(importScalar));
      const rssNodeDetails = await this._getRssNodeDetails();
      const {
        pubKey: newTSSServerPub,
        nodeIndexes
      } = await this.serviceProvider.getTSSPubKey(this.tssTag, newTssNonce);
      let finalSelectedServers = selectedServers;
      if ((nodeIndexes === null || nodeIndexes === void 0 ? void 0 : nodeIndexes.length) > 0) {
        if (selectedServers.length) {
          finalSelectedServers = nodeIndexes.slice(0, Math.min(selectedServers.length, nodeIndexes.length));
        } else {
          finalSelectedServers = nodeIndexes.slice(0, 3);
        }
      } else if ((selectedServers === null || selectedServers === void 0 ? void 0 : selectedServers.length) === 0) {
        finalSelectedServers = randomSelection(new Array(rssNodeDetails.serverEndpoints.length).fill(null).map((_, i) => i + 1), Math.ceil(rssNodeDetails.serverEndpoints.length / 2));
      }
      const {
        serverEndpoints,
        serverPubKeys,
        serverThreshold
      } = rssNodeDetails;
      const rssClient = new RSSClient({
        serverEndpoints,
        serverPubKeys,
        serverThreshold,
        tssPubKey,
        keyType: this._tssKeyType
      });
      const refreshResponses = await rssClient.import({
        importKey: importScalar,
        dkgNewPub: pointToHex(newTSSServerPub),
        selectedServers: finalSelectedServers,
        factorPubs: factorPubs.map((f) => pointToHex(f)),
        targetIndexes: tssIndexes,
        newLabel: label,
        sigs: authSignatures
      });
      const secondCommit = newTSSServerPub.toEllipticPoint(ec5).add(ecPoint(ec5, tssPubKey).neg());
      const newTSSCommits = [Point$1.fromJSON(tssPubKey), Point$1.fromJSON({
        x: secondCommit.getX().toString(16, 64),
        y: secondCommit.getY().toString(16, 64)
      })];
      const factorEncs = {};
      for (let i = 0; i < refreshResponses.length; i++) {
        const refreshResponse = refreshResponses[i];
        factorEncs[refreshResponse.factorPub.x.padStart(64, "0")] = {
          type: "hierarchical",
          tssIndex: refreshResponse.targetIndex,
          userEnc: refreshResponse.userFactorEnc,
          serverEncs: refreshResponse.serverFactorEncs
        };
      }
      this.metadata.updateTSSData({
        tssKeyType: this._tssKeyType,
        tssTag: this.tssTag,
        tssNonce: newTssNonce,
        tssPolyCommits: newTSSCommits,
        factorPubs,
        factorEncs
      });
      if (!this._accountSalt) {
        const accountSalt = generateSalt(this._tssCurve);
        await this._setTKeyStoreItem(TSS_MODULE, {
          id: "accountSalt",
          value: accountSalt
        });
        this._accountSalt = accountSalt;
      }
      await this._syncShareMetadata();
    } catch (error) {
      this._tssTag = oldTag;
      throw error;
    }
  }
  /**
   * UNSAFE: USE WITH CAUTION
   *
   * Reconstructs and exports the TSS private key.
   */
  async _UNSAFE_exportTssKey(tssOptions) {
    if (!this.metadata) throw CoreError$1.metadataUndefined("metadata is undefined");
    if (!this.secp256k1Key) throw new Error("Tkey is not reconstructed");
    if (!this.metadata.tssPolyCommits[this.tssTag]) throw new Error(`tss key has not been initialized for tssTag ${this.tssTag}`);
    const {
      factorKey,
      selectedServers,
      authSignatures,
      accountIndex
    } = tssOptions;
    const {
      tssIndex
    } = await this.getTSSShare(factorKey);
    const tempShareIndex = tssIndex === 2 ? 3 : 2;
    const tempFactorKey = factorKeyCurve.genKeyPair().getPrivate();
    const tempFactorPub = getPubKeyPoint2(tempFactorKey, factorKeyCurve);
    await this.addFactorPub({
      existingFactorKey: factorKey,
      newFactorPub: tempFactorPub,
      newTSSIndex: tempShareIndex,
      authSignatures,
      selectedServers,
      refreshShares: true
    });
    const {
      tssShare: factorShare,
      tssIndex: factorIndex
    } = await this.getTSSShare(factorKey);
    const {
      tssShare: tempShare,
      tssIndex: tempIndex
    } = await this.getTSSShare(tempFactorKey);
    const ec5 = this._tssCurve;
    const tssKey = lagrangeInterpolation(ec5, [tempShare, factorShare], [new import_bn9.default(tempIndex), new import_bn9.default(factorIndex)]);
    await this.deleteFactorPub({
      factorKey,
      deleteFactorPub: tempFactorPub,
      authSignatures,
      selectedServers
    });
    const nonce = this.computeAccountNonce(accountIndex);
    const derivedKey = tssKey.add(nonce).umod(this._tssCurve.n);
    return derivedKey;
  }
  /**
   * UNSAFE: USE WITH CAUTION
   *
   * Reconstructs the TSS private key and exports the ed25519 private key seed.
   */
  async _UNSAFE_exportTssEd25519Seed(tssOptions) {
    const edScalar = await this._UNSAFE_exportTssKey(tssOptions);
    const domainKey = getEd25519SeedStoreDomainKey(this.tssTag || TSS_TAG_DEFAULT);
    const result = this.metadata.getGeneralStoreDomain(domainKey);
    const decKey = getSecpKeyFromEd25519(edScalar).scalar;
    const seed = await decrypt(decKey.toArrayLike(Buffer, "be", 32), result.message);
    return seed;
  }
  /**
   * Runs the share refresh protocol for the TSS key shares.
   * @param inputShare - The current user secret share.
   * @param inputIndex - The user share index.
   * @param factorPubs - The target factor keys.
   * @param targetIndexes - The target indices to provide new shares for.
   */
  async _refreshTSSShares(updateMetadata, inputShare, inputIndex, factorPubs, targetIndexes, verifierNameVerifierId, serverOpts) {
    if (!this.metadata) throw CoreError$1.metadataUndefined();
    if (!this.metadata.tssPolyCommits) throw CoreError$1.default(`tss poly commits obj not found`);
    const tssCommits = this.metadata.tssPolyCommits[this.tssTag];
    if (!tssCommits) throw CoreError$1.default(`tss commits not found for tssTag ${this.tssTag}`);
    if (tssCommits.length === 0) throw CoreError$1.default(`tssCommits is empty`);
    const tssPubKeyPoint = tssCommits[0];
    const tssPubKey = pointToHex(tssPubKeyPoint);
    const {
      serverEndpoints,
      serverPubKeys,
      serverThreshold,
      selectedServers,
      authSignatures
    } = serverOpts;
    const rssClient = new RSSClient({
      serverEndpoints,
      serverPubKeys,
      serverThreshold,
      tssPubKey,
      keyType: this._tssKeyType
    });
    if (!this.metadata.factorPubs) throw CoreError$1.default(`factorPubs obj not found`);
    if (!factorPubs) throw CoreError$1.default(`factorPubs not found for tssTag ${this.tssTag}`);
    if (factorPubs.length === 0) throw CoreError$1.default(`factorPubs is empty`);
    if (!this.metadata.tssNonces) throw CoreError$1.default(`tssNonces obj not found`);
    const tssNonce = this.metadata.tssNonces[this.tssTag] || 0;
    const oldLabel = `${verifierNameVerifierId}${this.tssTag}${tssNonce}`;
    const newLabel = `${verifierNameVerifierId}${this.tssTag}${tssNonce + 1}`;
    const {
      pubKey: newTSSServerPub,
      nodeIndexes
    } = await this.serviceProvider.getTSSPubKey(this.tssTag, tssNonce + 1);
    let finalSelectedServers = selectedServers;
    if ((nodeIndexes === null || nodeIndexes === void 0 ? void 0 : nodeIndexes.length) > 0) {
      finalSelectedServers = nodeIndexes.slice(0, Math.min(selectedServers.length, nodeIndexes.length));
    }
    const refreshResponses = await rssClient.refresh({
      factorPubs: factorPubs.map((f) => pointToHex(f)),
      targetIndexes,
      oldLabel,
      newLabel,
      sigs: authSignatures,
      dkgNewPub: pointToHex(newTSSServerPub),
      inputShare,
      inputIndex,
      selectedServers: finalSelectedServers
    });
    const secondCommit = newTSSServerPub.toEllipticPoint(this._tssCurve).add(ecPoint(this._tssCurve, tssPubKey).neg());
    const newTSSCommits = [Point$1.fromJSON(tssPubKey), Point$1.fromJSON({
      x: secondCommit.getX().toString(16, 64),
      y: secondCommit.getY().toString(16, 64)
    })];
    const factorEncs = {};
    for (let i = 0; i < refreshResponses.length; i++) {
      const refreshResponse = refreshResponses[i];
      factorEncs[refreshResponse.factorPub.x.padStart(64, "0")] = {
        type: "hierarchical",
        tssIndex: refreshResponse.targetIndex,
        userEnc: refreshResponse.userFactorEnc,
        serverEncs: refreshResponse.serverFactorEncs
      };
    }
    this.metadata.updateTSSData({
      tssKeyType: this._tssKeyType,
      tssTag: this.tssTag,
      tssNonce: tssNonce + 1,
      tssPolyCommits: newTSSCommits,
      factorPubs,
      factorEncs
    });
    if (updateMetadata) await this._syncShareMetadata();
  }
  /**
   * Derives the account nonce for the specified account index.
   */
  computeAccountNonce(index) {
    if (!index || index === 0) {
      return new import_bn9.default(0);
    }
    if (this._tssKeyType === KeyType.ed25519) {
      throw new Error("account index not supported with ed25519");
    }
    if (!this._accountSalt) {
      throw Error("account salt undefined");
    }
    let accountHash = keccak256(Buffer.from(`${index}${this._accountSalt}`));
    if (accountHash.length === 66) accountHash = accountHash.slice(2);
    return new import_bn9.default(accountHash, "hex").umod(this._tssCurve.n);
  }
  /**
   * Reconstructs the TKey and finalize intialization.
   */
  async reconstructKey(_reconstructKeyMiddleware) {
    const k = await super.reconstructKey(_reconstructKeyMiddleware);
    const accountSalt = await this.getTKeyStoreItem(TSS_MODULE, "accountSalt");
    if (accountSalt && accountSalt.value) {
      this._accountSalt = accountSalt.value;
    } else {
      const newSalt = generateSalt(this._tssCurve);
      await this._setTKeyStoreItem(TSS_MODULE, {
        id: "accountSalt",
        value: newSalt
      });
      this._accountSalt = newSalt;
      if (this.manualSync) await this.syncLocalMetadataTransitions();
    }
    return k;
  }
  /**
   * Adds a factor key to the set of authorized keys.
   *
   * `refreshShares` - If this is true, then refresh the shares. If this is
   * false, `newTSSIndex` must be the same as current factor key index.
   */
  async addFactorPub(args) {
    if (!this.metadata) throw CoreError$1.metadataUndefined("metadata is undefined");
    if (!this.secp256k1Key) throw new Error("Tkey is not reconstructed");
    if (!this.metadata.tssPolyCommits[this.tssTag]) throw new Error(`tss key has not been initialized for tssTag ${this.tssTag}`);
    const {
      existingFactorKey,
      newFactorPub,
      newTSSIndex,
      selectedServers,
      authSignatures,
      refreshShares
    } = args;
    const {
      tssShare,
      tssIndex
    } = await this.getTSSShare(existingFactorKey);
    if (tssIndex !== newTSSIndex && !refreshShares) {
      throw CoreError$1.default("newTSSIndex does not match existing tssIndex, set refreshShares to true to refresh shares");
    }
    if (!refreshShares) {
      if (tssIndex !== newTSSIndex) {
        throw CoreError$1.default("newTSSIndex does not match existing tssIndex, set refreshShares to true to refresh shares");
      }
      const updatedFactorPubs = this.metadata.factorPubs[this.tssTag].concat([newFactorPub]);
      const factorEncs = JSON.parse(JSON.stringify(this.metadata.factorEncs[this.tssTag]));
      const factorPubID = newFactorPub.x.toString(16, 64);
      factorEncs[factorPubID] = {
        tssIndex,
        type: "direct",
        userEnc: await encrypt(newFactorPub.toSEC1(secp256k1, false), tssShare.toArrayLike(Buffer, "be", 32)),
        serverEncs: []
      };
      this.metadata.updateTSSData({
        tssKeyType: this.tssKeyType,
        tssTag: this.tssTag,
        factorPubs: updatedFactorPubs,
        factorEncs
      });
    } else {
      const existingFactorPubs = this.metadata.factorPubs[this.tssTag];
      const updatedFactorPubs = existingFactorPubs.concat([newFactorPub]);
      const verifierId = this.serviceProvider.getVerifierNameVerifierId();
      const rssNodeDetails = await this._getRssNodeDetails();
      const randomSelectedServers = randomSelection(new Array(rssNodeDetails.serverEndpoints.length).fill(null).map((_, i) => i + 1), Math.ceil(rssNodeDetails.serverEndpoints.length / 2));
      const finalServer = selectedServers || randomSelectedServers;
      const existingTSSIndexes = existingFactorPubs.map((fb) => this.getFactorEncs(fb).tssIndex);
      const updatedTSSIndexes = existingTSSIndexes.concat([newTSSIndex]);
      await this._refreshTSSShares(false, tssShare, tssIndex, updatedFactorPubs, updatedTSSIndexes, verifierId, _objectSpread2(_objectSpread2({}, rssNodeDetails), {}, {
        selectedServers: finalServer,
        authSignatures
      }));
    }
    await this._syncShareMetadata();
  }
  /**
   * Removes a factor key from the set of authorized keys and refreshes the TSS
   * key shares.
   */
  async deleteFactorPub(args) {
    if (!this.metadata) throw CoreError$1.metadataUndefined("metadata is undefined");
    if (!this.secp256k1Key) throw new Error("Tkey is not reconstructed");
    if (!this.metadata.tssPolyCommits[this.tssTag]) throw new Error(`tss key has not been initialized for tssTag ${this.tssTag}`);
    const {
      factorKey,
      deleteFactorPub,
      selectedServers,
      authSignatures
    } = args;
    const existingFactorPubs = this.metadata.factorPubs[this.tssTag];
    const {
      tssShare,
      tssIndex
    } = await this.getTSSShare(factorKey);
    const found = existingFactorPubs.filter((f) => f.x.eq(deleteFactorPub.x) && f.y.eq(deleteFactorPub.y));
    if (found.length === 0) throw CoreError$1.default("could not find factorPub to delete");
    if (found.length > 1) throw CoreError$1.default("found two or more factorPubs that match, error in metadata");
    const updatedFactorPubs = existingFactorPubs.filter((f) => !f.x.eq(deleteFactorPub.x) || !f.y.eq(deleteFactorPub.y));
    this.metadata.updateTSSData({
      tssKeyType: this._tssKeyType,
      tssTag: this.tssTag,
      factorPubs: updatedFactorPubs
    });
    const rssNodeDetails = await this._getRssNodeDetails();
    const randomSelectedServers = randomSelection(new Array(rssNodeDetails.serverEndpoints.length).fill(null).map((_, i) => i + 1), Math.ceil(rssNodeDetails.serverEndpoints.length / 2));
    const finalServer = selectedServers || randomSelectedServers;
    const updatedTSSIndexes = updatedFactorPubs.map((fb) => this.getFactorEncs(fb).tssIndex);
    await this._refreshTSSShares(false, tssShare, tssIndex, updatedFactorPubs, updatedTSSIndexes, this.serviceProvider.getVerifierNameVerifierId(), _objectSpread2(_objectSpread2({}, rssNodeDetails), {}, {
      selectedServers: finalServer,
      authSignatures
    }));
    await this._syncShareMetadata();
  }
  /**
   * Adjusts a TSS key share based on account index and share coefficient.
   */
  adjustTssShare(share, accountIndex, coefficient) {
    const nonce = this.computeAccountNonce(accountIndex);
    return share.mul(coefficient).add(nonce).umod(this._tssCurve.n);
  }
  /**
   * Initializes a new TSS key under the specified factor key and using the
   * provided user share.
   */
  async _initializeNewTSSKey(tssTag, deviceTSSShare, factorPub, deviceTSSIndex) {
    const ec5 = this._tssCurve;
    let tss2;
    const _tssIndex = deviceTSSIndex || 2;
    if (deviceTSSShare) {
      tss2 = deviceTSSShare;
    } else {
      tss2 = this._tssCurve.genKeyPair().getPrivate();
    }
    const {
      pubKey: tss1Pub
    } = await this.serviceProvider.getTSSPubKey(tssTag, 0);
    const tss1PubKey = tss1Pub.toEllipticPoint(ec5);
    const tss2PubKey = this._tssCurve.g.mul(tss2);
    const L1_0 = getLagrangeCoeffs(ec5, [1, _tssIndex], 1, 0);
    const LIndex_0 = getLagrangeCoeffs(ec5, [1, _tssIndex], _tssIndex, 0);
    const a0Pub = tss1PubKey.mul(L1_0).add(tss2PubKey.mul(LIndex_0));
    const a1Pub = tss1PubKey.add(a0Pub.neg());
    const tssPolyCommits = [Point$1.fromElliptic(a0Pub), Point$1.fromElliptic(a1Pub)];
    const factorPubs = [factorPub];
    const factorEncs = {};
    for (let i = 0; i < factorPubs.length; i++) {
      const f = factorPubs[i];
      const factorPubID = f.x.toString(16, 64);
      factorEncs[factorPubID] = {
        tssIndex: _tssIndex,
        type: "direct",
        userEnc: await encrypt(f.toSEC1(factorKeyCurve, false), Buffer.from(tss2.toString(16, 64), "hex")),
        serverEncs: []
      };
    }
    return {
      tss2,
      factorEncs,
      factorPubs,
      tssPolyCommits
    };
  }
};

export {
  kCombinations,
  generateSalt,
  getLagrangeCoeffs,
  lagrangeInterpolation,
  pointToHex,
  getPubKeyPoint2 as getPubKeyPoint,
  DELIMITERS,
  getExtendedVerifierId,
  getEd25519SeedStoreDomainKey,
  TSSTorusServiceProvider,
  CoreError$1,
  generatePrivateBN,
  randomSelection,
  TSS_MODULE,
  TSS_TAG_DEFAULT,
  FACTOR_KEY_TYPE,
  factorKeyCurve,
  LEGACY_KEY_TYPE,
  TKeyTSS
};
//# sourceMappingURL=chunk-WAZ3JWJ6.js.map
