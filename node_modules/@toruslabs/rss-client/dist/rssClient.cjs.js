/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	// The require scope
/******/ 	var __webpack_require__ = {};
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
var __webpack_exports__ = {};
// ESM COMPAT FLAG
__webpack_require__.r(__webpack_exports__);

// EXPORTS
__webpack_require__.d(__webpack_exports__, {
  RSSClient: () => (/* reexport */ RSSClient),
  decrypt: () => (/* reexport */ decrypt),
  dotProduct: () => (/* reexport */ dotProduct),
  ecCurveSecp256k1: () => (/* reexport */ ecCurveSecp256k1),
  ecPoint: () => (/* reexport */ ecPoint),
  encrypt: () => (/* reexport */ encrypt),
  generatePolynomial: () => (/* reexport */ generatePolynomial),
  getEndpoint: () => (/* reexport */ getEndpoint),
  getLagrangeCoeff: () => (/* reexport */ getLagrangeCoeff),
  getShare: () => (/* reexport */ getShare),
  hexPoint: () => (/* reexport */ hexPoint),
  lagrangeInterpolation: () => (/* reexport */ lagrangeInterpolation),
  postEndpoint: () => (/* reexport */ postEndpoint),
  randomSelection: () => (/* reexport */ randomSelection),
  recover: () => (/* reexport */ recover)
});

;// external "@babel/runtime/helpers/defineProperty"
const defineProperty_namespaceObject = require("@babel/runtime/helpers/defineProperty");
var defineProperty_default = /*#__PURE__*/__webpack_require__.n(defineProperty_namespaceObject);
;// external "@toruslabs/http-helpers"
const http_helpers_namespaceObject = require("@toruslabs/http-helpers");
;// external "bn.js"
const external_bn_js_namespaceObject = require("bn.js");
var external_bn_js_default = /*#__PURE__*/__webpack_require__.n(external_bn_js_namespaceObject);
;// external "elliptic"
const external_elliptic_namespaceObject = require("elliptic");
;// external "loglevel"
const external_loglevel_namespaceObject = require("loglevel");
var external_loglevel_default = /*#__PURE__*/__webpack_require__.n(external_loglevel_namespaceObject);
;// external "@toruslabs/eccrypto"
const eccrypto_namespaceObject = require("@toruslabs/eccrypto");
;// ./src/utils.ts



const ecCurveSecp256k1 = new external_elliptic_namespaceObject.ec("secp256k1");
function randomSelection(arr, num) {
  if (num > arr.length) throw new Error("trying to select more elements than available");
  const selected = [];
  const slice = arr.slice();
  while (selected.length < num) {
    selected.push(slice.splice(Math.floor(Math.random() * slice.length), 1)[0]);
  }
  return selected;
}
function ecPoint(ecCurve, p) {
  if (p.x === null && p.y === null) {
    return ecCurve.curve.g.add(ecCurve.curve.g.neg());
  }
  return ecCurve.keyFromPublic({
    x: p.x.padStart(64, "0"),
    y: p.y.padStart(64, "0")
  }).getPublic();
}
function hexPoint(p) {
  if (p.isInfinity()) {
    return {
      x: null,
      y: null
    };
  }
  return {
    x: p.getX().toString(16, 64),
    y: p.getY().toString(16, 64)
  };
}
// Wrappers around ECC encrypt/decrypt to use the hex serialization
async function encrypt(publicKey, msg) {
  const encryptedDetails = await (0,eccrypto_namespaceObject.encrypt)(publicKey, msg);
  return {
    ciphertext: encryptedDetails.ciphertext.toString("hex"),
    ephemPublicKey: encryptedDetails.ephemPublicKey.toString("hex"),
    iv: encryptedDetails.iv.toString("hex"),
    mac: encryptedDetails.mac.toString("hex")
  };
}
async function decrypt(privKey, msg) {
  const bufferEncDetails = {
    ciphertext: Buffer.from(msg.ciphertext, "hex"),
    ephemPublicKey: Buffer.from(msg.ephemPublicKey, "hex"),
    iv: Buffer.from(msg.iv, "hex"),
    mac: Buffer.from(msg.mac, "hex")
  };
  return (0,eccrypto_namespaceObject.decrypt)(privKey, bufferEncDetails);
}
function generatePolynomial(degree, yIntercept, randomElement) {
  const res = [];
  let i = 0;
  if (yIntercept !== undefined) {
    res.push(yIntercept);
    i++;
  }
  for (; i <= degree; i++) {
    res.push(randomElement());
  }
  return res;
}
function getShare(polynomial, index, modulus) {
  let res = new (external_bn_js_default())(0);
  for (let i = 0; i < polynomial.length; i++) {
    const term = polynomial[i].mul(new (external_bn_js_default())(index).pow(new (external_bn_js_default())(i)));
    res = res.add(term.umod(modulus));
  }
  return res.umod(modulus);
}
function dotProduct(arr1, arr2, modulus) {
  if (arr1.length !== arr2.length) {
    throw new Error("arrays of different lengths");
  }
  let sum = new (external_bn_js_default())(0);
  for (let i = 0; i < arr1.length; i++) {
    sum = sum.add(arr1[i].mul(arr2[i]));
    if (modulus) {
      sum = sum.umod(modulus);
    }
  }
  return sum;
}
function getLagrangeCoeff(_allIndexes, _myIndex, _target, modulus) {
  const allIndexes = _allIndexes.map(i => new (external_bn_js_default())(i));
  const myIndex = new (external_bn_js_default())(_myIndex);
  const target = new (external_bn_js_default())(_target);
  let upper = new (external_bn_js_default())(1);
  let lower = new (external_bn_js_default())(1);
  for (let j = 0; j < allIndexes.length; j += 1) {
    if (myIndex.cmp(allIndexes[j]) !== 0) {
      let tempUpper = target.sub(allIndexes[j]);
      tempUpper = tempUpper.umod(modulus);
      upper = upper.mul(tempUpper);
      upper = upper.umod(modulus);
      let tempLower = myIndex.sub(allIndexes[j]);
      tempLower = tempLower.umod(modulus);
      lower = lower.mul(tempLower).umod(modulus);
    }
  }
  return upper.mul(lower.invm(modulus)).umod(modulus);
}
function lagrangeInterpolation(shares, nodeIndex, modulus) {
  if (shares.length !== nodeIndex.length) {
    return null;
  }
  let secret = new (external_bn_js_default())(0);
  for (let i = 0; i < shares.length; i += 1) {
    let upper = new (external_bn_js_default())(1);
    let lower = new (external_bn_js_default())(1);
    for (let j = 0; j < shares.length; j += 1) {
      if (i !== j) {
        upper = upper.mul(nodeIndex[j].neg());
        upper = upper.umod(modulus);
        let temp = nodeIndex[i].sub(nodeIndex[j]);
        temp = temp.umod(modulus);
        lower = lower.mul(temp).umod(modulus);
      }
    }
    let delta = upper.mul(lower.invm(modulus)).umod(modulus);
    delta = delta.mul(shares[i]).umod(modulus);
    secret = secret.add(delta);
  }
  return secret.umod(modulus);
}
;// ./src/rss.ts






function getEndpoint(endpoint, path, options_, customOptions) {
  if (typeof endpoint === "string") {
    return (0,http_helpers_namespaceObject.get)(`${endpoint}${path}`, options_, customOptions);
  }
  return endpoint.get(path);
}
function postEndpoint(endpoint, path, data, options_, customOptions) {
  if (typeof endpoint === "string") {
    return (0,http_helpers_namespaceObject.post)(`${endpoint}${path}`, data, options_, customOptions);
  }
  return endpoint.post(path, data);
}
class RSSClient {
  constructor(opts) {
    defineProperty_default()(this, "tssPubKey", void 0);
    defineProperty_default()(this, "tempPrivKey", void 0);
    defineProperty_default()(this, "tempPubKey", void 0);
    defineProperty_default()(this, "serverEndpoints", void 0);
    defineProperty_default()(this, "serverThreshold", void 0);
    defineProperty_default()(this, "serverPubKeys", void 0);
    defineProperty_default()(this, "ecCurve", void 0);
    defineProperty_default()(this, "keyType", void 0);
    if (opts.keyType !== "secp256k1" && opts.keyType !== "ed25519") throw new Error("Invalid keyType, only secp256k1 or ed25519 is supported");
    this.keyType = opts.keyType;
    this.ecCurve = new external_elliptic_namespaceObject.ec(this.keyType);
    this.tssPubKey = ecPoint(this.ecCurve, opts.tssPubKey);
    this.serverEndpoints = opts.serverEndpoints;
    this.serverThreshold = opts.serverThreshold;
    this.serverPubKeys = opts.serverPubKeys;
    if (opts.tempKey) {
      this.tempPrivKey = opts.tempKey;
      this.tempPubKey = ecCurveSecp256k1.g.mul(opts.tempKey);
    } else {
      const kp = ecCurveSecp256k1.genKeyPair();
      this.tempPrivKey = kp.getPrivate();
      this.tempPubKey = kp.getPublic();
    }
  }
  async import(opts) {
    const {
      importKey,
      newLabel,
      sigs,
      dkgNewPub,
      targetIndexes,
      selectedServers,
      factorPubs
    } = opts;
    if (factorPubs.length !== targetIndexes.length) throw new Error("inconsistent factorPubs and targetIndexes lengths");
    const serversInfo = {
      pubkeys: this.serverPubKeys,
      selected: selectedServers,
      threshold: this.serverThreshold
    };

    // send requests to T servers (import only requires the T new servers)
    const rssRound1Proms = selectedServers.map(ind => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "new",
        server_index: ind,
        new_servers_info: serversInfo,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: newLabel,
          // TODO: undesigned
          sigs
        },
        key_type: this.keyType
      });
    });

    // front end also generates hierarchical secret sharing
    // - calculate lagrange coeffs
    const _finalLagrangeCoeffs = targetIndexes.map(target => getLagrangeCoeff([0, 1], 0, target, this.ecCurve.n).umod(this.ecCurve.n));
    const _masterPolys = [];
    const _masterPolyCommits = [];
    const _serverPolys = [];
    const _serverPolyCommits = [];
    const generateRandomScalar = () => this.ecCurve.genKeyPair().getPrivate();
    for (let i = 0; i < _finalLagrangeCoeffs.length; i++) {
      const _lc = _finalLagrangeCoeffs[i];
      const _m = generatePolynomial(1, _lc.mul(importKey).umod(this.ecCurve.n), generateRandomScalar);
      _masterPolys.push(_m);
      _masterPolyCommits.push(_m.map(coeff => {
        const _gCoeff = this.ecCurve.g.mul(coeff);
        return hexPoint(_gCoeff);
      }));
      const _s = generatePolynomial(serversInfo.threshold - 1, getShare(_m, 1, this.ecCurve.n), generateRandomScalar);
      _serverPolys.push(_s);
      _serverPolyCommits.push(_s.map(coeff => hexPoint(this.ecCurve.g.mul(coeff))));
    }
    const _serverEncs = [];
    const _userEncs = [];
    for (let i = 0; i < _masterPolys.length; i++) {
      _serverEncs.push([]); // for each target_index, create an array of server encryptions
    }
    // - generate N + 1 shares
    for (let i = 0; i < targetIndexes.length; i++) {
      const _masterPoly = _masterPolys[i];
      _userEncs.push(await encrypt(Buffer.from(`04${hexPoint(this.tempPubKey).x.padStart(64, "0")}${hexPoint(this.tempPubKey).y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_masterPoly, 99, this.ecCurve.n).toString(16, 64), "hex")));
      const _serverPoly = _serverPolys[i];
      const _serverEnc = _serverEncs[i];
      for (let j = 0; j < serversInfo.pubkeys.length; j++) {
        const _pub = serversInfo.pubkeys[j];
        _serverEnc.push(await encrypt(Buffer.from(`04${_pub.x.padStart(64, "0")}${_pub.y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_serverPoly, j + 1, this.ecCurve.n).toString(16, 64), "hex")));
      }
    }
    const _data = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      _data.push({
        master_poly_commits: _masterPolyCommits[i],
        server_poly_commits: _serverPolyCommits[i],
        target_encryptions: {
          user_enc: _userEncs[i],
          server_encs: _serverEncs[i]
        }
      });
    }

    // add front end generated hierarchical sharing to the list
    rssRound1Proms.push(new Promise(resolve => {
      resolve({
        target_index: targetIndexes,
        data: _data
      });
    }));

    // await responses
    const rssRound1Responses = await Promise.all(rssRound1Proms);

    // sum up all master poly commits and sum up all server poly commits
    const sums = targetIndexes.map((_, i) => {
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (masterPolyCommits.length !== 2) throw new Error("incorrect number of coeffs for master poly commits");
        if (serverPolyCommits.length !== this.serverThreshold) throw new Error("incorrect number of coeffs for server poly commits");
      }
      let sumMasterPolyCommits = [];
      let sumServerPolyCommits = [];
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (sumMasterPolyCommits.length === 0 && sumServerPolyCommits.length === 0) {
          sumMasterPolyCommits = masterPolyCommits.map(p => ecPoint(this.ecCurve, p));
          sumServerPolyCommits = serverPolyCommits.map(p => ecPoint(this.ecCurve, p));
          continue;
        }
        sumMasterPolyCommits = sumMasterPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, masterPolyCommits[k]).add(summedCommit);
        });
        sumServerPolyCommits = sumServerPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, serverPolyCommits[k]).add(summedCommit);
        });
      }
      return {
        mc: sumMasterPolyCommits,
        sc: sumServerPolyCommits
      };
    });

    // front end checks
    targetIndexes.map((target, i) => {
      const {
        mc,
        sc
      } = sums[i];
      // check master poly commits are consistent with tssPubKey
      const temp1 = ecPoint(this.ecCurve, dkgNewPub).mul(getLagrangeCoeff([1, target], 1, 0, this.ecCurve.n));
      const temp2 = mc[0].mul(getLagrangeCoeff([1, target], target, 0, this.ecCurve.n));
      const _tssPubKey = temp1.add(temp2);
      if (!_tssPubKey.eq(this.tssPubKey)) throw new Error("master poly commits inconsistent with tssPubKey");

      // check server poly commits are consistent with master poly commits
      if (!mc[0].add(mc[1]).eq(sc[0])) throw new Error("server poly commits inconsistent with master poly commits");
      return null;
    });

    // front end checks if decrypted user shares are consistent with poly commits
    const privKeyBuffer = Buffer.from(this.tempPrivKey.toString(16, 64), "hex");
    const userShares = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      const userEncs = rssRound1Responses.map(r => r.data[i].target_encryptions.user_enc);
      const userDecs = await Promise.all(userEncs.map(encMsg => decrypt(privKeyBuffer, encMsg)));
      const userShare = userDecs.map(userDec => new (external_bn_js_default())(userDec)).reduce((acc, d) => acc.add(d).umod(this.ecCurve.n), new (external_bn_js_default())(0));
      const {
        mc
      } = sums[i];
      const gU = this.ecCurve.g.mul(userShare);
      const _gU = mc[0].add(mc[1].mul(new (external_bn_js_default())(99))); // master poly evaluated at x = 99
      if (!gU.eq(_gU)) throw new Error("decrypted user shares inconsistent with poly commits");
      userShares.push(userShare);
    }
    const userFactorEncs = await Promise.all(userShares.map((userShare, i) => {
      const pub = factorPubs[i];
      return encrypt(Buffer.from(`04${pub.x.padStart(64, "0")}${pub.y.padStart(64, "0")}`, "hex"), Buffer.from(userShare.toString(16, 64), "hex"));
    }));

    // rearrange received serverEncs before sending them to new servers
    const serverEncs = targetIndexes.map((_, i) => {
      const serverEncsReceived = rssRound1Responses.map(r => r.data[i].target_encryptions.server_encs);
      // flip the matrix
      const serverEncsToSend = [];
      for (let j = 0; j < this.serverEndpoints.length; j++) {
        const serverEnc = [];

        // Import only has T servers and the user, so it's T + 1
        for (let k = 0; k < this.serverThreshold + 1; k++) {
          serverEnc.push(serverEncsReceived[k][j]);
        }
        serverEncsToSend.push(serverEnc);
      }
      return serverEncsToSend;
    });

    // servers sum up their shares and encrypt it for factorPubs
    const serverIndexes = this.serverEndpoints.map((_, i) => i + 1);
    const serverFactorEncs = await Promise.all(serverIndexes.map(ind => {
      // TODO: specify it's "new" server set for server indexes
      const data = [];
      targetIndexes.map((_, i) => {
        const {
          mc,
          sc
        } = sums[i];
        const round2RequestData = {
          master_commits: mc.map(hexPoint),
          server_commits: sc.map(hexPoint),
          server_encs: serverEncs[i][ind - 1],
          factor_pubkeys: [factorPubs[i]] // TODO: must we do it like this?
        };
        data.push(round2RequestData);
        return null;
      });
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_2", {
        round_name: "rss_round_2",
        server_index: ind,
        target_index: targetIndexes,
        data,
        key_type: this.keyType
      }).catch(e => external_loglevel_default().error(e));
    }));
    if (serverFactorEncs.filter(s => s).length < this.serverThreshold) throw new Error("not enough servers responded");
    const factorEncs = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      factorEncs.push({
        targetIndex: targetIndexes[i],
        factorPub: factorPubs[i],
        serverFactorEncs: serverFactorEncs.map(s => s && s.data[i].encs[0]),
        userFactorEnc: userFactorEncs[i]
      });
    }
    return factorEncs;
  }
  async refresh(opts) {
    const {
      targetIndexes,
      inputIndex,
      selectedServers,
      oldLabel,
      newLabel,
      sigs,
      dkgNewPub,
      inputShare,
      factorPubs
    } = opts;
    if (factorPubs.length !== targetIndexes.length) throw new Error("inconsistent factorPubs and targetIndexes lengths");
    const serversInfo = {
      pubkeys: this.serverPubKeys,
      selected: selectedServers,
      threshold: this.serverThreshold
    };

    // send requests to 2T servers
    const rssRound1Proms = selectedServers.map(ind => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "old",
        server_index: ind,
        old_servers_info: serversInfo,
        new_servers_info: serversInfo,
        old_user_share_index: inputIndex,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: oldLabel,
          sigs
        },
        key_type: this.keyType
      });
    }).concat(selectedServers.map(ind => {
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_1", {
        round_name: "rss_round_1",
        server_set: "new",
        server_index: ind,
        old_servers_info: serversInfo,
        new_servers_info: serversInfo,
        old_user_share_index: inputIndex,
        user_temp_pubkey: hexPoint(this.tempPubKey),
        target_index: targetIndexes,
        auth: {
          label: newLabel,
          // TODO: undesigned
          sigs
        },
        key_type: this.keyType
      });
    }));

    // front end also generates hierarchical secret sharing
    // - calculate lagrange coeffs
    const _L = getLagrangeCoeff([1, inputIndex], inputIndex, 0, this.ecCurve.n);
    const _finalLagrangeCoeffs = targetIndexes.map(target => _L.mul(getLagrangeCoeff([0, 1], 0, target, this.ecCurve.n)).umod(this.ecCurve.n));
    const _masterPolys = [];
    const _masterPolyCommits = [];
    const _serverPolys = [];
    const _serverPolyCommits = [];
    const generateRandomScalar = () => this.ecCurve.genKeyPair().getPrivate();
    for (let i = 0; i < _finalLagrangeCoeffs.length; i++) {
      const _lc = _finalLagrangeCoeffs[i];
      const _m = generatePolynomial(1, _lc.mul(inputShare).umod(this.ecCurve.n), generateRandomScalar);
      _masterPolys.push(_m);
      _masterPolyCommits.push(_m.map(coeff => {
        const _gCoeff = this.ecCurve.g.mul(coeff);
        return hexPoint(_gCoeff);
      }));
      const _s = generatePolynomial(serversInfo.threshold - 1, getShare(_m, 1, this.ecCurve.n), generateRandomScalar);
      _serverPolys.push(_s);
      _serverPolyCommits.push(_s.map(coeff => hexPoint(this.ecCurve.g.mul(coeff))));
    }
    const _serverEncs = [];
    const _userEncs = [];
    for (let i = 0; i < _masterPolys.length; i++) {
      _serverEncs.push([]); // for each target_index, create an array of server encryptions
    }
    // - generate N + 1 shares
    for (let i = 0; i < targetIndexes.length; i++) {
      const _masterPoly = _masterPolys[i];
      _userEncs.push(await encrypt(Buffer.from(`04${hexPoint(this.tempPubKey).x.padStart(64, "0")}${hexPoint(this.tempPubKey).y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_masterPoly, 99, this.ecCurve.n).toString(16, 64), "hex")));
      const _serverPoly = _serverPolys[i];
      const _serverEnc = _serverEncs[i];
      for (let j = 0; j < serversInfo.pubkeys.length; j++) {
        const _pub = serversInfo.pubkeys[j];
        _serverEnc.push(await encrypt(Buffer.from(`04${_pub.x.padStart(64, "0")}${_pub.y.padStart(64, "0")}`, "hex"), Buffer.from(getShare(_serverPoly, j + 1, this.ecCurve.n).toString(16, 64), "hex")));
      }
    }
    const _data = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      _data.push({
        master_poly_commits: _masterPolyCommits[i],
        server_poly_commits: _serverPolyCommits[i],
        target_encryptions: {
          user_enc: _userEncs[i],
          server_encs: _serverEncs[i]
        }
      });
    }

    // add front end generated hierarchical sharing to the list
    rssRound1Proms.push(new Promise(resolve => {
      resolve({
        target_index: targetIndexes,
        data: _data
      });
    }));

    // await responses
    const rssRound1Responses = await Promise.all(rssRound1Proms);

    // sum up all master poly commits and sum up all server poly commits
    const sums = targetIndexes.map((_, i) => {
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (masterPolyCommits.length !== 2) throw new Error("incorrect number of coeffs for master poly commits");
        if (serverPolyCommits.length !== this.serverThreshold) throw new Error("incorrect number of coeffs for server poly commits");
      }
      let sumMasterPolyCommits = [];
      let sumServerPolyCommits = [];
      for (let j = 0; j < rssRound1Responses.length; j++) {
        const rssRound1ResponseData = rssRound1Responses[j].data[i];
        const {
          master_poly_commits: masterPolyCommits,
          server_poly_commits: serverPolyCommits
        } = rssRound1ResponseData;
        if (sumMasterPolyCommits.length === 0 && sumServerPolyCommits.length === 0) {
          sumMasterPolyCommits = masterPolyCommits.map(p => ecPoint(this.ecCurve, p));
          sumServerPolyCommits = serverPolyCommits.map(p => ecPoint(this.ecCurve, p));
          continue;
        }
        sumMasterPolyCommits = sumMasterPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, masterPolyCommits[k]).add(summedCommit);
        });
        sumServerPolyCommits = sumServerPolyCommits.map((summedCommit, k) => {
          return ecPoint(this.ecCurve, serverPolyCommits[k]).add(summedCommit);
        });
      }
      return {
        mc: sumMasterPolyCommits,
        sc: sumServerPolyCommits
      };
    });

    // front end checks
    targetIndexes.map((target, i) => {
      const {
        mc,
        sc
      } = sums[i];
      // check master poly commits are consistent with tssPubKey
      const temp1 = ecPoint(this.ecCurve, dkgNewPub).mul(getLagrangeCoeff([1, target], 1, 0, this.ecCurve.n));
      const temp2 = mc[0].mul(getLagrangeCoeff([1, target], target, 0, this.ecCurve.n));
      const _tssPubKey = temp1.add(temp2);
      if (!_tssPubKey.eq(this.tssPubKey)) throw new Error("master poly commits inconsistent with tssPubKey");

      // check server poly commits are consistent with master poly commits
      if (!mc[0].add(mc[1]).eq(sc[0])) throw new Error("server poly commits inconsistent with master poly commits");
      return null;
    });

    // front end checks if decrypted user shares are consistent with poly commits
    const privKeyBuffer = Buffer.from(this.tempPrivKey.toString(16, 64), "hex");
    const userShares = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      const userEncs = rssRound1Responses.map(r => r.data[i].target_encryptions.user_enc);
      const userDecs = await Promise.all(userEncs.map(encMsg => decrypt(privKeyBuffer, encMsg)));
      const userShare = userDecs.map(userDec => new (external_bn_js_default())(userDec)).reduce((acc, d) => acc.add(d).umod(this.ecCurve.n), new (external_bn_js_default())(0));
      const {
        mc
      } = sums[i];
      const gU = this.ecCurve.g.mul(userShare);
      const _gU = mc[0].add(mc[1].mul(new (external_bn_js_default())(99))); // master poly evaluated at x = 99
      if (!gU.eq(_gU)) throw new Error("decrypted user shares inconsistent with poly commits");
      userShares.push(userShare);
    }
    const userFactorEncs = await Promise.all(userShares.map((userShare, i) => {
      const pub = factorPubs[i];
      return encrypt(Buffer.from(`04${pub.x.padStart(64, "0")}${pub.y.padStart(64, "0")}`, "hex"), Buffer.from(userShare.toString(16, 64), "hex"));
    }));

    // rearrange received serverEncs before sending them to new servers
    const serverEncs = targetIndexes.map((_, i) => {
      const serverEncsReceived = rssRound1Responses.map(r => r.data[i].target_encryptions.server_encs);
      // flip the matrix
      const serverEncsToSend = [];
      for (let j = 0; j < this.serverEndpoints.length; j++) {
        const serverEnc = [];
        for (let k = 0; k < this.serverThreshold * 2 + 1; k++) {
          serverEnc.push(serverEncsReceived[k][j]);
        }
        serverEncsToSend.push(serverEnc);
      }
      return serverEncsToSend;
    });

    // servers sum up their shares and encrypt it for factorPubs
    const serverIndexes = this.serverEndpoints.map((_, i) => i + 1);
    const serverFactorEncs = await Promise.all(serverIndexes.map(ind => {
      // TODO: specify it's "new" server set for server indexes
      const data = [];
      targetIndexes.map((_, i) => {
        const {
          mc,
          sc
        } = sums[i];
        const round2RequestData = {
          master_commits: mc.map(hexPoint),
          server_commits: sc.map(hexPoint),
          server_encs: serverEncs[i][ind - 1],
          factor_pubkeys: [factorPubs[i]] // TODO: must we do it like this?
        };
        data.push(round2RequestData);
        return null;
      });
      const serverEndpoint = this.serverEndpoints[ind - 1];
      return postEndpoint(serverEndpoint, "/rss_round_2", {
        round_name: "rss_round_2",
        server_index: ind,
        target_index: targetIndexes,
        data,
        key_type: this.keyType
      }).catch(e => external_loglevel_default().error(e));
    }));
    if (serverFactorEncs.filter(s => s).length < this.serverThreshold) throw new Error("not enough servers responded");
    const factorEncs = [];
    for (let i = 0; i < targetIndexes.length; i++) {
      factorEncs.push({
        targetIndex: targetIndexes[i],
        factorPub: factorPubs[i],
        serverFactorEncs: serverFactorEncs.map(s => s && s.data[i].encs[0]),
        userFactorEnc: userFactorEncs[i]
      });
    }
    return factorEncs;
  }
}
async function recover(opts) {
  const {
    factorKey,
    serverEncs,
    userEnc,
    selectedServers,
    keyType
  } = opts;
  if (opts.keyType !== "secp256k1" && opts.keyType !== "ed25519") throw new Error("Invalid keyType, only secp256k1 or ed25519 is supported");
  const ecCurve = new external_elliptic_namespaceObject.ec(keyType);
  const factorKeyBuf = Buffer.from(factorKey.toString(16, 64), "hex");
  const prom1 = decrypt(factorKeyBuf, userEnc).then(buf => new (external_bn_js_default())(buf));
  const prom2 = Promise.all(serverEncs.map(serverEnc => serverEnc && decrypt(factorKeyBuf, serverEnc).then(buf => new (external_bn_js_default())(buf))));
  const [decryptedUserEnc, decryptedServerEncs] = await Promise.all([prom1, prom2]);
  // use threshold number of factor encryptions from the servers to interpolate server share
  const someDecrypted = decryptedServerEncs.filter((_, j) => selectedServers.indexOf(j + 1) >= 0);
  const decryptedLCs = selectedServers.map(index => getLagrangeCoeff(selectedServers, index, 0, ecCurve.n));
  const temp1 = decryptedUserEnc.mul(getLagrangeCoeff([1, 99], 99, 0, ecCurve.n));
  const serverReconstructed = dotProduct(someDecrypted, decryptedLCs).umod(ecCurve.n);
  const temp2 = serverReconstructed.mul(getLagrangeCoeff([1, 99], 1, 0, ecCurve.n));
  const tssShare = temp1.add(temp2).umod(ecCurve.n);
  return {
    tssShare
  };
}
;// ./src/index.ts


module.exports = __webpack_exports__;
/******/ })()
;